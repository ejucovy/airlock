{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"api/core/","title":"Core API Reference","text":"<p>The main functions you'll use in application code.</p>"},{"location":"api/core/#airlockscope","title":"airlock.scope()","text":"<p>Create a lifecycle boundary for side effects.</p> <pre><code>airlock.scope(\n    policy=None,\n    executor=None,\n    *,\n    _cls=Scope\n) -&gt; ContextManager[Scope]\n</code></pre> <p>Parameters:</p> <ul> <li><code>policy</code> (Policy | None) - Policy controlling what intents are allowed. Defaults to <code>AllowAll()</code>.</li> <li><code>executor</code> (Callable | None) - Executor for dispatching intents. Defaults to <code>sync_executor</code>.</li> <li><code>_cls</code> (Type[Scope]) - Scope class to use. For custom scope subclasses.</li> </ul> <p>Returns: Context manager yielding the scope instance.</p> <p>Example:</p> <pre><code>with airlock.scope() as s:\n    airlock.enqueue(task_a)\n    airlock.enqueue(task_b)\n# Effects dispatch here\n</code></pre> <p>With custom scope:</p> <pre><code>from airlock.integrations.django import DjangoScope\n\nwith airlock.scope(_cls=DjangoScope):\n    airlock.enqueue(task)\n</code></pre>"},{"location":"api/core/#airlockenqueue","title":"airlock.enqueue()","text":"<p>Express intent to perform a side effect.</p> <pre><code>airlock.enqueue(\n    task: Callable,\n    *args,\n    _origin: str | None = None,\n    _dispatch_options: dict | None = None,\n    **kwargs\n) -&gt; None\n</code></pre> <p>Parameters:</p> <ul> <li><code>task</code> (Callable) - The callable to execute (Celery task, function, etc.)</li> <li><code>*args</code> - Positional arguments for the task</li> <li><code>_origin</code> (str | None) - Optional origin metadata for debugging</li> <li><code>_dispatch_options</code> (dict | None) - Optional dispatch options (countdown, queue, etc.)</li> <li><code>**kwargs</code> - Keyword arguments for the task</li> </ul> <p>Raises:</p> <ul> <li><code>NoScopeError</code> - If no scope is active</li> <li><code>PolicyEnqueueError</code> - If called from within a policy callback</li> </ul> <p>Example:</p> <pre><code>airlock.enqueue(send_email, user_id=123)\n\nairlock.enqueue(\n    send_email,\n    user_id=123,\n    _dispatch_options={\"countdown\": 60, \"queue\": \"emails\"}\n)\n</code></pre>"},{"location":"api/core/#airlockpolicy","title":"airlock.policy()","text":"<p>Context manager for local policy control without creating a new buffer.</p> <pre><code>airlock.policy(p: Policy) -&gt; ContextManager[None]\n</code></pre> <p>Parameters:</p> <ul> <li><code>p</code> (Policy) - Policy to apply to intents enqueued within this context</li> </ul> <p>Example:</p> <pre><code>with airlock.scope():\n    airlock.enqueue(task_a)  # Will dispatch\n\n    with airlock.policy(airlock.DropAll()):\n        airlock.enqueue(task_b)  # Won't dispatch\n\n    airlock.enqueue(task_c)  # Will dispatch\n</code></pre> <p>All intents go to the same buffer. Policy is captured per-intent at enqueue time.</p>"},{"location":"api/core/#airlockget_current_scope","title":"airlock.get_current_scope()","text":"<p>Get the currently active scope, or None.</p> <pre><code>airlock.get_current_scope() -&gt; Scope | None\n</code></pre> <p>Returns: The active scope, or <code>None</code> if no scope is active.</p> <p>Example:</p> <pre><code>scope = airlock.get_current_scope()\nif scope:\n    print(f\"Buffered intents: {len(scope.intents)}\")\nelse:\n    print(\"No active scope\")\n</code></pre>"},{"location":"api/core/#next-steps","title":"Next Steps","text":"<ul> <li>Scope Class API - Scope methods and properties</li> <li>Policies API - Built-in policies reference</li> <li>Intent API - Intent class reference</li> </ul>"},{"location":"api/intent/","title":"Intent API","text":"<p>The <code>Intent</code> class represents a buffered side effect.</p>"},{"location":"api/intent/#properties","title":"Properties","text":"Property Type Description <code>task</code> <code>Callable</code> The callable to execute <code>args</code> <code>tuple</code> Positional arguments <code>kwargs</code> <code>dict</code> Keyword arguments <code>name</code> <code>str</code> Derived name for logging/filtering <code>origin</code> <code>str \\| None</code> Optional origin metadata <code>dispatch_options</code> <code>dict \\| None</code> Queue-specific options (countdown, queue, etc.) <code>local_policies</code> <code>tuple[Policy, ...]</code> Captured policy stack from <code>airlock.policy()</code>"},{"location":"api/intent/#methods","title":"Methods","text":""},{"location":"api/intent/#passes_local_policies","title":"passes_local_policies()","text":"<p>Check if this intent passes its captured local policies.</p> <pre><code>def passes_local_policies(self) -&gt; bool:\n    \"\"\"\n    Returns:\n        True if intent passes all local policies, False otherwise\n    \"\"\"\n</code></pre> <p>Example:</p> <pre><code>with airlock.scope() as s:\n    airlock.enqueue(task_a)  # No local policies\n\n    with airlock.policy(airlock.DropAll()):\n        airlock.enqueue(task_b)  # Captured DropAll\n\n    intent_a, intent_b = s.intents\n\n    assert intent_a.passes_local_policies() is True   # No policies\n    assert intent_b.passes_local_policies() is False  # DropAll blocks\n</code></pre> <p>Note: This only checks local policies (from <code>airlock.policy()</code>). It does NOT check: - Scope-level policy - Whether scope will flush or discard - Dispatch execution success</p>"},{"location":"api/intent/#intent-name","title":"Intent Name","text":"<p>The <code>name</code> property is derived from the task:</p> <pre><code># Function\ndef my_task():\n    pass\n\nintent = Intent(task=my_task, ...)\nassert intent.name == \"my_task\"\n\n# Celery task\n@app.task\ndef celery_task():\n    pass\n\nintent = Intent(task=celery_task, ...)\nassert intent.name == \"celery_task\"\n\n# Lambda (gets generic name)\nintent = Intent(task=lambda: None, ...)\nassert intent.name == \"&lt;lambda&gt;\"\n</code></pre> <p>Used for: - Logging - Policy filtering (e.g., <code>BlockTasks({\"my_task\"})</code>) - Debugging</p>"},{"location":"api/intent/#creating-intents","title":"Creating Intents","text":"<p>You typically don't create intents directly - use <code>airlock.enqueue()</code>:</p> <pre><code>airlock.enqueue(my_task, arg1, arg2, kwarg=value)\n# Creates: Intent(task=my_task, args=(arg1, arg2), kwargs={\"kwarg\": value})\n</code></pre> <p>But you can create them manually for testing:</p> <pre><code>from airlock import Intent\n\nintent = Intent(\n    task=my_task,\n    args=(1, 2),\n    kwargs={\"foo\": \"bar\"},\n    origin=\"test\",\n    dispatch_options={\"queue\": \"high\"},\n    local_policies=()\n)\n</code></pre>"},{"location":"api/intent/#dispatch-options","title":"Dispatch Options","text":"<p>Options are passed through to the executor:</p> <pre><code># Celery executor\nairlock.enqueue(\n    celery_task,\n    arg,\n    _dispatch_options={\"countdown\": 60, \"queue\": \"emails\"}\n)\n# Calls: celery_task.apply_async(args=(arg,), countdown=60, queue=\"emails\")\n\n# django-q executor\nairlock.enqueue(\n    task,\n    arg,\n    _dispatch_options={\"group\": \"batch\", \"timeout\": 300}\n)\n# Calls: async_task(task, arg, group=\"batch\", timeout=300)\n</code></pre> <p>Options are executor-specific.</p>"},{"location":"api/intent/#local-policies","title":"Local Policies","text":"<p>Policies captured via <code>airlock.policy()</code>:</p> <pre><code>with airlock.scope() as s:\n    with airlock.policy(airlock.BlockTasks({\"foo\"})):\n        with airlock.policy(airlock.LogOnFlush()):\n            airlock.enqueue(task)\n\nintent = s.intents[0]\nassert len(intent.local_policies) == 2\n# [BlockTasks(...), LogOnFlush(...)]\n</code></pre> <p>Policies are evaluated innermost first at flush time.</p>"},{"location":"api/intent/#provenance-origin","title":"Provenance (origin)","text":"<p>Optional metadata for debugging:</p> <pre><code>airlock.enqueue(task, _origin=\"checkout_flow:step_3\")\n\n# Later inspection\nfor intent in scope.intents:\n    print(f\"{intent.name} from {intent.origin}\")\n</code></pre>"},{"location":"api/intent/#immutability","title":"Immutability","text":"<p>Intents are frozen after creation - you cannot modify them:</p> <pre><code>intent.args = (new_args,)  # Error: can't set attribute\n</code></pre> <p>This ensures policies can't mutate intents.</p>"},{"location":"api/intent/#example-testing","title":"Example: Testing","text":"<pre><code>def test_order_processing():\n    with airlock.scope() as s:\n        process_order(123)\n\n    # Inspect buffered intents\n    assert len(s.intents) == 2\n\n    email_intent = s.intents[0]\n    assert email_intent.name == \"send_confirmation_email\"\n    assert email_intent.args == ()\n    assert email_intent.kwargs == {\"order_id\": 123}\n\n    warehouse_intent = s.intents[1]\n    assert warehouse_intent.name == \"notify_warehouse\"\n    assert warehouse_intent.kwargs == {\"order_id\": 123}\n</code></pre>"},{"location":"api/intent/#example-custom-policy-using-intent","title":"Example: Custom Policy Using Intent","text":"<pre><code>class PriorityFilter(Policy):\n    def allows(self, intent: Intent) -&gt; bool:\n        # Filter based on dispatch options\n        priority = intent.dispatch_options.get(\"priority\", 0)\n        return priority &gt;= 5\n\nwith airlock.scope(policy=PriorityFilter()):\n    airlock.enqueue(low, _dispatch_options={\"priority\": 1})   # Dropped\n    airlock.enqueue(high, _dispatch_options={\"priority\": 10}) # Dispatches\n</code></pre>"},{"location":"api/intent/#next-steps","title":"Next Steps","text":"<ul> <li>Core API - Main airlock functions</li> <li>Scope API - Scope class reference</li> <li>Policies API - Built-in policies</li> </ul>"},{"location":"api/policies/","title":"Policies API Reference","text":"<p>Built-in policies for controlling side effect execution.</p>"},{"location":"api/policies/#allowall","title":"AllowAll","text":"<p>Allows all intents (default).</p> <pre><code>class AllowAll(Policy)\n</code></pre> <p>Example:</p> <pre><code>with airlock.scope(policy=airlock.AllowAll()):\n    airlock.enqueue(anything)  # Always dispatches\n</code></pre>"},{"location":"api/policies/#dropall","title":"DropAll","text":"<p>Silently drops all intents.</p> <pre><code>class DropAll(Policy)\n</code></pre> <p>Example:</p> <pre><code>with airlock.scope(policy=airlock.DropAll()):\n    airlock.enqueue(task)  # Buffered but never dispatched\n</code></pre>"},{"location":"api/policies/#assertnoeffects","title":"AssertNoEffects","text":"<p>Raises <code>PolicyViolation</code> if any intent is enqueued.</p> <pre><code>class AssertNoEffects(Policy)\n</code></pre> <p>Raises: <code>PolicyViolation</code> immediately on any <code>enqueue()</code> call.</p> <p>Example:</p> <pre><code>with airlock.scope(policy=airlock.AssertNoEffects()):\n    pure_function()  # OK\n    airlock.enqueue(task)  # Raises PolicyViolation\n</code></pre>"},{"location":"api/policies/#blocktasks","title":"BlockTasks","text":"<p>Blocks specific tasks by name.</p> <pre><code>class BlockTasks(Policy):\n    def __init__(\n        self,\n        blocked_names: Set[str],\n        raise_on_enqueue: bool = False\n    )\n</code></pre> <p>Parameters:</p> <ul> <li><code>blocked_names</code> (Set[str]) - Set of task names to block</li> <li><code>raise_on_enqueue</code> (bool) - If <code>True</code>, raise on enqueue. If <code>False</code>, silently drop at flush.</li> </ul> <p>Example:</p> <pre><code># Silent drop\npolicy = airlock.BlockTasks({\"send_email\", \"send_sms\"})\n\n# Fail fast\npolicy = airlock.BlockTasks({\"dangerous_task\"}, raise_on_enqueue=True)\n</code></pre>"},{"location":"api/policies/#logonflush","title":"LogOnFlush","text":"<p>Logs all intents at flush time.</p> <pre><code>class LogOnFlush(Policy):\n    def __init__(self, logger: logging.Logger | None = None)\n</code></pre> <p>Parameters:</p> <ul> <li><code>logger</code> (Logger | None) - Logger to use. If None, uses default logger.</li> </ul> <p>Example:</p> <pre><code>import logging\nlogger = logging.getLogger(__name__)\n\nwith airlock.scope(policy=airlock.LogOnFlush(logger)):\n    airlock.enqueue(task_a)\n    airlock.enqueue(task_b)\n# Logs: \"Flushing intent: task_a\"\n# Logs: \"Flushing intent: task_b\"\n</code></pre>"},{"location":"api/policies/#compositepolicy","title":"CompositePolicy","text":"<p>Combines multiple policies.</p> <pre><code>class CompositePolicy(Policy):\n    def __init__(self, *policies: Policy)\n</code></pre> <p>Parameters:</p> <ul> <li><code>*policies</code> (Policy) - Policies to combine</li> </ul> <p>Behavior: All policies must allow for intent to execute. If any policy returns <code>False</code> from <code>allows()</code>, the intent is dropped.</p> <p>Example:</p> <pre><code>policy = airlock.CompositePolicy(\n    airlock.LogOnFlush(logger),\n    airlock.BlockTasks({\"expensive_task\"}),\n)\n\nwith airlock.scope(policy=policy):\n    airlock.enqueue(cheap_task)      # Logged + dispatched\n    airlock.enqueue(expensive_task)  # Logged but blocked\n</code></pre>"},{"location":"api/policies/#policy-protocol","title":"Policy Protocol","text":"<p>To write custom policies, implement this protocol:</p> <pre><code>class Policy(Protocol):\n    def on_enqueue(self, intent: Intent) -&gt; None:\n        \"\"\"\n        Called when intent is added to buffer.\n        Observe or raise. Return value ignored.\n        \"\"\"\n        ...\n\n    def allows(self, intent: Intent) -&gt; bool:\n        \"\"\"\n        Called at flush time.\n        Return True to dispatch, False to drop.\n        \"\"\"\n        ...\n</code></pre> <p>See Custom Policies for examples.</p>"},{"location":"api/policies/#next-steps","title":"Next Steps","text":"<ul> <li>Custom Policies Guide - Write your own policies</li> <li>Core API - Main airlock functions</li> <li>Intent API - Intent class reference</li> </ul>"},{"location":"api/scope-class/","title":"Scope Class API","text":"<p>The <code>Scope</code> class manages the lifecycle of side effect buffering and dispatch.</p>"},{"location":"api/scope-class/#context-manager-api-recommended","title":"Context Manager API (Recommended)","text":"<p>Most code should use the context manager:</p> <pre><code>with airlock.scope() as s:\n    airlock.enqueue(task)\n# Automatic lifecycle management\n</code></pre>"},{"location":"api/scope-class/#scope-properties","title":"Scope Properties","text":"Property Type Description <code>intents</code> <code>list[Intent]</code> All buffered intents (own + captured) <code>own_intents</code> <code>list[Intent]</code> Intents enqueued directly in this scope <code>captured_intents</code> <code>list[Intent]</code> Intents captured from nested scopes <code>is_flushed</code> <code>bool</code> True after <code>flush()</code> called <code>is_discarded</code> <code>bool</code> True after <code>discard()</code> called <p>Example:</p> <pre><code>with airlock.scope() as s:\n    airlock.enqueue(task_a)\n\n    with airlock.scope():\n        airlock.enqueue(task_b)\n\n    print(f\"Own: {len(s.own_intents)}\")          # 1\n    print(f\"Captured: {len(s.captured_intents)}\")  # 1\n    print(f\"Total: {len(s.intents)}\")            # 2\n</code></pre>"},{"location":"api/scope-class/#subclassing-api","title":"Subclassing API","text":"<p>Override these methods to customize behavior:</p>"},{"location":"api/scope-class/#should_flusherror","title":"should_flush(error)","text":"<p>Decide whether to flush or discard on scope exit.</p> <pre><code>def should_flush(self, error: BaseException | None) -&gt; bool:\n    \"\"\"\n    Args:\n        error: Exception that caused exit, or None for normal exit\n\n    Returns:\n        True to flush, False to discard\n\n    Default: flush on success (error is None), discard on error\n    \"\"\"\n    return error is None\n</code></pre> <p>Example:</p> <pre><code>class AlwaysFlushScope(Scope):\n    def should_flush(self, error):\n        return True  # Flush even on error\n\nwith airlock.scope(_cls=AlwaysFlushScope):\n    airlock.enqueue(send_alert)\n    raise Exception()  # Alert still dispatches\n</code></pre>"},{"location":"api/scope-class/#before_descendant_flushesexiting_scope-intents","title":"before_descendant_flushes(exiting_scope, intents)","text":"<p>Control what happens when nested scopes exit.</p> <pre><code>def before_descendant_flushes(\n    self,\n    exiting_scope: Scope,\n    intents: list[Intent]\n) -&gt; list[Intent]:\n    \"\"\"\n    Args:\n        exiting_scope: The nested scope that is exiting\n        intents: Intents the nested scope wants to flush\n\n    Returns:\n        Intents to allow through (rest are captured)\n\n    Default: return [] (capture all)\n    \"\"\"\n    return []\n</code></pre> <p>Example:</p> <pre><code>class IndependentScope(Scope):\n    def before_descendant_flushes(self, exiting_scope, intents):\n        return intents  # Allow all through (don't capture)\n\nwith IndependentScope():\n    with airlock.scope():\n        airlock.enqueue(task)\n    # task dispatches here (not captured)\n</code></pre>"},{"location":"api/scope-class/#_dispatch_allintents","title":"_dispatch_all(intents)","text":"<p>Customize how intents are dispatched.</p> <pre><code>def _dispatch_all(self, intents: list[Intent]) -&gt; None:\n    \"\"\"\n    Args:\n        intents: Filtered intents to dispatch\n\n    Default: iterate and execute via executor\n    \"\"\"\n    for intent in intents:\n        _execute(intent, executor=self._executor)\n</code></pre> <p>Example:</p> <pre><code>from django.db import transaction\n\nclass DjangoScope(Scope):\n    def _dispatch_all(self, intents):\n        # Defer to transaction.on_commit()\n        def do_dispatch():\n            for intent in intents:\n                _execute(intent, executor=self._executor)\n\n        transaction.on_commit(do_dispatch)\n</code></pre>"},{"location":"api/scope-class/#imperative-api-advanced","title":"Imperative API (Advanced)","text":"<p>For framework integrations (middleware, task wrappers):</p>"},{"location":"api/scope-class/#enter","title":"enter()","text":"<p>Activate the scope.</p> <pre><code>s = Scope()\ns.enter()  # Scope is now active\n</code></pre>"},{"location":"api/scope-class/#exit","title":"exit()","text":"<p>Deactivate the scope.</p> <pre><code>s.exit()  # Scope is no longer active\n# Must still call flush() or discard()\n</code></pre>"},{"location":"api/scope-class/#flush","title":"flush()","text":"<p>Apply policy and dispatch intents.</p> <pre><code>s.flush()  # Dispatches allowed intents\n</code></pre> <p>Raises: <code>ScopeStateError</code> if already flushed/discarded or still active.</p>"},{"location":"api/scope-class/#discard","title":"discard()","text":"<p>Drop all intents without dispatching.</p> <pre><code>s.discard()  # All intents dropped\n</code></pre> <p>Raises: <code>ScopeStateError</code> if already flushed/discarded or still active.</p>"},{"location":"api/scope-class/#example-django-middleware-pattern","title":"Example: Django Middleware Pattern","text":"<pre><code>def middleware(get_response, request):\n    s = Scope()\n    s.enter()\n\n    error = None\n    try:\n        response = get_response(request)\n    except BaseException as e:\n        error = e\n        raise\n    finally:\n        s.exit()  # Deactivate first\n\n    # Decide terminal action\n    if s.should_flush(error):\n        s.flush()\n    else:\n        s.discard()\n\n    return response\n</code></pre>"},{"location":"api/scope-class/#lifecycle-states","title":"Lifecycle States","text":"<pre><code>Created \u2192 Entered \u2192 Exited \u2192 Flushed/Discarded\n          (active)  (inactive)  (terminal)\n</code></pre> <p>State transitions:</p> <ul> <li><code>enter()</code>: Created \u2192 Entered</li> <li><code>exit()</code>: Entered \u2192 Exited</li> <li><code>flush()</code> or <code>discard()</code>: Exited \u2192 Terminal</li> </ul> <p>Invariants:</p> <ul> <li>Can only <code>enter()</code> once</li> <li>Can only <code>exit()</code> after <code>enter()</code></li> <li>Can only <code>flush()</code> or <code>discard()</code> after <code>exit()</code></li> <li>Cannot <code>flush()</code> and <code>discard()</code> (terminal states are exclusive)</li> </ul>"},{"location":"api/scope-class/#next-steps","title":"Next Steps","text":"<ul> <li>Custom Scopes Guide - Subclassing patterns</li> <li>Core API - Main airlock functions</li> <li>Intent API - Intent class reference</li> </ul>"},{"location":"extending/custom-executors/","title":"Custom Executors","text":"<p>Write custom executors to dispatch intents however you want.</p>"},{"location":"extending/custom-executors/#the-executor-interface","title":"The Executor Interface","text":"<p>An executor is just a callable that accepts an <code>Intent</code>:</p> <pre><code>def my_executor(intent: Intent) -&gt; None:\n    \"\"\"Execute an intent.\"\"\"\n    intent.task(*intent.args, **intent.kwargs)\n</code></pre> <p>That's it! No inheritance, no protocol, just a function.</p>"},{"location":"extending/custom-executors/#example-thread-pool","title":"Example: Thread Pool","text":"<pre><code>from concurrent.futures import ThreadPoolExecutor\n\nexecutor_pool = ThreadPoolExecutor(max_workers=10)\n\ndef thread_executor(intent):\n    \"\"\"Execute in thread pool.\"\"\"\n    executor_pool.submit(intent.task, *intent.args, **intent.kwargs)\n\n# Usage\nwith airlock.scope(executor=thread_executor):\n    airlock.enqueue(cpu_bound_task, data)\n# Dispatches in background thread\n</code></pre>"},{"location":"extending/custom-executors/#example-process-pool","title":"Example: Process Pool","text":"<pre><code>from multiprocessing import Pool\n\nprocess_pool = Pool(processes=4)\n\ndef process_executor(intent):\n    \"\"\"Execute in process pool.\"\"\"\n    process_pool.apply_async(intent.task, intent.args, intent.kwargs)\n\nwith airlock.scope(executor=process_executor):\n    airlock.enqueue(heavy_computation, large_data)\n</code></pre>"},{"location":"extending/custom-executors/#example-aws-lambda","title":"Example: AWS Lambda","text":"<pre><code>import boto3\nimport json\n\nlambda_client = boto3.client('lambda')\n\ndef lambda_executor(intent):\n    \"\"\"Execute via AWS Lambda.\"\"\"\n    payload = {\n        \"function\": intent.name,\n        \"args\": intent.args,\n        \"kwargs\": intent.kwargs,\n    }\n\n    lambda_client.invoke(\n        FunctionName=intent.name,\n        InvocationType='Event',\n        Payload=json.dumps(payload)\n    )\n\nwith airlock.scope(executor=lambda_executor):\n    airlock.enqueue(remote_task, data=payload)\n</code></pre>"},{"location":"extending/custom-executors/#example-http-api","title":"Example: HTTP API","text":"<pre><code>import requests\n\ndef api_executor(intent):\n    \"\"\"Execute via HTTP webhook.\"\"\"\n    endpoint = intent.dispatch_options.get(\"endpoint\", \"/default\")\n\n    requests.post(\n        f\"https://api.example.com{endpoint}\",\n        json={\n            \"task\": intent.name,\n            \"args\": intent.args,\n            \"kwargs\": intent.kwargs,\n        }\n    )\n\nwith airlock.scope(executor=api_executor):\n    airlock.enqueue(\n        remote_task,\n        data,\n        _dispatch_options={\"endpoint\": \"/tasks/heavy\"}\n    )\n</code></pre>"},{"location":"extending/custom-executors/#example-dry-run-logger","title":"Example: Dry-Run Logger","text":"<pre><code>def logging_executor(intent):\n    \"\"\"Log instead of executing (dry-run).\"\"\"\n    logger.info(\n        f\"Would execute: {intent.name}({intent.args}, {intent.kwargs})\"\n    )\n\nwith airlock.scope(executor=logging_executor):\n    airlock.enqueue(dangerous_task)  # Just logs, doesn't execute\n</code></pre>"},{"location":"extending/custom-executors/#example-conditional-executor","title":"Example: Conditional Executor","text":"<p>Route to different backends based on intent:</p> <pre><code>from airlock.integrations.executors.celery import celery_executor\nfrom airlock.integrations.executors.sync import sync_executor\n\ndef smart_executor(intent):\n    \"\"\"Route heavy tasks to Celery, light tasks run sync.\"\"\"\n    if intent.dispatch_options.get(\"heavy\"):\n        celery_executor(intent)\n    else:\n        sync_executor(intent)\n\nwith airlock.scope(executor=smart_executor):\n    airlock.enqueue(light_task)  # Runs sync\n    airlock.enqueue(heavy_task, _dispatch_options={\"heavy\": True})  # Via Celery\n</code></pre>"},{"location":"extending/custom-executors/#using-dispatch-options","title":"Using Dispatch Options","text":"<p>Executors can read <code>intent.dispatch_options</code>:</p> <pre><code>def priority_executor(intent):\n    \"\"\"Execute high-priority tasks immediately, queue low-priority.\"\"\"\n    priority = intent.dispatch_options.get(\"priority\", 5)\n\n    if priority &gt;= 8:\n        # High priority: execute immediately\n        intent.task(*intent.args, **intent.kwargs)\n    else:\n        # Low priority: queue for later\n        celery_executor(intent)\n\n# Usage\nairlock.enqueue(\n    urgent_task,\n    _dispatch_options={\"priority\": 10}\n)  # Runs immediately\n\nairlock.enqueue(\n    batch_task,\n    _dispatch_options={\"priority\": 3}\n)  # Queued\n</code></pre>"},{"location":"extending/custom-executors/#error-handling","title":"Error Handling","text":"<p>Executor exceptions abort flush:</p> <pre><code>def careful_executor(intent):\n    try:\n        intent.task(*intent.args, **intent.kwargs)\n    except Exception as e:\n        # Log but don't crash flush\n        logger.error(f\"Failed to execute {intent.name}: {e}\")\n        # Re-raise to abort flush (or don't to continue)\n        raise\n</code></pre> <p>By default, exceptions propagate and abort flush. This is fail-fast behavior.</p>"},{"location":"extending/custom-executors/#composing-executors","title":"Composing Executors","text":"<p>Wrap executors for additional behavior:</p> <pre><code>def with_retry(executor, retries=3):\n    \"\"\"Wrap executor with retry logic.\"\"\"\n    def retrying_executor(intent):\n        for attempt in range(retries):\n            try:\n                executor(intent)\n                return\n            except Exception as e:\n                if attempt == retries - 1:\n                    raise\n                logger.warning(f\"Retry {attempt + 1}/{retries} for {intent.name}\")\n    return retrying_executor\n\n# Usage\nexecutor = with_retry(celery_executor, retries=3)\n\nwith airlock.scope(executor=executor):\n    airlock.enqueue(flaky_task)\n</code></pre>"},{"location":"extending/custom-executors/#testing-custom-executors","title":"Testing Custom Executors","text":"<pre><code>def test_thread_executor():\n    executed = []\n\n    def track_executor(intent):\n        executed.append(intent.name)\n\n    with airlock.scope(executor=track_executor):\n        airlock.enqueue(task_a)\n        airlock.enqueue(task_b)\n\n    assert len(executed) == 2\n    assert executed == [\"task_a\", \"task_b\"]\n</code></pre>"},{"location":"extending/custom-executors/#built-in-executors","title":"Built-in Executors","text":"<p>Airlock provides executors for common backends:</p> <pre><code>from airlock.integrations.executors.sync import sync_executor\nfrom airlock.integrations.executors.celery import celery_executor\nfrom airlock.integrations.executors.django_q import django_q_executor\nfrom airlock.integrations.executors.huey import huey_executor\nfrom airlock.integrations.executors.dramatiq import dramatiq_executor\n</code></pre> <p>See Dispatch Guide for details.</p>"},{"location":"extending/custom-executors/#common-patterns","title":"Common Patterns","text":""},{"location":"extending/custom-executors/#pattern-1-fallback-executor","title":"Pattern 1: Fallback Executor","text":"<pre><code>def fallback_executor(intent):\n    \"\"\"Try Celery, fall back to sync if unavailable.\"\"\"\n    try:\n        celery_executor(intent)\n    except Exception:\n        logger.warning(f\"Celery unavailable, running {intent.name} sync\")\n        sync_executor(intent)\n</code></pre>"},{"location":"extending/custom-executors/#pattern-2-batching-executor","title":"Pattern 2: Batching Executor","text":"<pre><code>class BatchingExecutor:\n    def __init__(self, batch_size=10):\n        self.batch_size = batch_size\n        self.batch = []\n\n    def __call__(self, intent):\n        self.batch.append(intent)\n        if len(self.batch) &gt;= self.batch_size:\n            self.flush_batch()\n\n    def flush_batch(self):\n        # Execute batch\n        for intent in self.batch:\n            intent.task(*intent.args, **intent.kwargs)\n        self.batch.clear()\n\nexecutor = BatchingExecutor(batch_size=100)\n</code></pre>"},{"location":"extending/custom-executors/#pattern-3-rate-limited-executor","title":"Pattern 3: Rate-Limited Executor","text":"<pre><code>import time\n\nclass RateLimitedExecutor:\n    def __init__(self, max_per_second=10):\n        self.interval = 1.0 / max_per_second\n        self.last_execute = 0\n\n    def __call__(self, intent):\n        now = time.time()\n        elapsed = now - self.last_execute\n        if elapsed &lt; self.interval:\n            time.sleep(self.interval - elapsed)\n\n        intent.task(*intent.args, **intent.kwargs)\n        self.last_execute = time.time()\n</code></pre>"},{"location":"extending/custom-executors/#next-steps","title":"Next Steps","text":"<ul> <li>Custom Scopes - Advanced scope customization</li> <li>Custom Policies - Write custom policies</li> <li>Executor API Reference - Complete executor API</li> </ul>"},{"location":"extending/custom-policies/","title":"Custom Policies","text":"<p>Write your own policies to implement custom filtering, validation, and observation logic.</p>"},{"location":"extending/custom-policies/#the-policy-protocol","title":"The Policy Protocol","text":"<pre><code>class Policy:\n    def on_enqueue(self, intent: Intent) -&gt; None:\n        \"\"\"\n        Called when intent is added to buffer.\n        Observe or raise. Return value ignored.\n        \"\"\"\n        pass\n\n    def allows(self, intent: Intent) -&gt; bool:\n        \"\"\"\n        Called at flush time.\n        Return True to dispatch, False to drop.\n        \"\"\"\n        return True\n</code></pre>"},{"location":"extending/custom-policies/#example-rate-limiting","title":"Example: Rate Limiting","text":"<pre><code>class RateLimitPolicy:\n    def __init__(self, max_per_flush: int):\n        self.max = max_per_flush\n        self._count = 0\n\n    def on_enqueue(self, intent):\n        pass  # Could warn if close to limit\n\n    def allows(self, intent):\n        if self._count &gt;= self.max:\n            return False\n        self._count += 1\n        return True\n\n# Usage\nwith airlock.scope(policy=RateLimitPolicy(max_per_flush=10)):\n    for i in range(100):\n        airlock.enqueue(task, i)\n# Only first 10 dispatch\n</code></pre>"},{"location":"extending/custom-policies/#example-priority-filtering","title":"Example: Priority Filtering","text":"<pre><code>class PriorityPolicy:\n    def __init__(self, min_priority: int):\n        self.min_priority = min_priority\n\n    def on_enqueue(self, intent):\n        pass\n\n    def allows(self, intent):\n        priority = intent.dispatch_options.get(\"priority\", 0)\n        return priority &gt;= self.min_priority\n\n# Usage\nwith airlock.scope(policy=PriorityPolicy(min_priority=5)):\n    airlock.enqueue(low_task, _dispatch_options={\"priority\": 1})   # Dropped\n    airlock.enqueue(high_task, _dispatch_options={\"priority\": 10}) # Dispatches\n</code></pre>"},{"location":"extending/custom-policies/#example-metrics-collection","title":"Example: Metrics Collection","text":"<pre><code>from datadog import statsd\n\nclass MetricsPolicy:\n    def on_enqueue(self, intent):\n        statsd.increment(f\"airlock.enqueued.{intent.name}\")\n\n    def allows(self, intent):\n        statsd.increment(f\"airlock.dispatched.{intent.name}\")\n        return True\n\n# All intents tracked in Datadog\n</code></pre>"},{"location":"extending/custom-policies/#example-audit-logging","title":"Example: Audit Logging","text":"<pre><code>import json\nfrom datetime import datetime\n\nclass AuditPolicy:\n    def __init__(self, audit_file):\n        self.audit_file = audit_file\n\n    def on_enqueue(self, intent):\n        entry = {\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"action\": \"enqueued\",\n            \"task\": intent.name,\n            \"args\": intent.args,\n            \"kwargs\": intent.kwargs,\n        }\n        with open(self.audit_file, \"a\") as f:\n            f.write(json.dumps(entry) + \"\\n\")\n\n    def allows(self, intent):\n        # Log again at dispatch\n        entry = {\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"action\": \"dispatched\",\n            \"task\": intent.name,\n        }\n        with open(self.audit_file, \"a\") as f:\n            f.write(json.dumps(entry) + \"\\n\")\n        return True\n</code></pre>"},{"location":"extending/custom-policies/#example-sampling","title":"Example: Sampling","text":"<pre><code>import random\n\nclass SamplingPolicy:\n    def __init__(self, sample_rate: float):\n        self.sample_rate = sample_rate\n\n    def on_enqueue(self, intent):\n        pass\n\n    def allows(self, intent):\n        return random.random() &lt; self.sample_rate\n\n# Only dispatch 10% of effects\nwith airlock.scope(policy=SamplingPolicy(0.1)):\n    for i in range(1000):\n        airlock.enqueue(analytics_task, i)\n# ~100 dispatch\n</code></pre>"},{"location":"extending/custom-policies/#example-circuit-breaker","title":"Example: Circuit Breaker","text":"<pre><code>class CircuitBreakerPolicy:\n    def __init__(self, error_threshold: int = 5):\n        self.error_threshold = error_threshold\n        self.error_count = 0\n        self.is_open = False\n\n    def on_enqueue(self, intent):\n        if self.is_open:\n            raise PolicyViolation(\"Circuit breaker is OPEN - too many errors\")\n\n    def allows(self, intent):\n        return not self.is_open\n\n    def record_error(self):\n        self.error_count += 1\n        if self.error_count &gt;= self.error_threshold:\n            self.is_open = True\n\n    def reset(self):\n        self.error_count = 0\n        self.is_open = False\n</code></pre>"},{"location":"extending/custom-policies/#when-to-raise-vs-return-false","title":"When to Raise vs Return False","text":"<p>Raise in <code>on_enqueue()</code> for fail-fast feedback:</p> <pre><code>def on_enqueue(self, intent):\n    if \"dangerous\" in intent.name:\n        raise PolicyViolation(f\"Dangerous task blocked: {intent.name}\")\n</code></pre> <p>Stack trace points to the <code>enqueue()</code> call site. Good for catching bugs.</p> <p>Return False in <code>allows()</code> for silent filtering:</p> <pre><code>def allows(self, intent):\n    if \"dangerous\" in intent.name:\n        return False  # Silently drop\n    return True\n</code></pre> <p>No error, no trace. Good for production filtering.</p>"},{"location":"extending/custom-policies/#stateful-policies","title":"Stateful Policies","text":"<p>Policies can maintain state:</p> <pre><code>class CountingPolicy:\n    def __init__(self):\n        self.enqueued = 0\n        self.dispatched = 0\n\n    def on_enqueue(self, intent):\n        self.enqueued += 1\n\n    def allows(self, intent):\n        self.dispatched += 1\n        return True\n\nwith airlock.scope(policy=CountingPolicy()) as s:\n    for i in range(10):\n        airlock.enqueue(task, i)\n\nprint(f\"Enqueued: {s._policy.enqueued}\")    # 10\nprint(f\"Dispatched: {s._policy.dispatched}\")  # 10\n</code></pre>"},{"location":"extending/custom-policies/#combining-policies","title":"Combining Policies","text":"<p>Use <code>CompositePolicy</code>:</p> <pre><code>policy = airlock.CompositePolicy(\n    RateLimitPolicy(max_per_flush=100),\n    MetricsPolicy(),\n    AuditPolicy(\"audit.log\"),\n)\n</code></pre> <p>Each policy's <code>allows()</code> is called. If any returns <code>False</code>, the intent is dropped.</p>"},{"location":"extending/custom-policies/#testing-custom-policies","title":"Testing Custom Policies","text":"<pre><code>def test_priority_policy():\n    policy = PriorityPolicy(min_priority=5)\n\n    low_intent = Intent(task=my_task, args=(), kwargs={}, dispatch_options={\"priority\": 1})\n    high_intent = Intent(task=my_task, args=(), kwargs={}, dispatch_options={\"priority\": 10})\n\n    assert policy.allows(low_intent) is False\n    assert policy.allows(high_intent) is True\n</code></pre>"},{"location":"extending/custom-policies/#common-patterns","title":"Common Patterns","text":""},{"location":"extending/custom-policies/#pattern-1-environment-based-behavior","title":"Pattern 1: Environment-Based Behavior","text":"<pre><code>class EnvPolicy:\n    def allows(self, intent):\n        if settings.ENV == \"development\":\n            return False  # Drop all in dev\n        if settings.ENV == \"staging\" and \"customer\" in intent.name:\n            return False  # Drop customer notifications in staging\n        return True\n</code></pre>"},{"location":"extending/custom-policies/#pattern-2-feature-flag-integration","title":"Pattern 2: Feature Flag Integration","text":"<pre><code>class FeatureFlagPolicy:\n    def allows(self, intent):\n        feature = intent.dispatch_options.get(\"feature\")\n        if feature and not feature_flags.is_enabled(feature):\n            return False\n        return True\n\n# Usage\nairlock.enqueue(\n    new_feature_task,\n    _dispatch_options={\"feature\": \"new_checkout\"}\n)\n</code></pre>"},{"location":"extending/custom-policies/#pattern-3-conditional-logging","title":"Pattern 3: Conditional Logging","text":"<pre><code>class VerbosePolicy:\n    def __init__(self, verbose: bool = False):\n        self.verbose = verbose\n\n    def on_enqueue(self, intent):\n        if self.verbose:\n            logger.debug(f\"Enqueued: {intent.name}\")\n\n    def allows(self, intent):\n        if self.verbose:\n            logger.debug(f\"Dispatching: {intent.name}\")\n        return True\n</code></pre>"},{"location":"extending/custom-policies/#important-constraints","title":"Important Constraints","text":""},{"location":"extending/custom-policies/#cannot-call-enqueue-from-policy","title":"Cannot Call enqueue() from Policy","text":"<pre><code>class BadPolicy:\n    def on_enqueue(self, intent):\n        airlock.enqueue(log_task)  # Raises PolicyEnqueueError!\n</code></pre> <p>This prevents infinite loops. If you need to trigger side effects from a policy, use a custom scope instead.</p>"},{"location":"extending/custom-policies/#cannot-reorder-intents","title":"Cannot Reorder Intents","text":"<p>Policies are per-intent boolean gates. They can't reorder:</p> <pre><code># \u274c Can't do this\ndef allows(self, intent):\n    if intent.priority == \"high\":\n        move_to_front(intent)  # Not possible\n    return True\n</code></pre> <p>For reordering, override <code>Scope._dispatch_all()</code>.</p>"},{"location":"extending/custom-policies/#next-steps","title":"Next Steps","text":"<ul> <li>Custom Executors - Write custom dispatch logic</li> <li>Custom Scopes - Advanced scope behavior</li> <li>Policy API Reference - Complete policy API</li> </ul>"},{"location":"extending/custom-scopes/","title":"Custom Scopes","text":"<p>Subclass <code>Scope</code> to customize lifecycle behavior: when to flush, how to dispatch, nested scope handling.</p>"},{"location":"extending/custom-scopes/#extension-points","title":"Extension Points","text":"Method Purpose Default <code>should_flush(error)</code> Decide whether to flush or discard Flush on success, discard on error <code>before_descendant_flushes(scope, intents)</code> Control nested scope capture Capture all <code>_dispatch_all(intents)</code> Customize dispatch mechanism Iterate and execute"},{"location":"extending/custom-scopes/#example-always-flush-even-on-error","title":"Example: Always Flush (Even on Error)","text":"<pre><code>class AlwaysFlushScope(Scope):\n    \"\"\"Flush even on error - for error notification patterns.\"\"\"\n\n    def should_flush(self, error: BaseException | None) -&gt; bool:\n        return True  # Always flush\n\n# Usage\nwith airlock.scope(_cls=AlwaysFlushScope):\n    airlock.enqueue(send_alert, severity=\"info\")\n    raise Exception(\"Something broke\")\n    # send_alert still dispatches despite exception\n</code></pre>"},{"location":"extending/custom-scopes/#example-conditional-flush","title":"Example: Conditional Flush","text":"<pre><code>class ConditionalScope(Scope):\n    \"\"\"Only flush if there are high-priority intents.\"\"\"\n\n    def should_flush(self, error: BaseException | None) -&gt; bool:\n        if error:\n            return False\n\n        # Only flush if at least one high-priority intent\n        return any(\n            i.dispatch_options and i.dispatch_options.get(\"priority\") == \"high\"\n            for i in self.intents\n        )\n\nwith airlock.scope(_cls=ConditionalScope):\n    airlock.enqueue(low_task, _dispatch_options={\"priority\": \"low\"})\n    airlock.enqueue(high_task, _dispatch_options={\"priority\": \"high\"})\n# Flushes because high_task is present\n</code></pre>"},{"location":"extending/custom-scopes/#example-deferred-dispatch-django-on_commit","title":"Example: Deferred Dispatch (Django on_commit)","text":"<pre><code>from django.db import transaction\n\nclass DjangoScope(Scope):\n    \"\"\"Defer dispatch until transaction commits.\"\"\"\n\n    def _dispatch_all(self, intents: list[Intent]) -&gt; None:\n        def do_dispatch():\n            # Execute dispatch after commit\n            for intent in intents:\n                _execute(intent)\n\n        transaction.on_commit(do_dispatch)\n\n# Usage\nwith transaction.atomic():\n    with airlock.scope(_cls=DjangoScope):\n        order.save()\n        airlock.enqueue(send_email, order.id)\n    # Email buffered, not dispatched yet\n# Email dispatches here (after commit)\n</code></pre>"},{"location":"extending/custom-scopes/#example-persistent-buffer-outbox-pattern","title":"Example: Persistent Buffer (Outbox Pattern)","text":"<pre><code>class OutboxScope(Scope):\n    \"\"\"Persist intents to database for durable buffering.\"\"\"\n\n    def _add(self, intent):\n        super()._add(intent)  # Add to in-memory buffer\n\n        # Also persist to database\n        TaskOutbox.objects.create(\n            task_name=intent.name,\n            args=intent.args,\n            kwargs=intent.kwargs,\n            status='pending'\n        )\n\n    def _dispatch_all(self, intents):\n        # Mark as ready instead of executing\n        # Separate worker will dispatch later\n        TaskOutbox.objects.filter(\n            task_name__in=[i.name for i in intents],\n            status='pending'\n        ).update(status='ready')\n\n# Intents survive process crashes\n</code></pre>"},{"location":"extending/custom-scopes/#example-independent-nested-scopes","title":"Example: Independent Nested Scopes","text":"<pre><code>class IndependentScope(Scope):\n    \"\"\"Allow nested scopes to flush independently.\"\"\"\n\n    def before_descendant_flushes(self, exiting_scope, intents):\n        return intents  # Allow all through (don't capture)\n\nwith IndependentScope():\n    with airlock.scope():\n        airlock.enqueue(task)\n    # task dispatches here (not captured)\n</code></pre>"},{"location":"extending/custom-scopes/#example-selective-capture","title":"Example: Selective Capture","text":"<pre><code>class SafetyScope(Scope):\n    \"\"\"Capture dangerous tasks, allow safe tasks through.\"\"\"\n\n    def before_descendant_flushes(self, exiting_scope, intents):\n        # Allow safe tasks through\n        safe = [i for i in intents if not i.dispatch_options.get(\"dangerous\")]\n        return safe\n\nwith SafetyScope():\n    with airlock.scope():\n        airlock.enqueue(safe_task)\n        airlock.enqueue(dangerous_task, _dispatch_options={\"dangerous\": True})\n    # safe_task executes here\n\n# dangerous_task executes here (was captured)\n</code></pre>"},{"location":"extending/custom-scopes/#example-batching-scope","title":"Example: Batching Scope","text":"<pre><code>class EmailBatchScope(Scope):\n    \"\"\"Batch emails, allow other intents through.\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.email_batch = []\n\n    def before_descendant_flushes(self, exiting_scope, intents):\n        # Separate emails from others\n        emails = [i for i in intents if 'email' in i.name]\n        others = [i for i in intents if 'email' not in i.name]\n\n        # Batch emails for later\n        self.email_batch.extend(emails)\n\n        # Allow others through now\n        return others\n\nwith EmailBatchScope() as scope:\n    process_bulk_operations()  # Nested code enqueues emails\n    # Non-email effects dispatched\n\n# Send batched emails\nsend_batch_emails(scope.email_batch)\n</code></pre>"},{"location":"extending/custom-scopes/#available-state-in-subclasses","title":"Available State in Subclasses","text":"Property Type Description <code>self.intents</code> <code>list[Intent]</code> All buffered intents (own + captured) <code>self.own_intents</code> <code>list[Intent]</code> Intents from this scope <code>self.captured_intents</code> <code>list[Intent]</code> Intents from nested scopes <code>self._policy</code> <code>Policy</code> Scope's policy <code>self.is_flushed</code> <code>bool</code> True after flush() called <code>self.is_discarded</code> <code>bool</code> True after discard() called"},{"location":"extending/custom-scopes/#lifecycle-phases","title":"Lifecycle Phases","text":"<p>Understanding the lifecycle helps with customization:</p> <pre><code>1. __init__()         - Scope created\n2. enter()            - Scope activated (context var set)\n3. [intents buffered] - Code executes, enqueue() calls buffered\n4. exit()             - Scope deactivated (context var reset)\n5. should_flush()     - Decide terminal action\n6. flush()            - Apply policy, call _dispatch_all()\n7. _dispatch_all()    - Execute intents\n</code></pre>"},{"location":"extending/custom-scopes/#common-mistakes","title":"Common Mistakes","text":""},{"location":"extending/custom-scopes/#dont-override-flush","title":"\u274c Don't Override flush()","text":"<pre><code># \u274c Bad - breaks internal state management\nclass BadScope(Scope):\n    def flush(self):\n        # Custom logic\n        ...\n</code></pre> <p>Instead: Override <code>should_flush()</code> or <code>_dispatch_all()</code>.</p>"},{"location":"extending/custom-scopes/#dont-forget-to-call-super","title":"\u274c Don't Forget to Call super()","text":"<pre><code># \u274c Bad - breaks buffer management\nclass BadScope(Scope):\n    def _add(self, intent):\n        my_custom_buffer.append(intent)  # Forgot super()!\n</code></pre> <p>Fix:</p> <pre><code>class GoodScope(Scope):\n    def _add(self, intent):\n        super()._add(intent)  # Add to internal buffer\n        my_custom_buffer.append(intent)  # Plus custom logic\n</code></pre>"},{"location":"extending/custom-scopes/#dont-mutate-intents-list","title":"\u274c Don't Mutate Intents List","text":"<pre><code># \u274c Bad - mutates caller's list\ndef before_descendant_flushes(self, exiting_scope, intents):\n    intents.append(new_intent)  # Mutates original!\n    return intents\n</code></pre> <p>Fix:</p> <pre><code>def before_descendant_flushes(self, exiting_scope, intents):\n    return intents + [new_intent]  # Return new list\n</code></pre>"},{"location":"extending/custom-scopes/#testing-custom-scopes","title":"Testing Custom Scopes","text":"<pre><code>def test_always_flush_scope():\n    with airlock.scope(_cls=AlwaysFlushScope) as s:\n        airlock.enqueue(task)\n        raise Exception()\n\n    # Verify it flushed despite exception\n    assert s.is_flushed\n    assert not s.is_discarded\n</code></pre>"},{"location":"extending/custom-scopes/#next-steps","title":"Next Steps","text":"<ul> <li>Custom Policies - Write custom policies</li> <li>Custom Executors - Write custom executors</li> <li>Scope API Reference - Complete scope API</li> </ul>"},{"location":"guide/basic-usage/","title":"Basic Usage","text":"<p>Core patterns for everyday use.</p>"},{"location":"guide/basic-usage/#the-basic-pattern","title":"The Basic Pattern","text":"<pre><code>import airlock\n\n# 1. Express intent with airlock.enqueue()\ndef process_order(order_id):\n    order = get_order(order_id)\n    order.status = \"processed\"\n    save(order)\n\n    airlock.enqueue(notify_warehouse, order_id=order_id)\n    airlock.enqueue(send_confirmation, order_id=order_id)\n\n# 2. Wrap in a scope\nwith airlock.scope():\n    process_order(123)\n# Effects dispatch here\n</code></pre>"},{"location":"guide/basic-usage/#scope-lifecycle","title":"Scope Lifecycle","text":"<p>On normal exit: calls <code>flush()</code> - intents dispatch</p> <p>On exception: calls <code>discard()</code> - intents dropped</p> <pre><code>with airlock.scope():\n    airlock.enqueue(task_a)\n    raise Exception()  # Scope discards, task_a doesn't run\n</code></pre>"},{"location":"guide/basic-usage/#local-policy-context","title":"Local Policy Context","text":"<p>Apply policy to a region without creating a new scope:</p> <pre><code>with airlock.scope():\n    airlock.enqueue(task_a)  # Will dispatch\n\n    with airlock.policy(airlock.DropAll()):\n        airlock.enqueue(task_b)  # Won't dispatch\n\n    airlock.enqueue(task_c)  # Will dispatch\n</code></pre> <p>All three intents go to the same buffer. Policy is captured per-intent.</p>"},{"location":"guide/basic-usage/#inspecting-the-buffer","title":"Inspecting the Buffer","text":"<pre><code>with airlock.scope() as s:\n    do_stuff()\n\n    # Check what's buffered\n    for intent in s.intents:\n        print(f\"{intent.name}: {intent.args}, {intent.kwargs}\")\n</code></pre>"},{"location":"guide/basic-usage/#pass-dispatch-options","title":"Pass Dispatch Options","text":"<pre><code>airlock.enqueue(\n    send_email,\n    user_id=123,\n    _dispatch_options={\"countdown\": 60, \"queue\": \"emails\"}\n)\n</code></pre> <p>Options are executor-specific (Celery, django-q, etc.)</p>"},{"location":"guide/basic-usage/#get-current-scope","title":"Get Current Scope","text":"<pre><code>scope = airlock.get_current_scope()\nif scope:\n    print(f\"In scope with {len(scope.intents)} intents buffered\")\n</code></pre>"},{"location":"guide/basic-usage/#error-handling","title":"Error Handling","text":"<p>No scope:</p> <pre><code>airlock.enqueue(task)  # Raises NoScopeError\n</code></pre> <p>This is intentional - side effects require explicit boundaries.</p> <p>Policy violation:</p> <pre><code>with airlock.scope(policy=airlock.AssertNoEffects()):\n    airlock.enqueue(task)  # Raises PolicyViolation immediately\n</code></pre>"},{"location":"guide/basic-usage/#next-steps","title":"Next Steps","text":"<ul> <li>Policies - Built-in and custom policies</li> <li>Nested scopes - Composition patterns</li> <li>Dispatch - Executors and options</li> </ul>"},{"location":"guide/dispatch/","title":"Dispatch Guide","text":"<p>How side effects are executed: executors, options, and dispatch flow.</p>"},{"location":"guide/dispatch/#the-dispatch-pipeline","title":"The Dispatch Pipeline","text":"<pre><code>airlock.enqueue(task, ...)\n    \u2193\nBuffer intent\n    \u2193\n[Scope exits]\n    \u2193\nApply policies (filter)\n    \u2193\nExecute via executor\n    \u2193\ntask(*args, **kwargs)\n</code></pre>"},{"location":"guide/dispatch/#executors","title":"Executors","text":"<p>Executors control how intents execute.</p>"},{"location":"guide/dispatch/#sync_executor-default","title":"sync_executor (Default)","text":"<pre><code>from airlock.integrations.executors.sync import sync_executor\n\nwith airlock.scope(executor=sync_executor):\n    airlock.enqueue(my_function, arg=123)\n# Executes: my_function(arg=123)\n</code></pre> <p>Runs synchronously at flush time.</p>"},{"location":"guide/dispatch/#celery_executor","title":"celery_executor","text":"<pre><code>from airlock.integrations.executors.celery import celery_executor\n\nwith airlock.scope(executor=celery_executor):\n    airlock.enqueue(celery_task, arg=123)\n    # Dispatches: celery_task.delay(arg=123)\n\n    airlock.enqueue(plain_function, arg=123)\n    # Falls back to sync: plain_function(arg=123)\n</code></pre> <p>Checks for <code>.delay()</code> / <code>.apply_async()</code>, falls back to sync.</p>"},{"location":"guide/dispatch/#django_q_executor","title":"django_q_executor","text":"<pre><code>from airlock.integrations.executors.django_q import django_q_executor\n\nwith airlock.scope(executor=django_q_executor):\n    airlock.enqueue(any_function, arg=123)\n# Dispatches: async_task(any_function, arg=123)\n</code></pre> <p>Always uses <code>async_task()</code> for all callables.</p>"},{"location":"guide/dispatch/#huey_executor","title":"huey_executor","text":"<pre><code>from airlock.integrations.executors.huey import huey_executor\n\nwith airlock.scope(executor=huey_executor):\n    airlock.enqueue(huey_task, arg=123)\n    # Dispatches: huey_task.schedule(args=(arg,), kwargs={})\n</code></pre> <p>Checks for <code>.schedule()</code>, falls back to sync.</p>"},{"location":"guide/dispatch/#dramatiq_executor","title":"dramatiq_executor","text":"<pre><code>from airlock.integrations.executors.dramatiq import dramatiq_executor\n\nwith airlock.scope(executor=dramatiq_executor):\n    airlock.enqueue(dramatiq_actor, arg=123)\n    # Dispatches: dramatiq_actor.send(arg=123)\n</code></pre> <p>Checks for <code>.send()</code>, falls back to sync.</p>"},{"location":"guide/dispatch/#dispatch-options","title":"Dispatch Options","text":"<p>Pass queue-specific options via <code>_dispatch_options</code>:</p> <pre><code>airlock.enqueue(\n    send_email,\n    user_id=123,\n    _dispatch_options={\n        \"countdown\": 60,      # Delay 60 seconds\n        \"queue\": \"emails\",    # Use specific queue\n        \"priority\": 9,        # High priority\n    }\n)\n</code></pre>"},{"location":"guide/dispatch/#celery-options","title":"Celery Options","text":"<p>With <code>celery_executor</code>:</p> <pre><code>airlock.enqueue(\n    task,\n    arg,\n    _dispatch_options={\n        \"countdown\": 60,           # Delay in seconds\n        \"eta\": datetime(...),      # Specific datetime\n        \"queue\": \"high-priority\",  # Queue name\n        \"priority\": 9,             # 0-9 (0=lowest, 9=highest)\n        \"expires\": 3600,           # Expire after 1 hour\n        \"retry\": True,             # Enable retries\n        \"retry_policy\": {...},     # Retry configuration\n    }\n)\n</code></pre> <p>Celery docs \u2192</p>"},{"location":"guide/dispatch/#django-q-options","title":"django-q Options","text":"<p>With <code>django_q_executor</code>:</p> <pre><code>airlock.enqueue(\n    task,\n    arg,\n    _dispatch_options={\n        \"group\": \"batch-jobs\",     # Task group\n        \"timeout\": 300,            # Timeout in seconds\n        \"hook\": \"my_hook\",         # Post-execution hook\n        \"retry\": 3,                # Retry count\n        \"sync\": False,             # Run async\n    }\n)\n</code></pre> <p>django-q docs \u2192</p>"},{"location":"guide/dispatch/#huey-options","title":"Huey Options","text":"<p>With <code>huey_executor</code>:</p> <pre><code>airlock.enqueue(\n    task,\n    arg,\n    _dispatch_options={\n        \"delay\": 60,              # Delay in seconds\n        \"eta\": datetime(...),     # Specific datetime\n        \"retries\": 3,             # Number of retries\n    }\n)\n</code></pre> <p>Huey docs \u2192</p>"},{"location":"guide/dispatch/#dramatiq-options","title":"Dramatiq Options","text":"<p>With <code>dramatiq_executor</code>:</p> <pre><code>airlock.enqueue(\n    actor,\n    arg,\n    _dispatch_options={\n        \"delay\": 60000,           # Delay in milliseconds\n        \"max_retries\": 3,         # Retry limit\n        \"priority\": 10,           # Message priority\n    }\n)\n</code></pre> <p>Dramatiq docs \u2192</p>"},{"location":"guide/dispatch/#configuring-default-executor","title":"Configuring Default Executor","text":""},{"location":"guide/dispatch/#via-django-settings","title":"Via Django Settings","text":"<pre><code># settings.py\nAIRLOCK = {\n    \"EXECUTOR\": \"airlock.integrations.executors.celery.celery_executor\",\n}\n</code></pre> <p>Now all <code>DjangoScope</code> instances use Celery by default.</p>"},{"location":"guide/dispatch/#via-custom-scope","title":"Via Custom Scope","text":"<pre><code>from airlock.integrations.executors.celery import celery_executor\n\nclass CeleryScope(Scope):\n    def __init__(self, *args, **kwargs):\n        kwargs.setdefault('executor', celery_executor)\n        super().__init__(*args, **kwargs)\n\nwith airlock.scope(_cls=CeleryScope):\n    airlock.enqueue(task)  # Uses Celery\n</code></pre>"},{"location":"guide/dispatch/#dispatch-flow","title":"Dispatch Flow","text":""},{"location":"guide/dispatch/#1-enqueue-phase","title":"1. Enqueue Phase","text":"<pre><code>with airlock.scope() as s:\n    airlock.enqueue(task_a)\n    airlock.enqueue(task_b)\n    # Intents buffered in memory\n</code></pre>"},{"location":"guide/dispatch/#2-policy-phase-at-flush","title":"2. Policy Phase (at flush)","text":"<pre><code># Scope applies policy to each intent\nfor intent in intents:\n    # Check local policies\n    if not intent.passes_local_policies():\n        continue  # Drop\n\n    # Check scope policy\n    if not scope.policy.allows(intent):\n        continue  # Drop\n\n    # Intent allowed\n    allowed_intents.append(intent)\n</code></pre>"},{"location":"guide/dispatch/#3-dispatch-phase","title":"3. Dispatch Phase","text":"<pre><code># Scope calls _dispatch_all()\nfor intent in allowed_intents:\n    executor(intent)  # Execute via configured executor\n</code></pre>"},{"location":"guide/dispatch/#error-handling","title":"Error Handling","text":""},{"location":"guide/dispatch/#dispatch-errors-are-fail-fast","title":"Dispatch Errors are Fail-Fast","text":"<p>If an executor raises during dispatch, flush aborts:</p> <pre><code>with airlock.scope():\n    airlock.enqueue(task_a)  # Will execute\n    airlock.enqueue(task_b)  # Raises (broker down)\n    airlock.enqueue(task_c)  # Never attempted\n\n# task_a: \u2705 dispatched\n# task_b: \u274c raised exception\n# task_c: \u26a0\ufe0f  never dispatched (flush aborted)\n</code></pre> <p>This is intentional - infrastructure failures should fail loudly.</p>"},{"location":"guide/dispatch/#for-async-executors","title":"For Async Executors","text":"<p>With Celery/django-q/etc., \"dispatch\" means \"submit to queue\", not \"run the task\":</p> <pre><code>with airlock.scope(executor=celery_executor):\n    airlock.enqueue(task)\n# If broker is available: succeeds (task queued)\n# If broker is down: raises (flush aborts)\n</code></pre> <p>Task execution happens asynchronously. Failures are handled by the task queue, not airlock.</p>"},{"location":"guide/dispatch/#custom-executors","title":"Custom Executors","text":"<p>Write your own for custom dispatch:</p> <pre><code>def my_executor(intent):\n    \"\"\"Execute via custom mechanism.\"\"\"\n    logger.info(f\"Executing: {intent.name}\")\n    intent.task(*intent.args, **intent.kwargs)\n\nwith airlock.scope(executor=my_executor):\n    airlock.enqueue(task)\n</code></pre> <p>See Custom Executors Guide for examples.</p>"},{"location":"guide/dispatch/#common-patterns","title":"Common Patterns","text":""},{"location":"guide/dispatch/#pattern-1-conditional-executor","title":"Pattern 1: Conditional Executor","text":"<pre><code>def smart_executor(intent):\n    \"\"\"Route to different backends based on intent.\"\"\"\n    if intent.dispatch_options.get(\"heavy\"):\n        celery_executor(intent)\n    else:\n        sync_executor(intent)\n\nwith airlock.scope(executor=smart_executor):\n    airlock.enqueue(light_task)                            # Sync\n    airlock.enqueue(heavy_task, _dispatch_options={\"heavy\": True})  # Celery\n</code></pre>"},{"location":"guide/dispatch/#pattern-2-fallback-executor","title":"Pattern 2: Fallback Executor","text":"<pre><code>def fallback_executor(intent):\n    \"\"\"Try Celery, fall back to sync if unavailable.\"\"\"\n    try:\n        celery_executor(intent)\n    except Exception:\n        logger.warning(f\"Celery unavailable, running {intent.name} sync\")\n        sync_executor(intent)\n</code></pre>"},{"location":"guide/dispatch/#pattern-3-batching-executor","title":"Pattern 3: Batching Executor","text":"<pre><code>class BatchingExecutor:\n    def __init__(self, batch_size=10):\n        self.batch = []\n        self.batch_size = batch_size\n\n    def __call__(self, intent):\n        self.batch.append(intent)\n        if len(self.batch) &gt;= self.batch_size:\n            self.flush()\n\n    def flush(self):\n        # Execute batch\n        for intent in self.batch:\n            intent.task(*intent.args, **intent.kwargs)\n        self.batch.clear()\n</code></pre>"},{"location":"guide/dispatch/#next-steps","title":"Next Steps","text":"<ul> <li>Custom Executors - Write your own</li> <li>Executors API - Complete executor reference (if exists)</li> <li>Policies Guide - Filter what executes</li> </ul>"},{"location":"guide/nested-scopes/","title":"Nested Scopes Guide","text":"<p>Practical patterns for composing scopes safely.</p>"},{"location":"guide/nested-scopes/#the-default-capture","title":"The Default: Capture","text":"<p>Nested scopes are captured by default:</p> <pre><code>with airlock.scope() as outer:\n    airlock.enqueue(task_a)\n\n    with airlock.scope() as inner:\n        airlock.enqueue(task_b)\n    # task_b captured by outer (doesn't dispatch)\n\n# Both task_a and task_b dispatch together\n</code></pre> <p>This is compositional safety - parent scopes have authority over nested scopes.</p>"},{"location":"guide/nested-scopes/#why-capture-matters","title":"Why Capture Matters","text":"<p>Without capture, library code could bypass your boundaries:</p> <pre><code># Your code\nwith TransactionScope():\n    order.save()\n    payment_lib.process(order)  # Uses airlock internally\n    # If nested scope flushed independently, effects escaped before commit!\n</code></pre> <p>With capture:</p> <pre><code># Your code\nwith TransactionScope():\n    order.save()\n    payment_lib.process(order)  # Nested scope captured\n    # Nothing dispatches yet\n# All effects dispatch after commit \u2713\n</code></pre>"},{"location":"guide/nested-scopes/#provenance-tracking","title":"Provenance Tracking","text":"<p>Distinguish your intents from captured intents:</p> <pre><code>with airlock.scope() as outer:\n    airlock.enqueue(task_a)  # Own intent\n\n    with airlock.scope():\n        airlock.enqueue(task_b)  # Captured intent\n\n    print(f\"Own: {len(outer.own_intents)}\")          # 1\n    print(f\"Captured: {len(outer.captured_intents)}\")  # 1\n    print(f\"Total: {len(outer.intents)}\")            # 2\n</code></pre> <p>Use for: - Debugging (\"where did this come from?\") - Metrics (\"how many intents from nested scopes?\") - Different handling for own vs captured</p>"},{"location":"guide/nested-scopes/#common-patterns","title":"Common Patterns","text":""},{"location":"guide/nested-scopes/#pattern-1-transaction-boundary","title":"Pattern 1: Transaction Boundary","text":"<p>Ensure all effects wait for commit:</p> <pre><code>from airlock.integrations.django import DjangoScope\n\nwith transaction.atomic():\n    with airlock.scope(_cls=DjangoScope):\n        order.save()\n        third_party_lib.process(order)  # May use nested scopes\n    # Nothing dispatches yet\n# All effects dispatch after commit\n</code></pre>"},{"location":"guide/nested-scopes/#pattern-2-multi-step-atomic-operation","title":"Pattern 2: Multi-Step Atomic Operation","text":"<pre><code>def checkout_cart(cart_id):\n    \"\"\"Ensure all steps dispatch together atomically.\"\"\"\n    with airlock.scope():\n        validate_inventory(cart_id)     # May have nested scopes\n        charge_payment(cart_id)         # May have nested scopes\n        send_confirmation(cart_id)      # May have nested scopes\n    # All effects from all steps dispatch together\n</code></pre>"},{"location":"guide/nested-scopes/#pattern-3-batching-from-nested-operations","title":"Pattern 3: Batching from Nested Operations","text":"<p>Collect specific effects for batch processing:</p> <pre><code>class EmailBatcher(Scope):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.emails = []\n\n    def before_descendant_flushes(self, exiting_scope, intents):\n        # Separate emails from other intents\n        for intent in intents:\n            if 'email' in intent.name:\n                self.emails.append(intent)\n\n        # Allow non-emails through\n        return [i for i in intents if 'email' not in i.name]\n\nwith EmailBatcher() as batcher:\n    process_bulk_orders()  # Nested code can enqueue emails\n    # Non-email effects dispatched immediately\n\n# Send all emails in one batch\nsend_batch_emails(batcher.emails)\n</code></pre>"},{"location":"guide/nested-scopes/#pattern-4-ordering-control","title":"Pattern 4: Ordering Control","text":"<p>Ensure effects execute in the right order:</p> <pre><code>class DBBeforeCacheScope(Scope):\n    \"\"\"DB writes execute now, cache updates execute later.\"\"\"\n\n    def before_descendant_flushes(self, exiting_scope, intents):\n        # Let DB writes through immediately\n        db_writes = [i for i in intents if 'db' in i.name]\n        return db_writes\n\nwith DBBeforeCacheScope():\n    with airlock.scope():\n        airlock.enqueue(db_write)\n        airlock.enqueue(update_cache)\n    # db_write executes here (allowed through)\n\n# update_cache executes here (was captured)\n</code></pre>"},{"location":"guide/nested-scopes/#pattern-5-independent-nested-scopes-opt-out","title":"Pattern 5: Independent Nested Scopes (Opt-Out)","text":"<p>Allow nested scopes to flush independently:</p> <pre><code>class IndependentScope(Scope):\n    def before_descendant_flushes(self, exiting_scope, intents):\n        return intents  # Allow all through\n\nwith IndependentScope():\n    with airlock.scope():\n        airlock.enqueue(task)\n    # task dispatches here (not captured)\n</code></pre> <p>Use sparingly - breaks compositional safety!</p>"},{"location":"guide/nested-scopes/#inspecting-nested-behavior","title":"Inspecting Nested Behavior","text":""},{"location":"guide/nested-scopes/#check-if-intent-is-captured","title":"Check if intent is captured","text":"<pre><code>with airlock.scope() as outer:\n    airlock.enqueue(task_a)\n\n    with airlock.scope() as inner:\n        airlock.enqueue(task_b)\n\n    # task_b is in outer's captured_intents\n    assert task_b_intent in outer.captured_intents\n</code></pre>"},{"location":"guide/nested-scopes/#audit-nested-dispatch","title":"Audit nested dispatch","text":"<pre><code>with airlock.scope() as s:\n    complex_operation()\n\n    print(f\"Total effects: {len(s.intents)}\")\n    print(f\"From this scope: {len(s.own_intents)}\")\n    print(f\"From nested scopes: {len(s.captured_intents)}\")\n</code></pre>"},{"location":"guide/nested-scopes/#policy-inheritance","title":"Policy Inheritance","text":"<p>Nested scopes inherit policy from parent? No, each scope has its own policy:</p> <pre><code>with airlock.scope(policy=DropAll()):\n    airlock.enqueue(task_a)  # Dropped by outer policy\n\n    with airlock.scope(policy=AllowAll()):\n        airlock.enqueue(task_b)  # Allowed by inner policy, captured by outer\n    # Inner scope would flush task_b, but outer captures it\n\n# Outer scope applies DropAll to captured task_b\n# Result: Both task_a and task_b dropped\n</code></pre> <p>Each scope's policy applies to its own flush decision, but captured intents are subject to the parent's policy when the parent flushes.</p>"},{"location":"guide/nested-scopes/#testing-with-nested-scopes","title":"Testing with Nested Scopes","text":""},{"location":"guide/nested-scopes/#test-that-library-uses-scopes","title":"Test that library uses scopes","text":"<pre><code>def test_library_buffers_effects():\n    with airlock.scope() as s:\n        third_party_lib.do_something()\n\n    # Verify library buffered effects (via nested scopes)\n    assert len(s.captured_intents) &gt; 0\n</code></pre>"},{"location":"guide/nested-scopes/#test-atomic-behavior","title":"Test atomic behavior","text":"<pre><code>def test_checkout_is_atomic():\n    with airlock.scope() as s:\n        checkout_cart(123)\n\n    # All steps buffered together\n    assert len(s.intents) &gt;= 3  # inventory + payment + email\n</code></pre>"},{"location":"guide/nested-scopes/#next-steps","title":"Next Steps","text":"<ul> <li>How It Composes - Deep dive on composition</li> <li>Custom Scopes - Implementing <code>before_descendant_flushes()</code></li> </ul>"},{"location":"guide/policies/","title":"Policies Guide","text":"<p>Policies control what side effects execute. They filter, observe, and validate intents.</p>"},{"location":"guide/policies/#built-in-policies","title":"Built-in Policies","text":""},{"location":"guide/policies/#allowall-default","title":"AllowAll (Default)","text":"<pre><code>with airlock.scope(policy=airlock.AllowAll()):\n    airlock.enqueue(anything)  # Always dispatches\n</code></pre> <p>This is the default - no filtering.</p>"},{"location":"guide/policies/#dropall","title":"DropAll","text":"<pre><code>with airlock.scope(policy=airlock.DropAll()):\n    airlock.enqueue(send_email)\n    airlock.enqueue(charge_card)\n    # Nothing dispatches\n</code></pre> <p>Use for: - Dry-run modes (<code>--dry-run</code> flag) - Testing business logic without side effects - Suppressing notifications in backfills</p>"},{"location":"guide/policies/#assertnoeffects","title":"AssertNoEffects","text":"<pre><code>with airlock.scope(policy=airlock.AssertNoEffects()):\n    pure_calculation()  # OK\n    airlock.enqueue(task)  # Raises PolicyViolation immediately\n</code></pre> <p>Use for: - Test assertions - Ensuring code paths are pure - Catching unexpected side effects</p>"},{"location":"guide/policies/#blocktasks","title":"BlockTasks","text":"<p>Block specific tasks by name:</p> <pre><code>policy = airlock.BlockTasks({\"myapp.tasks:send_email\", \"myapp.tasks:send_sms\"})\n\nwith airlock.scope(policy=policy):\n    airlock.enqueue(send_email)       # Dropped\n    airlock.enqueue(send_sms)          # Dropped\n    airlock.enqueue(log_event)         # Dispatches\n</code></pre> <p>Fail fast (raise on enqueue instead of silently dropping):</p> <pre><code>policy = airlock.BlockTasks({\"dangerous_task\"}, raise_on_enqueue=True)\n\nwith airlock.scope(policy=policy):\n    airlock.enqueue(dangerous_task)  # Raises PolicyViolation immediately\n</code></pre> <p>Use for: - Admin panels (suppress customer notifications) - Backfills (block emails, allow analytics) - Feature flags (disable specific tasks)</p>"},{"location":"guide/policies/#logonflush","title":"LogOnFlush","text":"<pre><code>import logging\nlogger = logging.getLogger(__name__)\n\nwith airlock.scope(policy=airlock.LogOnFlush(logger)):\n    airlock.enqueue(task_a)\n    airlock.enqueue(task_b)\n# Logs each dispatch\n</code></pre> <p>Use for: - Debugging - Audit trails - Observability</p>"},{"location":"guide/policies/#compositepolicy","title":"CompositePolicy","text":"<p>Combine multiple policies:</p> <pre><code>policy = airlock.CompositePolicy(\n    airlock.LogOnFlush(logger),\n    airlock.BlockTasks({\"expensive_task\"}),\n)\n\nwith airlock.scope(policy=policy):\n    airlock.enqueue(cheap_task)      # Logged + dispatched\n    airlock.enqueue(expensive_task)  # Logged but blocked\n</code></pre> <p>All policies must allow for the intent to execute.</p>"},{"location":"guide/policies/#local-policy-contexts","title":"Local Policy Contexts","text":"<p>Apply policy to a region without creating a new scope:</p> <pre><code>with airlock.scope():\n    airlock.enqueue(task_a)  # Will dispatch\n\n    with airlock.policy(airlock.DropAll()):\n        airlock.enqueue(task_b)  # Won't dispatch\n\n    airlock.enqueue(task_c)  # Will dispatch\n</code></pre> <p>All three intents go to the same buffer. Policy is captured per-intent.</p>"},{"location":"guide/policies/#common-patterns","title":"Common Patterns","text":""},{"location":"guide/policies/#pattern-1-dry-run-flag","title":"Pattern 1: Dry-Run Flag","text":"<pre><code>def backfill_orders(dry_run=False):\n    policy = airlock.DropAll() if dry_run else airlock.AllowAll()\n\n    with airlock.scope(policy=policy):\n        for order in Order.objects.all():\n            order.process()\n    # Nothing dispatches if dry_run=True\n</code></pre>"},{"location":"guide/policies/#pattern-2-suppress-notifications-in-admin","title":"Pattern 2: Suppress Notifications in Admin","text":"<pre><code># middleware.py\nclass AdminAirlockMiddleware(AirlockMiddleware):\n    def get_policy(self, request):\n        if request.user.is_staff:\n            return airlock.BlockTasks({\"send_customer_email\"})\n        return airlock.AllowAll()\n</code></pre>"},{"location":"guide/policies/#pattern-3-feature-flags","title":"Pattern 3: Feature Flags","text":"<pre><code>from django.conf import settings\n\ndef get_policy():\n    blocked = set()\n    if not settings.EMAILS_ENABLED:\n        blocked.add(\"send_email\")\n    if not settings.SMS_ENABLED:\n        blocked.add(\"send_sms\")\n\n    return airlock.BlockTasks(blocked) if blocked else airlock.AllowAll()\n\nwith airlock.scope(policy=get_policy()):\n    ...\n</code></pre>"},{"location":"guide/policies/#pattern-4-environment-based","title":"Pattern 4: Environment-Based","text":"<pre><code>if settings.ENV == \"development\":\n    policy = airlock.DropAll()  # No side effects in dev\nelif settings.ENV == \"staging\":\n    policy = airlock.BlockTasks({\"send_customer_email\"})  # No customer emails\nelse:\n    policy = airlock.AllowAll()  # Production\n</code></pre>"},{"location":"guide/policies/#pattern-5-conditional-suppression","title":"Pattern 5: Conditional Suppression","text":"<pre><code>def process_order(order, suppress_emails=False):\n    with airlock.scope():\n        order.status = \"processed\"\n        order.save()\n\n        if not suppress_emails:\n            airlock.enqueue(send_confirmation, order.id)\n\n        airlock.enqueue(update_analytics, order.id)\n</code></pre> <p>Or with policy:</p> <pre><code>def process_order(order, suppress_emails=False):\n    policy = airlock.BlockTasks({\"send_confirmation\"}) if suppress_emails else airlock.AllowAll()\n\n    with airlock.scope(policy=policy):\n        order.process()  # Model handles side effects\n</code></pre>"},{"location":"guide/policies/#policy-behavior","title":"Policy Behavior","text":""},{"location":"guide/policies/#when-policies-run","title":"When Policies Run","text":"<p><code>on_enqueue()</code> - Called immediately when <code>airlock.enqueue()</code> is invoked:</p> <pre><code>class LoggingPolicy:\n    def on_enqueue(self, intent):\n        print(f\"Enqueuing: {intent.name}\")\n\nwith airlock.scope(policy=LoggingPolicy()):\n    airlock.enqueue(task)  # Prints \"Enqueuing: task\"\n</code></pre> <p><code>allows()</code> - Called at flush time for each intent:</p> <pre><code>class FilterPolicy:\n    def allows(self, intent):\n        return \"safe\" in intent.name\n\nwith airlock.scope(policy=FilterPolicy()):\n    airlock.enqueue(safe_task)    # Allowed\n    airlock.enqueue(unsafe_task)  # Dropped\n</code></pre>"},{"location":"guide/policies/#fail-fast-vs-silent-drop","title":"Fail Fast vs Silent Drop","text":"<p>Fail fast (raise in <code>on_enqueue</code>):</p> <pre><code>class AssertNoEffects:\n    def on_enqueue(self, intent):\n        raise PolicyViolation(f\"Unexpected effect: {intent.name}\")\n\n# Raises immediately at enqueue()\n</code></pre> <p>Silent drop (return False in <code>allows</code>):</p> <pre><code>class DropAll:\n    def allows(self, intent):\n        return False\n\n# Buffers, then drops at flush\n</code></pre> <p>When to use which: - Fail fast: Tests, catching bugs - Silent drop: Production filtering, dry-run modes</p>"},{"location":"guide/policies/#next-steps","title":"Next Steps","text":"<ul> <li>Custom Policies - Write your own policies</li> <li>Nested Scopes - Policy inheritance and composition</li> </ul>"},{"location":"integrations/celery/task-wrapper/","title":"Celery Task Wrapper (AirlockTask)","text":"<p>Deep dive on wrapping Celery tasks with automatic scoping.</p>"},{"location":"integrations/celery/task-wrapper/#basic-usage","title":"Basic Usage","text":"<p>Use <code>AirlockTask</code> as base class to auto-scope task execution:</p> <pre><code>from celery import Celery\nfrom airlock.integrations.celery import AirlockTask\n\napp = Celery('myapp')\n\n@app.task(base=AirlockTask)\ndef process_order(order_id):\n    order = fetch_order(order_id)\n    order.status = \"processed\"\n    save_order(order)\n\n    # These are buffered within the task's scope\n    airlock.enqueue(send_email, order_id=order_id)\n    airlock.enqueue(notify_warehouse, order_id=order_id)\n    # Flushes when task completes successfully\n</code></pre>"},{"location":"integrations/celery/task-wrapper/#what-it-does","title":"What It Does","text":"<p><code>AirlockTask</code> wraps task execution in a scope:</p> <pre><code># Without AirlockTask\ndef my_task():\n    do_work()\n    airlock.enqueue(followup)  # NoScopeError!\n\n# With AirlockTask\n@app.task(base=AirlockTask)\ndef my_task():\n    do_work()\n    airlock.enqueue(followup)  # \u2713 Buffered\n    # Dispatches when task exits\n</code></pre>"},{"location":"integrations/celery/task-wrapper/#lifecycle","title":"Lifecycle","text":"<pre><code>Task starts\n    \u2193\nScope created and activated\n    \u2193\nTask body executes\n    \u2193\nTask completes (success or error)\n    \u2193\nScope exits\n    \u2193\nShould flush? (default: flush on success, discard on error)\n    \u2193\nEffects dispatch (if flushed)\n</code></pre>"},{"location":"integrations/celery/task-wrapper/#customizing-behavior","title":"Customizing Behavior","text":""},{"location":"integrations/celery/task-wrapper/#custom-policy","title":"Custom Policy","text":"<pre><code>class MyAirlockTask(AirlockTask):\n    def get_policy(self):\n        # Log all side effects\n        return airlock.LogOnFlush(logger)\n\n@app.task(base=MyAirlockTask)\ndef my_task():\n    ...\n</code></pre>"},{"location":"integrations/celery/task-wrapper/#custom-executor","title":"Custom Executor","text":"<pre><code>class MyAirlockTask(AirlockTask):\n    def get_executor(self):\n        # Use django-q for nested tasks\n        from airlock.integrations.executors.django_q import django_q_executor\n        return django_q_executor\n\n@app.task(base=MyAirlockTask)\ndef my_task():\n    airlock.enqueue(nested_task)  # Dispatches via django-q\n</code></pre>"},{"location":"integrations/celery/task-wrapper/#custom-flush-behavior","title":"Custom Flush Behavior","text":"<pre><code>class AlwaysFlushTask(AirlockTask):\n    def should_flush(self, error):\n        # Flush even on error (for error notification tasks)\n        return True\n\n@app.task(base=AlwaysFlushTask)\ndef send_error_alert():\n    airlock.enqueue(notify_oncall, severity=\"critical\")\n    raise Exception(\"Something broke\")\n    # Still dispatches notification despite exception\n</code></pre>"},{"location":"integrations/celery/task-wrapper/#combining-with-django","title":"Combining with Django","text":"<p>Use both Django scoping and Celery scoping:</p> <pre><code># settings.py\nMIDDLEWARE = [\"airlock.integrations.django.AirlockMiddleware\"]\n\nAIRLOCK = {\n    \"EXECUTOR\": \"airlock.integrations.executors.celery.celery_executor\",\n}\n</code></pre> <pre><code># tasks.py\n@app.task(base=AirlockTask)\ndef process_order(order_id):\n    # This task runs in its own scope\n    order = Order.objects.get(id=order_id)\n    order.process()\n    airlock.enqueue(send_email, order_id)\n    # Email dispatches when task completes\n\n# views.py (has middleware scope)\ndef checkout(request):\n    order = create_order(request)\n    airlock.enqueue(process_order, order_id=order.id)\n    # process_order dispatches when request completes\n</code></pre> <p>Result: Nested scopes! Request scope captures task dispatch, task scope captures email dispatch.</p>"},{"location":"integrations/celery/task-wrapper/#task-chaining","title":"Task Chaining","text":"<p>Tasks can trigger other tasks:</p> <pre><code>@app.task(base=AirlockTask)\ndef step_1(data):\n    result = process(data)\n    airlock.enqueue(step_2, result)\n    return result\n\n@app.task(base=AirlockTask)\ndef step_2(data):\n    final = finalize(data)\n    airlock.enqueue(step_3, final)\n    return final\n\n@app.task(base=AirlockTask)\ndef step_3(data):\n    cleanup(data)\n</code></pre> <p>Each task has its own scope. Effects dispatch when each task completes.</p>"},{"location":"integrations/celery/task-wrapper/#retries","title":"Retries","text":"<p>Airlock respects Celery retries:</p> <pre><code>@app.task(base=AirlockTask, max_retries=3)\ndef flaky_task(order_id):\n    try:\n        risky_operation()\n        airlock.enqueue(success_notification)\n    except Exception as e:\n        # Scope discards (task failed)\n        raise self.retry(exc=e)\n</code></pre> <p>Behavior: - On retry: scope discards (error path) - On final success: scope flushes - On final failure: scope discards</p> <p>Effects only dispatch when task ultimately succeeds.</p>"},{"location":"integrations/celery/task-wrapper/#testing","title":"Testing","text":"<p>Test tasks without running broker:</p> <pre><code>def test_task_side_effects():\n    with airlock.scope(policy=airlock.AssertNoEffects()):\n        process_order(123)  # Raises if any side effects\n\ndef test_task_effects():\n    # Run task body directly (not via .delay())\n    with airlock.scope() as s:\n        process_order(123)\n\n    # Inspect buffered effects\n    assert len(s.intents) == 2\n    assert s.intents[0].task.__name__ == \"send_email\"\n</code></pre>"},{"location":"integrations/celery/task-wrapper/#comparison-airlocktask-vs-install_global_intercept","title":"Comparison: AirlockTask vs install_global_intercept","text":"Feature AirlockTask install_global_intercept Explicit \u2705 Opt-in per task \u274c All tasks affected Safe \u2705 No monkey-patching \u274c Global side effects Migration Medium effort \u26a0\ufe0f Quick but not steady-state Control \u2705 Per-task customization \u274c Global behavior <p>Recommendation: Use <code>AirlockTask</code> for production. Use <code>install_global_intercept</code> for migration only.</p>"},{"location":"integrations/celery/task-wrapper/#next-steps","title":"Next Steps","text":"<ul> <li>Migration Guide - Migrating existing tasks</li> <li>Custom Scopes - Advanced scope customization</li> </ul>"},{"location":"migration/from-direct-delay/","title":"Migrating from Direct .delay() Calls","text":"<p>How to migrate an existing codebase from direct Celery <code>.delay()</code> calls to airlock.</p>"},{"location":"migration/from-direct-delay/#the-challenge","title":"The Challenge","text":"<p>You have code like this scattered everywhere:</p> <pre><code>class Order(models.Model):\n    def save(self, *args, **kwargs):\n        super().save(*args, **kwargs)\n        notify_warehouse.delay(self.id)\n        send_email.delay(self.id)\n\n# And in views\ndef process_order(request, order_id):\n    order.process()\n    analytics.delay(order.id)\n    return HttpResponse(\"OK\")\n</code></pre> <p>Changing every <code>.delay()</code> to <code>airlock.enqueue()</code> is tedious and error-prone.</p>"},{"location":"migration/from-direct-delay/#strategy-1-selective-migration-recommended","title":"Strategy 1: Selective Migration (Recommended)","text":"<p>Migrate tasks one at a time using <code>LegacyTaskShim</code>:</p> <pre><code>from airlock.integrations.celery import LegacyTaskShim\n\n# Apply to tasks you're migrating\n@app.task(base=LegacyTaskShim)\ndef notify_warehouse(order_id):\n    ...\n\n# Old code still works (inside scopes)\nwith airlock.scope():\n    notify_warehouse.delay(order_id)  # Routes through airlock, warns\n</code></pre> <p>Behavior: - \u2705 Inside scope: routes through airlock, returns <code>None</code> - \u274c Outside scope: raises <code>NoScopeError</code> - \u26a0\ufe0f Always emits <code>DeprecationWarning</code></p> <p>Migration path: 1. Add <code>LegacyTaskShim</code> to one task 2. Ensure all call sites have scopes 3. Replace <code>.delay()</code> with <code>airlock.enqueue()</code> at your leisure 4. Remove <code>LegacyTaskShim</code> when done</p>"},{"location":"migration/from-direct-delay/#strategy-2-blanket-migration","title":"Strategy 2: Blanket Migration","text":"<p>Intercept ALL tasks globally:</p> <pre><code># celery.py\nfrom celery import Celery\nfrom airlock.integrations.celery import install_global_intercept\n\napp = Celery('myapp')\n\n# Patch all tasks at startup\ninstall_global_intercept(app)\n</code></pre> <p>Behavior: - \u2705 Inside scope: routes through airlock, returns <code>None</code> - \u2705 Outside scope: passes through to Celery, warns - \u26a0\ufe0f Always emits <code>DeprecationWarning</code> - \ud83d\udd04 Wraps all task execution in scopes automatically</p> <p>Use for: - Large codebases with 100s of <code>.delay()</code> calls - Quick proof-of-concept - Gradual migration without breaking existing code</p> <p>\u26a0\ufe0f Warning: This is a migration tool, not steady-state architecture. It monkey-patches Celery globally. Plan to replace <code>.delay()</code> with <code>airlock.enqueue()</code> over time.</p>"},{"location":"migration/from-direct-delay/#strategy-3-greenfield-new-code","title":"Strategy 3: Greenfield (New Code)","text":"<p>Just use <code>airlock.enqueue()</code> from the start:</p> <pre><code>import airlock\n\nclass Order(models.Model):\n    def save(self, *args, **kwargs):\n        super().save(*args, **kwargs)\n        airlock.enqueue(notify_warehouse, self.id)\n\n# In views (with Django middleware)\ndef process_order(request, order_id):\n    order.process()  # Effects auto-scoped by middleware\n    return HttpResponse(\"OK\")\n</code></pre> <p>No shims, no warnings, no migration needed.</p>"},{"location":"migration/from-direct-delay/#comparison","title":"Comparison","text":"Approach Effort Risk Use When Selective Medium Low Methodical migration, want control Blanket Low Medium Large codebase, need quick win Greenfield Low None New project or isolated feature"},{"location":"migration/from-direct-delay/#common-issues","title":"Common Issues","text":""},{"location":"migration/from-direct-delay/#issue-noscopeerror-with-legacytaskshim","title":"Issue: <code>NoScopeError</code> with <code>LegacyTaskShim</code>","text":"<pre><code>notify_warehouse.delay(123)  # NoScopeError!\n</code></pre> <p>Fix: <code>LegacyTaskShim</code> requires a scope. Add one:</p> <pre><code>with airlock.scope():\n    notify_warehouse.delay(123)  # Works\n</code></pre> <p>Or use <code>install_global_intercept()</code> instead (allows outside scopes).</p>"},{"location":"migration/from-direct-delay/#issue-return-value-is-none","title":"Issue: Return value is <code>None</code>","text":"<pre><code>result = task.delay(123)\nresult.get()  # AttributeError: 'NoneType' has no attribute 'get'\n</code></pre> <p>Why: Inside scopes, <code>.delay()</code> returns <code>None</code> because dispatch is deferred.</p> <p>Fix: Stop relying on <code>AsyncResult</code>. Decouple intent from result tracking. If you need results, use a different pattern (callbacks, database polling, etc.).</p>"},{"location":"migration/from-direct-delay/#issue-warnings-everywhere","title":"Issue: Warnings everywhere","text":"<pre><code>DeprecationWarning: task.delay() is deprecated, use airlock.enqueue()\n</code></pre> <p>Fix: This is intentional! Replace <code>.delay()</code> with <code>airlock.enqueue()</code>:</p> <pre><code># Old\ntask.delay(arg)\n\n# New\nairlock.enqueue(task, arg)\n</code></pre>"},{"location":"migration/from-direct-delay/#next-steps","title":"Next Steps","text":"<ul> <li>Selective vs Blanket - Choosing migration strategy</li> <li>Celery Task Wrapper - <code>AirlockTask</code> deep dive</li> </ul>"},{"location":"migration/selective-vs-blanket/","title":"Selective vs Blanket Migration","text":"<p>Choosing the right migration strategy for your codebase.</p>"},{"location":"migration/selective-vs-blanket/#decision-tree","title":"Decision Tree","text":"<pre><code>Do you have 100+ .delay() calls?\n\u251c\u2500 Yes \u2192 Start with blanket migration\n\u2514\u2500 No  \u2192 Use selective migration\n\nIs this a new feature/module?\n\u251c\u2500 Yes \u2192 Use greenfield (airlock.enqueue from start)\n\u2514\u2500 No  \u2192 Continue below\n\nCan you afford 1-2 weeks of migration work?\n\u251c\u2500 Yes \u2192 Selective migration (safest)\n\u2514\u2500 No  \u2192 Blanket migration (fastest)\n</code></pre>"},{"location":"migration/selective-vs-blanket/#selective-migration","title":"Selective Migration","text":""},{"location":"migration/selective-vs-blanket/#how-it-works","title":"How It Works","text":"<p>Apply <code>LegacyTaskShim</code> to individual tasks:</p> <pre><code>from airlock.integrations.celery import LegacyTaskShim\n\n@app.task(base=LegacyTaskShim)\ndef notify_warehouse(order_id):\n    ...\n</code></pre> <p>Migrate one task at a time, replacing <code>.delay()</code> calls at your own pace.</p>"},{"location":"migration/selective-vs-blanket/#pros","title":"Pros","text":"<ul> <li>\u2705 Safe - Explicit about what's migrated</li> <li>\u2705 Controlled - Migrate critical paths first</li> <li>\u2705 Clear - Easy to see migration progress</li> <li>\u2705 Testable - Test each task individually</li> </ul>"},{"location":"migration/selective-vs-blanket/#cons","title":"Cons","text":"<ul> <li>\u274c Slow - Must apply shim to each task</li> <li>\u274c Requires scopes - Raises <code>NoScopeError</code> outside scopes</li> <li>\u274c Incomplete coverage - Un-shimmed tasks still use old behavior</li> </ul>"},{"location":"migration/selective-vs-blanket/#when-to-use","title":"When to Use","text":"<ul> <li>You have &lt; 50 tasks</li> <li>You want explicit control</li> <li>You can afford time to migrate properly</li> <li>You're risk-averse</li> </ul>"},{"location":"migration/selective-vs-blanket/#migration-steps","title":"Migration Steps","text":"<ol> <li>Identify critical tasks - Start with high-value paths</li> <li>Add shim to one task</li> <li>Add scopes to call sites - Ensure no <code>NoScopeError</code></li> <li>Test thoroughly</li> <li>Replace <code>.delay()</code> with <code>airlock.enqueue()</code> (optional)</li> <li>Repeat for next task</li> </ol>"},{"location":"migration/selective-vs-blanket/#blanket-migration","title":"Blanket Migration","text":""},{"location":"migration/selective-vs-blanket/#how-it-works_1","title":"How It Works","text":"<p>Intercept ALL tasks globally:</p> <pre><code># celery.py\nfrom airlock.integrations.celery import install_global_intercept\n\napp = Celery('myapp')\ninstall_global_intercept(app)\n</code></pre> <p>Every task is automatically intercepted and wrapped.</p>"},{"location":"migration/selective-vs-blanket/#pros_1","title":"Pros","text":"<ul> <li>\u2705 Fast - One line of code</li> <li>\u2705 Complete - Covers all tasks immediately</li> <li>\u2705 Graceful - Works outside scopes (warns, doesn't break)</li> <li>\u2705 Auto-wraps execution - Tasks run in scopes automatically</li> </ul>"},{"location":"migration/selective-vs-blanket/#cons_1","title":"Cons","text":"<ul> <li>\u274c Global side effects - Monkey-patches Celery</li> <li>\u274c Migration tool - Not intended for steady-state</li> <li>\u274c Less control - Everything migrated at once</li> <li>\u274c Returns None - <code>.delay()</code> returns <code>None</code> inside scopes</li> </ul>"},{"location":"migration/selective-vs-blanket/#when-to-use_1","title":"When to Use","text":"<ul> <li>You have 100+ tasks</li> <li>You need quick proof-of-concept</li> <li>You're refactoring a legacy codebase</li> <li>You want immediate benefits with gradual cleanup</li> </ul>"},{"location":"migration/selective-vs-blanket/#migration-steps_1","title":"Migration Steps","text":"<ol> <li>Install global intercept - One line in <code>celery.py</code></li> <li>Test critical paths - Ensure scopes exist where needed</li> <li>Monitor warnings - Find <code>.delay()</code> calls to replace</li> <li>Gradually replace - <code>task.delay()</code> \u2192 <code>airlock.enqueue(task)</code></li> <li>Remove intercept - When all <code>.delay()</code> replaced</li> </ol>"},{"location":"migration/selective-vs-blanket/#hybrid-approach","title":"Hybrid Approach","text":"<p>Use both strategies:</p> <pre><code># celery.py - Global intercept for most tasks\ninstall_global_intercept(app, wrap_task_execution=False)\n\n# Critical tasks - Explicit shimming for control\n@app.task(base=LegacyTaskShim)\ndef critical_payment_task(order_id):\n    ...\n</code></pre> <p>This gives: - Blanket coverage for routine tasks - Explicit control for critical tasks - Gradual migration path</p>"},{"location":"migration/selective-vs-blanket/#common-patterns","title":"Common Patterns","text":""},{"location":"migration/selective-vs-blanket/#pattern-1-start-blanket-finish-selective","title":"Pattern 1: Start Blanket, Finish Selective","text":"<pre><code># Week 1: Install blanket migration\ninstall_global_intercept(app)\n\n# Week 2-4: Add scopes to critical paths\nwith airlock.scope():\n    process_order()\n\n# Week 5+: Replace .delay() with airlock.enqueue()\n# Old: task.delay(arg)\n# New: airlock.enqueue(task, arg)\n\n# Eventually: Remove intercept when all replaced\n</code></pre>"},{"location":"migration/selective-vs-blanket/#pattern-2-selective-for-new-blanket-for-old","title":"Pattern 2: Selective for New, Blanket for Old","text":"<pre><code># New feature: Use airlock.enqueue from start\ndef new_checkout_flow():\n    airlock.enqueue(new_task, ...)\n\n# Legacy code: Blanket intercept\ninstall_global_intercept(app)\n</code></pre>"},{"location":"migration/selective-vs-blanket/#pattern-3-feature-flag-migration","title":"Pattern 3: Feature Flag Migration","text":"<pre><code># settings.py\nUSE_AIRLOCK = env.bool(\"USE_AIRLOCK\", default=False)\n\n# celery.py\nif settings.USE_AIRLOCK:\n    install_global_intercept(app)\n</code></pre> <p>Test in staging, roll out gradually.</p>"},{"location":"migration/selective-vs-blanket/#gotchas","title":"Gotchas","text":""},{"location":"migration/selective-vs-blanket/#blanket-airlocktask-double-scopes","title":"Blanket + AirlockTask = Double Scopes","text":"<p>Don't use both:</p> <pre><code># \u274c Bad - creates nested scopes\ninstall_global_intercept(app)  # Wraps execution in scope\n\n@app.task(base=AirlockTask)  # Also wraps execution in scope\ndef my_task():\n    ...\n</code></pre> <p>Choose one: - Blanket intercept with <code>wrap_task_execution=True</code> (default) - OR explicit <code>AirlockTask</code> base class</p>"},{"location":"migration/selective-vs-blanket/#selective-requires-scopes-everywhere","title":"Selective Requires Scopes Everywhere","text":"<pre><code>@app.task(base=LegacyTaskShim)\ndef shimmed_task():\n    ...\n\n# \u274c Fails - no scope\nshimmed_task.delay()\n\n# \u2705 Works - has scope\nwith airlock.scope():\n    shimmed_task.delay()\n</code></pre> <p>Blanket migration allows outside scopes (warns, doesn't break).</p>"},{"location":"migration/selective-vs-blanket/#recommendation","title":"Recommendation","text":"<p>For most teams: Start with blanket migration, gradually replace <code>.delay()</code> calls.</p> <p>For small teams/codebases: Use selective migration for explicit control.</p> <p>For new code: Skip migration entirely, use <code>airlock.enqueue()</code> from day 1.</p>"},{"location":"migration/selective-vs-blanket/#next-steps","title":"Next Steps","text":"<ul> <li>Migrating from .delay() - Detailed migration guide</li> <li>Celery Integration - AirlockTask deep dive</li> </ul>"},{"location":"quickstart/celery/","title":"Celery Quickstart","text":"<p>Goal: Get airlock working with Celery tasks in 5 minutes.</p>"},{"location":"quickstart/celery/#install","title":"Install","text":"<pre><code>pip install airlock celery\n</code></pre>"},{"location":"quickstart/celery/#wrap-task-execution","title":"Wrap Task Execution","text":"<p>Use <code>AirlockTask</code> as base class to auto-scope task execution:</p> <pre><code>from celery import Celery\nfrom airlock.integrations.celery import AirlockTask\nimport airlock\n\napp = Celery('myapp')\n\n@app.task(base=AirlockTask)\ndef process_order(order_id):\n    order = fetch_order(order_id)\n    order.status = \"processed\"\n    save_order(order)\n\n    # These are buffered within the task's scope\n    airlock.enqueue(send_email, order_id=order_id)\n    airlock.enqueue(update_analytics, order_id=order_id)\n    # Flushes when task completes successfully\n    # Discards if task raises exception\n</code></pre> <p>Now when <code>process_order</code> runs: - \u2705 Creates automatic scope - \u2705 Flushes on success - \u274c Discards on error</p>"},{"location":"quickstart/celery/#dispatch-via-celery","title":"Dispatch via Celery","text":"<p>Use <code>celery_executor</code> to dispatch through Celery:</p> <pre><code>from airlock.integrations.executors.celery import celery_executor\n\nwith airlock.scope(executor=celery_executor):\n    airlock.enqueue(send_email, user_id=123)\n    airlock.enqueue(process_data, item_id=456)\n# Dispatches via .delay()\n</code></pre> <p>The executor automatically detects Celery tasks and uses <code>.delay()</code> or <code>.apply_async()</code>. Plain functions run synchronously.</p>"},{"location":"quickstart/celery/#combining-both","title":"Combining Both","text":"<p>Task execution scoping + Celery dispatch:</p> <pre><code>@app.task(base=AirlockTask)\ndef process_order(order_id):\n    # This task runs in a scope\n    order = fetch_order(order_id)\n    save_order(order)\n\n    # Dispatch follow-up task via Celery\n    airlock.enqueue(send_email, order_id=order_id)\n\n# Trigger it\nwith airlock.scope(executor=celery_executor):\n    airlock.enqueue(process_order, order_id=123)\n# process_order.delay(order_id=123) is called\n# When it runs, send_email is also queued via Celery\n</code></pre>"},{"location":"quickstart/celery/#pass-celery-options","title":"Pass Celery Options","text":"<pre><code>airlock.enqueue(\n    send_email,\n    user_id=123,\n    _dispatch_options={\n        \"countdown\": 60,      # Delay 60 seconds\n        \"queue\": \"emails\",    # Use specific queue\n        \"priority\": 9,        # High priority\n    }\n)\n# Calls: send_email.apply_async((user_id,), {}, countdown=60, queue=\"emails\", priority=9)\n</code></pre>"},{"location":"quickstart/celery/#migrating-existing-code","title":"Migrating Existing Code","text":""},{"location":"quickstart/celery/#selective-migration","title":"Selective Migration","text":"<p>Apply <code>LegacyTaskShim</code> to tasks you're migrating:</p> <pre><code>from airlock.integrations.celery import LegacyTaskShim\n\n@app.task(base=LegacyTaskShim)\ndef old_task(arg):\n    ...\n\n# This now routes through airlock\nwith airlock.scope():\n    old_task.delay(123)  # Emits DeprecationWarning, buffers intent\n# Dispatches here\n</code></pre> <p>Note: <code>LegacyTaskShim</code> requires an active scope. It will raise <code>NoScopeError</code> if called outside a scope.</p>"},{"location":"quickstart/celery/#blanket-migration","title":"Blanket Migration","text":"<p>For large codebases, intercept all tasks globally:</p> <pre><code># celery.py\nfrom celery import Celery\nfrom airlock.integrations.celery import install_global_intercept\n\napp = Celery('myapp')\n\n# Patch all tasks globally\ninstall_global_intercept(app)\n</code></pre> <p>This: 1. Intercepts all <code>.delay()</code> and <code>.apply_async()</code> calls 2. Routes them through airlock when inside a scope 3. Wraps all task execution in scopes (like <code>AirlockTask</code>) 4. Emits <code>DeprecationWarning</code> to encourage migration</p> <p>Inside scope: <pre><code>with airlock.scope():\n    my_task.delay(123)  # Buffered, returns None\n# Dispatches here\n</code></pre></p> <p>Outside scope: <pre><code>my_task.delay(123)  # Passes through to Celery, warns\n</code></pre></p> <p>\u26a0\ufe0f Global intercept is a migration tool, not steady state. Use it to migrate legacy code, but prefer <code>airlock.enqueue()</code> for new code.</p> <p>Full migration guide \u2192</p>"},{"location":"quickstart/celery/#with-django","title":"With Django","text":"<p>Combine Django middleware + Celery executor:</p> <pre><code># settings.py\nMIDDLEWARE = [\n    \"airlock.integrations.django.AirlockMiddleware\",\n]\n\nAIRLOCK = {\n    \"EXECUTOR\": \"airlock.integrations.executors.celery.celery_executor\",\n}\n</code></pre> <p>Now every request auto-scopes and dispatches via Celery:</p> <pre><code>import airlock\n\ndef checkout_view(request):\n    order = process_checkout(request)\n    airlock.enqueue(send_confirmation, order_id=order.id)\n    airlock.enqueue(notify_warehouse, order_id=order.id)\n    return HttpResponse(\"OK\")\n# Both tasks dispatch via Celery after transaction.on_commit()\n</code></pre>"},{"location":"quickstart/celery/#next-steps","title":"Next Steps","text":"<ul> <li>Migration strategies - Selective vs blanket</li> <li>Task wrapper details - AirlockTask deep dive</li> <li>Raw Python quickstart - Core concepts without frameworks</li> </ul>"},{"location":"quickstart/django/","title":"Django integration","text":"<p>Airlock provides a Django middleware that automatically creates a scopes for your view code.  Out of the box, Airlock is compatible with many popular task frameworks including Celery,  django-q, Dramatiq, huey, and Django Tasks.</p>"},{"location":"quickstart/django/#how-it-works","title":"How it works","text":"<p>The middleware automatically wraps each request in a scope with the following behaviors:</p> <ul> <li>All side effects enqueued during a request remain buffered until the end of the request.</li> <li>When the Response reaches airlock's middleware:</li> <li>If the response is an error (4xx/5xx or unhandled exception) side effects are discarded.</li> <li>If the response is successful (1xx/2xx/3xx) side effects are dispatched.<ul> <li>If you're in a database transaction, side effects will be deferred to <code>transaction.on_commit()</code> automatically.</li> </ul> </li> </ul> <p>These default behaviors are configurable.</p>"},{"location":"quickstart/django/#installation-setup","title":"Installation &amp; setup","text":"<pre><code>pip install airlock\n</code></pre> <p>In <code>settings.py</code>, add middleware and configure your task framework:</p> <pre><code>MIDDLEWARE = [\n    # ... other middleware ...\n    \"airlock.integrations.django.AirlockMiddleware\",\n]\n\nAIRLOCK = {\n    \"EXECUTOR\": \"airlock.integrations.executors.celery.celery_executor\",\n}\n</code></pre>"},{"location":"quickstart/django/#basic-usage","title":"Basic usage","text":"<p>Anywhere in your models/views/services/etc, pass your task functions to <code>airlock.enqueue()</code>:</p> <pre><code>## models.py\nimport airlock\nimport .tasks\n\nclass Order(models.Model):\n    def process(self):\n        self.status = \"processed\"\n        self.save()\n        airlock.enqueue(tasks.send_confirmation_email, order_id=self.id)\n        airlock.enqueue(tasks.notify_warehouse, order_id=self.id)\n\n## views.py\ndef checkout(request):\n    order = Order.objects.get(id=request.POST['order_id'])\n    order.process()\n    return HttpResponse(\"OK\")\n# All side effects dispatch here after response + transaction commit\n</code></pre>"},{"location":"quickstart/django/#configuration","title":"Configuration","text":"<p>With zero configuration, all tasks execute synchronously as plain callables at dispatch time, hooked in to <code>transaction.on_commit(robust=True)</code> against the default database.</p> <pre><code># settings.py\nAIRLOCK = {\n    # Just call functions synchronously at dispatch time\n    \"EXECUTOR\": \"airlock.integrations.executors.sync.sync_executor\",\n    # Other built in options:\n    # \"EXECUTOR\": \"airlock.integrations.executors.celery.celery_executor\",\n    # \"EXECUTOR\": \"airlock.integrations.executors.django_q.django_q_executor\",\n    # \"EXECUTOR\": \"airlock.integrations.executors.huey.huey_executor\",\n    # \"EXECUTOR\": \"airlock.integrations.executors.dramatiq.dramatiq_executor\",\n    # \"EXECUTOR\": \"airlock.integrations.executors.django_tasks.django_tasks_executor\",\n\n    \"POLICY\": \"airlock.AllowAll\",\n}\n</code></pre>"},{"location":"quickstart/django/#overriding-4xx5xx-behavior","title":"Overriding 4xx/5xx behavior","text":"<p>By default airlock's Django middleware discards side effects  on 4xx/5xx responses and on exceptions. To customize this behavior, subclass <code>AirlockMiddleware</code> and override <code>should_flush</code>:</p> <pre><code>## middleware.py\nfrom airlock.integrations.django import AirlockMiddleware\nclass UnconditionallyDispatchingAirlockMiddleware(AirlockMiddleware):\n    def should_flush(self, request, response):\n        return True\n\n## settings.py\nMIDDLEWARE = [\n    # ...\n    \"my_app.middleware.UnconditionallyDispatchingAirlockMiddleware\",\n    # ...\n]\n</code></pre>"},{"location":"quickstart/django/#middleware-placement","title":"Middleware placement","text":"<p>Any placement works for most projects. Django's request handler converts uncaught exceptions to 4xx/5xx responses, so <code>AirlockMiddleware</code> typically sees the correct status code and discards appropriately.</p> <p>Placement matters if you have custom middleware with <code>process_exception()</code> that catches view exceptions and returns 2xx or 3xx responses. In that case, place <code>AirlockMiddleware</code> higher (earlier) in the list than such middleware, so it sees the exception via its own <code>process_exception</code> before another middleware converts it to a misleading success response.</p> <p>If you care about dispatching conditional on exceptions from middleware themselves (not just views), place <code>AirlockMiddleware</code> above those middleware. Similarly, if you use <code>ATOMIC_REQUESTS=False</code> and maintain your own control over transaction boundaries across middleware layers, you may need to be more opinionated about ordering.</p>"},{"location":"quickstart/django/#airlock-in-management-commands","title":"Airlock in management commands","text":"<p>Wrap commands with <code>@airlock_command</code> for automatic scoping:</p> <ul> <li>All side effects enqueued during a command remain buffered until the end of the command.</li> <li>When the command finishes:</li> <li>If there was an unhandled exception, side effects are discarded.</li> <li>If the command is successful, side effects are dispatched.</li> <li>If your command supports a <code>--dry-run</code> flag, airlock will discard side effects when your command executes in dry-run mode.</li> </ul> <pre><code>from django.core.management.base import BaseCommand\nfrom airlock.integrations.django import airlock_command\n\nclass Command(BaseCommand):\n    def add_arguments(self, parser):\n        parser.add_argument('--dry-run', action='store_true')\n\n    @airlock_command\n    def handle(self, *args, **options):\n        # If --dry-run, all side effects will drop automatically\n        # Otherwise, all side effects will dispatch at the end of the script\n        for order in Order.objects.filter(status='pending'):\n            order.process()\n</code></pre>"},{"location":"quickstart/django/#manual-scoping","title":"Manual scoping","text":"<p>You can always maintain explicit control too with the context manager API.  Use <code>DjangoScope</code> to pick up settings and transaction-aware dispatch timing:</p> <pre><code>from airlock.integrations.django import DjangoScope\n\n# In a script, task, etc:\ndef background_job():\n    with airlock.scope(_cls=DjangoScope):\n        do_stuff()\n    # Effects dispatch after transaction commit\n\n# Or in a view with finer-grained control:\ndef checkout(request):\n    order = Order.objects.get(id=request.POST['order_id'])\n    with airlock.scope(_cls=DjangoScope):\n        order.process()\n    with airlock.scope(_cls=DjangoScope):\n        ping_analytics(request.user)\n    return HttpResponse(\"OK\")\n</code></pre> <p>This pattern can also be combined with middleware-based implicit scopes. You'll want to read more about how nested scopes work in that case!</p>"},{"location":"quickstart/raw-python/","title":"Raw Python Quickstart","text":"<p>Goal: Get airlock working in 5 minutes without any framework.</p>"},{"location":"quickstart/raw-python/#install","title":"Install","text":"<pre><code>pip install airlock\n</code></pre>"},{"location":"quickstart/raw-python/#basic-pattern","title":"Basic Pattern","text":"<pre><code>import airlock\n\n# 1. Use airlock.enqueue() instead of direct calls\ndef process_order(order_id):\n    order = fetch_order(order_id)\n    order.status = \"processed\"\n    save_order(order)\n\n    airlock.enqueue(send_email, order_id=order_id)\n    airlock.enqueue(notify_warehouse, order_id=order_id)\n\n# 2. Wrap execution in a scope\nwith airlock.scope():\n    process_order(123)\n# Side effects dispatch here when scope exits\n</code></pre> <p>That's it. Effects buffer during execution, dispatch at scope exit.</p>"},{"location":"quickstart/raw-python/#controlling-behavior","title":"Controlling Behavior","text":""},{"location":"quickstart/raw-python/#drop-everything-dry-run-mode","title":"Drop everything (dry-run mode)","text":"<pre><code>with airlock.scope(policy=airlock.DropAll()):\n    process_order(123)\n# Nothing dispatches\n</code></pre>"},{"location":"quickstart/raw-python/#assert-no-side-effects-testing","title":"Assert no side effects (testing)","text":"<pre><code>def test_pure_calculation():\n    with airlock.scope(policy=airlock.AssertNoEffects()):\n        result = calculate_total(cart)  # OK\n        airlock.enqueue(send_email)     # Raises PolicyViolation\n</code></pre>"},{"location":"quickstart/raw-python/#block-specific-tasks","title":"Block specific tasks","text":"<pre><code>with airlock.scope(policy=airlock.BlockTasks({\"send_email\"})):\n    process_order(123)\n# notify_warehouse dispatches, send_email doesn't\n</code></pre>"},{"location":"quickstart/raw-python/#inspect-before-dispatch","title":"Inspect before dispatch","text":"<pre><code>with airlock.scope() as s:\n    process_order(123)\n\n    # Check what's buffered\n    print(f\"Buffered {len(s.intents)} side effects:\")\n    for intent in s.intents:\n        print(f\"  - {intent.name}\")\n# Dispatches here\n</code></pre>"},{"location":"quickstart/raw-python/#using-task-queues","title":"Using Task Queues","text":""},{"location":"quickstart/raw-python/#with-celery","title":"With Celery","text":"<pre><code>from airlock.integrations.executors.celery import celery_executor\n\nwith airlock.scope(executor=celery_executor):\n    airlock.enqueue(celery_task, arg=123)\n# Dispatches via celery_task.delay(arg=123)\n</code></pre>"},{"location":"quickstart/raw-python/#with-django-q","title":"With django-q","text":"<pre><code>from airlock.integrations.executors.django_q import django_q_executor\n\nwith airlock.scope(executor=django_q_executor):\n    airlock.enqueue(any_function, arg=123)\n# Dispatches via async_task(any_function, arg=123)\n</code></pre>"},{"location":"quickstart/raw-python/#common-patterns","title":"Common Patterns","text":""},{"location":"quickstart/raw-python/#local-policy-override","title":"Local policy override","text":"<pre><code>with airlock.scope():\n    airlock.enqueue(task_a)  # Will dispatch\n\n    with airlock.policy(airlock.DropAll()):\n        airlock.enqueue(task_b)  # Won't dispatch\n\n    airlock.enqueue(task_c)  # Will dispatch\n# task_a and task_c dispatch, task_b dropped\n</code></pre>"},{"location":"quickstart/raw-python/#pass-dispatch-options","title":"Pass dispatch options","text":"<pre><code>airlock.enqueue(\n    send_email,\n    user_id=123,\n    _dispatch_options={\"countdown\": 60, \"queue\": \"emails\"}\n)\n# Options passed to underlying queue (Celery, etc)\n</code></pre>"},{"location":"quickstart/raw-python/#next-steps","title":"Next Steps","text":"<ul> <li>Understand the problem - Why airlock exists</li> <li>Policies guide - Built-in and custom policies</li> <li>Nested scopes - Composition and capture</li> <li>Celery integration - Wrap Celery tasks</li> </ul>"},{"location":"understanding/alternatives/","title":"Alternatives","text":""},{"location":"understanding/alternatives/#transactionon_commit","title":"<code>transaction.on_commit()</code>","text":"<p>In many Django projects, the typical pattern evolution is to start with immediately-escaping tasks:</p> <pre><code>class Order:\n    def process(self):\n        self.status = \"processed\"\n        self.save()\n        notify_warehouse.delay(self.id)\n        send_confirmation_email(self.id)\n</code></pre> <p>And then migrate to a transaction boundary:</p> <pre><code>class Order:\n    def process(self):\n        self.status = \"processed\"\n        self.save()\n        transaction.on_commit(lambda: notify_warehouse.delay(self.id))\n        transaction.on_commit(lambda: send_confirmation_email(self.id))\n</code></pre> <p>This solves one problem: don't fire if the transaction rolls back, and don't fire until database state has settled. But it doesn't solve the rest:</p> <ul> <li>Only works inside a transaction. If you call <code>on_commit()</code> while there isn't an open transaction, the callback will be executed immediately. So the temporal sequence of your code changes silently based on both global configuration (<code>ATOMIC_REQUESTS</code>) and any given call stack (<code>with transaction.atomic()</code>) -- yikes!</li> <li>No opt-out. Migrations, fixtures, tests still trigger.</li> <li>No introspection. Can't ask \"what's about to fire?\"</li> <li>No policy control. Can't suppress specific tasks or block regions.</li> <li>What about sequential transactions? What about savepoints (nested transactions)? Hard to reason about! (Your side effects will run after each outermost transaction commits, in the order they were registered within that transaction's scope.)</li> </ul> <p>Airlock gives you <code>on_commit</code> behavior (via <code>DjangoScope</code>) plus policies, introspection, and a single dispatch boundary.</p>"},{"location":"understanding/alternatives/#django-signals","title":"Django signals","text":"<p>Signals move where the side effect lives, not whether or when it fires. This is a powerful tool for code organization, but it doesn't address the core problems.</p>"},{"location":"understanding/alternatives/#celery-chordschains","title":"Celery chords/chains","text":"<p>If your tasks trigger other tasks, consider whether the workflow should be defined upfront instead. <code>chain(task_a.s(), task_b.s())</code> makes the cascade explicit with no hidden enqueues.</p> <p>Airlock helps when that's not practical: triggers deep in the call stack that can't be extracted trivially; tasks that conditionally trigger others; or when you legitimately want to keep your side effect intents DRY across all callers.</p>"},{"location":"understanding/alternatives/#when-you-dont-need-this","title":"When you don't need this","text":"<p>You might not need airlock if:</p> <ul> <li>Views are the only place you enqueue. All <code>.delay()</code> calls are in views, never in models or reusable services.</li> <li>Tasks don't chain internally. No task triggers another task within its code.</li> <li>You use <code>ATOMIC_REQUESTS</code>. Transaction boundaries are already request-scoped, so <code>on_commit</code> behaves predictably.</li> <li>You always remember to hook into <code>transaction.on_commit</code>. All your view code reliably runs <code>transaction.on_commit(functools.partial(task.delay, ...))</code> so side effects never escape out of an incomplete or rolled-back transaction.</li> <li>You're happy with these constraints. You accept that domain intent (\"notify warehouse when order ships\") lives in views, not models.</li> </ul> <p>In this scenario, the view plus the database transaction is your boundary.</p> <p>That's a valid architecture. (I prefer it actually!) Airlock is for when you want to express intent closer to the domain -- in <code>save()</code>, in signals, in service methods -- without losing control over escape.</p>"},{"location":"understanding/alternatives/#next","title":"Next","text":"<ul> <li>Core model - The 3 concerns (Policy/Executor/Scope)</li> <li>How it composes - Nested scopes and provenance</li> </ul>"},{"location":"understanding/core-model/","title":"Core Model: The 3 Concerns","text":"<p>Airlock separates three orthogonal concerns that can be mixed and customized.</p> Concern Controlled By Question WHEN Scope When do effects escape? WHAT Policy Which effects execute? HOW Executor How do they run?"},{"location":"understanding/core-model/#concern-1-when-scope","title":"Concern 1: WHEN (Scope)","text":"<p>Scopes control timing and lifecycle.</p> <pre><code># Basic scope: flush on success, discard on error\nwith airlock.scope():\n    do_stuff()\n    # Effects buffered...\n# Effects execute here (on normal exit)\n</code></pre> <pre><code># Transaction-aware scope: wait for commit\nfrom airlock.integrations.django import DjangoScope\n\nwith transaction.atomic():\n    with airlock.scope(_cls=DjangoScope):\n        order.save()\n        airlock.enqueue(send_email, order.id)\n    # Effects still buffered...\n# Effects execute here (after commit)\n</code></pre>"},{"location":"understanding/core-model/#scope-decides","title":"Scope decides:","text":"<ul> <li>When to flush (end of block, after commit, custom)</li> <li>Whether to flush (success vs error)</li> <li>How to store buffer (memory, database, etc.)</li> </ul> <p>Default: flush on normal exit, discard on exception.</p>"},{"location":"understanding/core-model/#concern-2-what-policy","title":"Concern 2: WHAT (Policy)","text":"<p>Policies filter and observe intents.</p> <pre><code># Drop all effects (dry-run)\nwith airlock.scope(policy=airlock.DropAll()):\n    process_orders()  # Effects buffered but never dispatched\n\n# Assert no effects (testing)\nwith airlock.scope(policy=airlock.AssertNoEffects()):\n    pure_function()  # Raises if any enqueue() called\n\n# Block specific tasks\nwith airlock.scope(policy=airlock.BlockTasks({\"send_email\"})):\n    process_order()  # Emails dropped, other tasks execute\n\n# Log everything\nwith airlock.scope(policy=airlock.LogOnFlush(logger)):\n    do_stuff()  # All dispatches logged\n</code></pre>"},{"location":"understanding/core-model/#policy-decides","title":"Policy decides:","text":"<ul> <li>Which intents are allowed (filter)</li> <li>What to observe (logging, metrics)</li> <li>When to fail fast (assertions)</li> </ul> <p>Default: allow everything.</p>"},{"location":"understanding/core-model/#concern-3-how-executor","title":"Concern 3: HOW (Executor)","text":"<p>Executors control dispatch mechanism.</p> <pre><code># Sync execution (default)\nwith airlock.scope():\n    airlock.enqueue(my_function, arg=123)\n# Executes: my_function(arg=123)\n\n# Celery\nfrom airlock.integrations.executors.celery import celery_executor\n\nwith airlock.scope(executor=celery_executor):\n    airlock.enqueue(celery_task, arg=123)\n# Executes: celery_task.delay(arg=123)\n\n# django-q\nfrom airlock.integrations.executors.django_q import django_q_executor\n\nwith airlock.scope(executor=django_q_executor):\n    airlock.enqueue(any_function, arg=123)\n# Executes: async_task(any_function, arg=123)\n</code></pre>"},{"location":"understanding/core-model/#executor-decides","title":"Executor decides:","text":"<ul> <li>How to run the task (sync, queue, thread pool...)</li> <li>What protocol to use (Celery, django-q, Huey, custom)</li> </ul> <p>Default: synchronous execution.</p>"},{"location":"understanding/core-model/#mixing-concerns","title":"Mixing Concerns","text":"<p>The power is in composition:</p> <pre><code># Transaction-aware + Celery + logging\nfrom airlock.integrations.django import DjangoScope\nfrom airlock.integrations.executors.celery import celery_executor\n\nwith airlock.scope(\n    _cls=DjangoScope,           # WHEN: after transaction.on_commit()\n    executor=celery_executor,   # HOW: via Celery\n    policy=LogOnFlush(logger)   # WHAT: log everything\n):\n    order.save()\n    airlock.enqueue(send_email, order.id)\n# Waits for commit, dispatches via Celery, logs\n</code></pre> <pre><code># Test scope + sync executor + assertion\nwith airlock.scope(\n    _cls=Scope,                      # WHEN: immediate (no transaction)\n    executor=sync_executor,          # HOW: synchronous\n    policy=AssertNoEffects()         # WHAT: fail if anything enqueued\n):\n    test_calculation()\n</code></pre> <pre><code># Migration scope + drop all + immediate\nwith airlock.scope(\n    _cls=Scope,                      # WHEN: immediate\n    executor=sync_executor,          # HOW: doesn't matter (nothing runs)\n    policy=DropAll()                 # WHAT: suppress everything\n):\n    backfill_data()\n</code></pre>"},{"location":"understanding/core-model/#next","title":"Next","text":"<ul> <li>How it composes - Nested scopes and provenance</li> <li>Basic usage guide - Practical patterns</li> </ul>"},{"location":"understanding/how-it-composes/","title":"How It Composes","text":"<p>With airlock you can nest scopes or policies arbitrarily.</p>"},{"location":"understanding/how-it-composes/#nested-policies","title":"Nested Policies","text":"<p>Use <code>with airlock.policy()</code> to layer additional policies anywhere in your codebase, all in the same scope's buffer:</p> <pre><code>with airlock.scope():\n    airlock.enqueue(task_a)  \n\n    with airlock.policy(airlock.DropAll()):\n        airlock.enqueue(task_b)  \n\n    airlock.enqueue(task_c) \n# `task_a` executes, `task_b` is dropped, `task_c` executes\n</code></pre>"},{"location":"understanding/how-it-composes/#nested-scopes","title":"Nested Scopes","text":"<p>Your <code>with airlock.scope()</code> contexts can also be nested. Nested scopes don't flush independently by default. They're captured by their parent instead.</p> <pre><code>with airlock.scope() as outer:\n    airlock.enqueue(task_a)\n\n    with airlock.scope() as inner:\n        airlock.enqueue(task_b)\n    # Inner scope exits, but task_b is CAPTURED by outer\n\n# `task_a` and `task_b` both execute here\n</code></pre> <p>This logic applies recursively; the outermost <code>airlock.scope</code> has ultimate authority:</p> <pre><code>def code_with_side_effects(a):\n    with airlock.scope():\n        airlock.enqueue(task_c)\n        return a * 2\n\nwith airlock.scope() as outer:\n    airlock.enqueue(task_a)\n\n    with airlock.scope() as inner:\n        airlock.enqueue(task_b)\n        code_with_side_effects(5)\n\n# `task_a`, `task_b`, and `task_c` all execute here\n</code></pre>"},{"location":"understanding/how-it-composes/#wait-what-why-not-local-control","title":"Wait, what? Why not local control?","text":"<p>If nested scopes were to flush by default, we would have an inverse flywheel -- the more library code adopts airlock, the less control you have. Airlock scopes defined deep in call stacks would recreate the same \"side effects might get released anywhere\" problem that airlock tries to solve.</p> <p>With \"outermost scope controls\", multi-step operations stay well defined even when callees use scopes, without callers needing to know:</p> <pre><code>def checkout_cart(cart_id):\n    with airlock.scope():\n        validate_inventory(cart_id)     # May use scopes internally\n        charge_payment(cart_id)         # May use scopes internally\n        send_confirmation(cart_id)      # May use scopes internally\n    # All effects dispatch only if we reach the end successfully\n</code></pre>"},{"location":"understanding/how-it-composes/#provenance-tracking","title":"Provenance Tracking","text":"<p>After capturing a nested scope's intents, a parent scope can distinguish its own intents from captured ones:</p> <pre><code>with airlock.scope() as outer:\n    airlock.enqueue(task_a)  \n\n    with airlock.scope() as inner:\n        airlock.enqueue(task_b) \n\n    print(f\"Own: {len(outer.own_intents)}\")          # 1\n    print(f\"Captured: {len(outer.captured_intents)}\")  # 1\n    print(f\"Total: {len(outer.intents)}\")            # 2\n</code></pre> <p>This enables: - Auditing where intents came from - Different handling for own vs captured - Debugging nested behavior</p>"},{"location":"understanding/how-it-composes/#the-before_descendant_flushes-hook","title":"The <code>before_descendant_flushes</code> Hook","text":"<p>If you want to change this behavior, create your own scope class to define what happens when nested scopes exit.</p> <pre><code>class Scope:\n    def before_descendant_flushes(\n        self,\n        exiting_scope: Scope,\n        intents: list[Intent]\n    ) -&gt; list[Intent]:\n        \"\"\"\n        Called when nested scope exits.\n\n        Return intents to allow through.\n        Anything not returned is captured.\n\n        Default: return [] (capture all)\n        \"\"\"\n        return []\n</code></pre>"},{"location":"understanding/how-it-composes/#use-cases","title":"Use Cases","text":"<p>Selective capture:</p> <pre><code>class SafetyScope(Scope):\n    \"\"\"Capture dangerous tasks, allow others through.\"\"\"\n\n    def before_descendant_flushes(self, exiting_scope, intents):\n        safe = [i for i in intents if not i.dispatch_options.get(\"dangerous\")]\n        return safe\n\nwith SafetyScope():\n    with airlock.scope():\n        airlock.enqueue(safe_task)              # Allowed through\n        airlock.enqueue(\n            dangerous_task,\n            _dispatch_options={\"dangerous\": True}\n        )                                        # Captured\n    # safe_task executed \u2713\n\n# dangerous_task executes here \u2713\n</code></pre> <p>Batching:</p> <pre><code>class EmailBatchScope(Scope):\n    \"\"\"Batch emails, allow others through.\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.email_batch = []\n\n    def before_descendant_flushes(self, exiting_scope, intents):\n        emails = [i for i in intents if 'email' in i.name]\n        others = [i for i in intents if 'email' not in i.name]\n\n        self.email_batch.extend(emails)  # Capture for batching\n        return others                     # Others execute now\n\nwith EmailBatchScope() as batch:\n    with airlock.scope():\n        airlock.enqueue(send_email, to=\"user1@example.com\")\n        airlock.enqueue(log_event, event=\"email_queued\")\n    # log_event executes \u2713, email captured\n\n# Send batch\nsend_batch_emails(batch.email_batch)\n</code></pre> <p>Independent scopes (opt-out of capture):</p> <pre><code>class IndependentScope(Scope):\n    \"\"\"Allow nested scopes to flush independently.\"\"\"\n\n    def before_descendant_flushes(self, exiting_scope, intents):\n        return intents  # Allow all through\n\nwith IndependentScope():\n    with airlock.scope():\n        airlock.enqueue(task)\n    # task dispatches here (not captured) \u2713\n</code></pre>"},{"location":"understanding/how-it-composes/#policy-vs-capture","title":"Policy vs Capture","text":"<p>Policy controls WHAT executes (filtering):</p> <pre><code>with airlock.scope(policy=BlockTasks({\"send_email\"})):\n    airlock.enqueue(send_email)  # Blocked - never executes\n    airlock.enqueue(log_event)   # Allowed - executes\n</code></pre> <p>Capture controls WHEN executes (timing):</p> <pre><code>with airlock.scope() as outer:\n    with airlock.scope():\n        airlock.enqueue(send_email)  # Captured - executes later\n        airlock.enqueue(log_event)   # Captured - executes later\n# Both execute here (deferred, not blocked)\n</code></pre> <p>Key difference: - Policy: intent filtered out (never executes) - Capture: intent deferred (executes later at outer scope)</p>"},{"location":"understanding/how-it-composes/#extension-points-summary","title":"Extension Points Summary","text":"<p>Control different aspects of composition:</p> Extension Point Controls Default Policy What intents are allowed <code>AllowAll()</code> <code>should_flush()</code> Whether scope flushes/discards Flush on success <code>before_descendant_flushes()</code> When nested intents execute Capture all Executor How intents execute Sync <p>These are independent and compose freely.</p>"},{"location":"understanding/how-it-composes/#mental-model","title":"Mental Model","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Outer Scope                         \u2502\n\u2502                                     \u2502\n\u2502  Own intent: task_a                 \u2502\n\u2502                                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Inner Scope                   \u2502 \u2502\n\u2502  \u2502                               \u2502 \u2502\n\u2502  \u2502  Own intent: task_b           \u2502 \u2502\n\u2502  \u2502                               \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502         \u2502                           \u2502\n\u2502         \u2502 before_descendant_flushes()\u2502\n\u2502         \u25bc                           \u2502\n\u2502  Captured intent: task_b            \u2502\n\u2502                                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u2502 flush()\n         \u25bc\n   [task_a, task_b] dispatch together\n</code></pre>"},{"location":"understanding/how-it-composes/#common-patterns","title":"Common Patterns","text":""},{"location":"understanding/how-it-composes/#pattern-1-transaction-boundary","title":"Pattern 1: Transaction Boundary","text":"<pre><code>class TransactionScope(DjangoScope):\n    def before_descendant_flushes(self, exiting_scope, intents):\n        return []  # Capture all\n\nwith transaction.atomic():\n    with airlock.scope(_cls=TransactionScope):\n        complex_operation()  # May have nested scopes\n    # Nothing dispatches yet\n# All dispatches after commit \u2713\n</code></pre>"},{"location":"understanding/how-it-composes/#pattern-2-conditional-batching","title":"Pattern 2: Conditional Batching","text":"<pre><code>class ConditionalBatchScope(Scope):\n    def before_descendant_flushes(self, exiting_scope, intents):\n        # Batch high-volume tasks, allow low-volume through\n        high_volume = [i for i in intents if i.dispatch_options.get(\"batch\")]\n        return [i for i in intents if i not in high_volume]\n\nwith ConditionalBatchScope():\n    bulk_operation()\n    # Low-volume dispatches immediately, high-volume batched\n</code></pre>"},{"location":"understanding/how-it-composes/#pattern-3-ordering-control","title":"Pattern 3: Ordering Control","text":"<pre><code>class DBBeforeCacheScope(Scope):\n    \"\"\"DB writes now, cache updates later.\"\"\"\n\n    def before_descendant_flushes(self, exiting_scope, intents):\n        db_writes = [i for i in intents if 'db' in i.name]\n        return db_writes  # Allow DB writes through now\n\nwith DBBeforeCacheScope():\n    with airlock.scope():\n        airlock.enqueue(update_cache)\n        airlock.enqueue(db_write)\n    # db_write executes \u2713, update_cache captured\n# update_cache executes here (after DB commit) \u2713\n</code></pre>"},{"location":"understanding/how-it-composes/#next","title":"Next","text":"<ul> <li>Basic usage - Practical patterns</li> <li>Nested scopes guide - Deep dive</li> <li>Custom scopes - Subclassing</li> </ul>"},{"location":"understanding/the-problem/","title":"The Problem","text":""},{"location":"understanding/the-problem/#why-does-airlock-exist-what-problem-does-it-solve","title":"Why does airlock exist? What problem does it solve?","text":"<p>Putting side effects deep in the call stack is common but dangerous:</p> <pre><code>class Order:\n    def process(self):\n        self.status = \"processed\"\n        notify_warehouse(self.id)\n        send_confirmation_email(self.id)\n</code></pre> <p>It's also tempting to centralize \"conditional side effect dispatch\" in a deep method. Also dangerous!</p> <pre><code>class Order:\n    def update_status(self, status):\n        notify_warehouse(self.id)\n        if status == \"paid\":\n            send_confirmation_email(self.id)\n        elif status == \"shipped\":\n            update_tracking_system(self.id)\n            send_update_email(self.id)\n</code></pre> <p>But why are they dangerous?</p> <ul> <li>You can't opt out. Every scripted creation, fixture load, and migration that calls the method fires the tasks.</li> <li>It's invisible at the call site. <code>order.mark_as_paid()</code> looks innocent. You have to know to trace its call stack for side effects.</li> <li>Testing is miserable. Mock at the task level (fragile), run a real broker (slow), or <code>CELERY_ALWAYS_EAGER=True</code> (hides async bugs).</li> <li>Bulk operations explode. A loop calling <code>save()</code> on 10,000 orders enqueues 10,000 tasks.</li> <li>Re-entrancy bites. <code>User.save()</code> calls <code>enrich_from_api.delay(user.id)</code>. That task fetches data, sets <code>user.age</code> and <code>user.income</code>, then calls <code>user.save()</code>... which enqueues <code>enrich_from_api</code> again. Now you're adding flags like <code>_skip_enrich=True</code> and threading them through everywhere. (Or you're diffing against <code>Model.objects.get(pk=self.pk)</code> in every <code>save()</code> and using <code>save(changed_fields=[])</code> as a task dispatcher. Now you have three problems.)</li> </ul> <p>The problem isn't where the intent is expressed. It's that the effects are silent, and escape immediately.</p>"},{"location":"understanding/the-problem/#stuff-it-all-in-an-airlock","title":"Stuff it all in an airlock","text":"<p>With airlock, you express an intent to perform a side effect, but the side effects don't escape until someone lets them out:</p> <pre><code>import airlock\n\nclass Order:\n    def process(self):\n        self.status = \"processed\"\n        airlock.enqueue(notify_warehouse, self.id)          # Buffered for later\n        airlock.enqueue(send_confirmation_email, self.id)   # Buffered for later\n</code></pre> <p>Now these methods are a legitimate and safe place to express domain intent:</p> <ul> <li>Colocation. The model knows when it needs side effects. You may want that knowledge to belong here.</li> <li>DRY. Every code path that saves an Order expresses the side effects. You can't forget.</li> <li>Control. The scope decides what escapes, not the call site.</li> <li>Visibility. You can inspect the buffer before it flushes... run a model method and compare before-and-after... great for tests!</li> <li>Control again. Define your own nested scopes for surgically stacked policies, or even define multiple execution boundaries.</li> </ul> <p>Side effects can be defined close to the source, and still escape in one place.</p>"},{"location":"understanding/the-problem/#what-this-unlocks","title":"What this unlocks","text":"<p>Without airlock, \"enqueue all side effects at the edge\" is an important constraint for maintaining predictable timing, auditability, and control. Side effects deep in the call stack are dangerous, so you're forced to pull them out.</p> <p>With airlock, both patterns are safe:</p> <ul> <li>Edge-only: All enqueues in views/handlers. Explicit, visible at the boundary.</li> <li>Colocated: Enqueues near domain logic (<code>save()</code>, signals, service methods). DRY, encapsulated.</li> </ul> <p>Choose based on your preferences, not out of necessity.</p>"},{"location":"understanding/the-problem/#do-i-really-need-this","title":"Do I really need this...?","text":"<ul> <li>See Alternatives</li> </ul>"},{"location":"understanding/the-problem/#next","title":"Next","text":"<ul> <li>Core model - The 3 concerns (Policy/Executor/Scope)</li> <li>How it composes - Nested scopes and provenance</li> </ul>"}]}