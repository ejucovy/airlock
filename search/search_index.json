{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"airlock","text":"<p>Express side effects anywhere. Control whether &amp; when they escape.</p>"},{"location":"#tldr","title":"tl;dr","text":"<pre><code>import airlock\n\nclass Order:\n    def process(self):\n        self.status = \"processed\"\n        airlock.enqueue(notify_warehouse, self.id)\n        airlock.enqueue(send_confirmation_email)\n</code></pre> <p>The execution context decides when (and whether) your side effects actually get dispatched:</p> <pre><code># Production API endpoint: flush at end of request\nwith airlock.scope():\n    order.process()\n# side effects dispatch here\n\n# Migration: suppress everything\nwith airlock.scope(policy=airlock.DropAll()):\n    order.process()\n# nothing dispatched\n\n# Test: fail if anything tries to escape\nwith airlock.scope(policy=airlock.AssertNoEffects()):\n    order.hopefully_pure_function() # raises if any enqueue() called\n\n# Test: surface the side effects\nwith airlock.scope(policy=airlock.DropAll()) as scope:\n    order.process() # raises if any enqueue() called\n    assert len(self.intents) == 2\n    print((intent.name, intent.args, intent.kwargs) for intent in self.intents)\n\n# Admin API endpoint: selective control\nwith airlock.scope(policy=airlock.BlockTasks({\"send_confirmation_email\"})):\n    order.process()\n    assert len(self.intents) == 2 # the blocked task remains enqueued while we're in the scope\n# side effects dispatch or discard here -- warehouse notified, but no confirmation email sent\n</code></pre>"},{"location":"#using-django-maybe-with-celery","title":"Using Django? Maybe with Celery?","text":"<pre><code># settings.py\nMIDDLEWARE = [\n    # ... other middleware ...\n    \"airlock.integrations.django.AirlockMiddleware\",\n]\n\n# models.py\nimport airlock\nimport .tasks\n\nclass Order(models.Model):\n    def process(self):\n        self.status = \"processed\"\n        self.save()\n        airlock.enqueue(tasks.send_confirmation_email, order_id=self.id)\n        airlock.enqueue(tasks.notify_warehouse, order_id=self.id)\n\n# views.py\ndef checkout(request):\n    order = Order.objects.get(id=request.POST['order_id'])\n    order.process()\n    return HttpResponse(\"OK\")\n# Celery tasks dispatch in transaction.on_commit\n</code></pre> <p>Read more: Django quickstart | Celery integration</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install airlock\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>The Problem - Why airlock exists</li> <li>Core Model - The 3 concerns (Policy/Executor/Scope)</li> <li>Celery - Celery integration and migration</li> <li>Extending - Custom policies, executors, and scopes</li> <li>API Reference - Full API documentation</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>See CONTRIBUTING.md for development setup.</p>"},{"location":"#license","title":"License","text":"<p>MIT</p>"},{"location":"api/","title":"API Reference","text":"<p>Autogenerated API documentation from source code.</p>"},{"location":"api/#modules","title":"Modules","text":"Module Description Core Main airlock API: <code>scope()</code>, <code>enqueue()</code>, <code>policy()</code>, policies, and exceptions Django Integration Django middleware, <code>DjangoScope</code>, and management command decorator Celery Integration <code>AirlockTask</code>, <code>LegacyTaskShim</code>, and global intercept Executors Built-in executors for Celery, django-q, Huey, Dramatiq, and sync"},{"location":"api/celery/","title":"Celery Integration","text":"<p>Celery-specific components for airlock.</p> <pre><code>from airlock.integrations.celery import AirlockTask, LegacyTaskShim, install_global_intercept\n</code></pre>"},{"location":"api/celery/#task-base-classes","title":"Task Base Classes","text":""},{"location":"api/celery/#airlock.integrations.celery.AirlockTask","title":"AirlockTask","text":"<p>               Bases: <code>Task</code></p> <p>A Celery Task base class that wraps execution in an airlock scope.</p> <ul> <li>On success: flushes intents (downstream effects fire)</li> <li>On exception: discards intents (no side effects)</li> </ul> Usage <p>@app.task(base=AirlockTask) def my_task():     airlock.enqueue(downstream_task, ...)</p>"},{"location":"api/celery/#airlock.integrations.celery.LegacyTaskShim","title":"LegacyTaskShim","text":"<p>               Bases: <code>Task</code></p> <p>Migration helper that intercepts .delay() and routes through airlock.</p> <p>Emits DeprecationWarning to encourage updating call sites.</p> Usage <p>@app.task(base=LegacyTaskShim) def old_task(...):     ...</p>"},{"location":"api/celery/#airlock.integrations.celery.LegacyTaskShim--this-now-goes-through-airlock","title":"This now goes through airlock:","text":"<p>old_task.delay(...)  # DeprecationWarning</p>"},{"location":"api/celery/#global-intercept","title":"Global Intercept","text":""},{"location":"api/celery/#airlock.integrations.celery.install_global_intercept","title":"install_global_intercept","text":"<pre><code>install_global_intercept(app: Celery | None = None, *, wrap_task_execution: bool = True) -&gt; None\n</code></pre> <p>Install global interception of .delay() and .apply_async() calls.</p> <p>When a scope is active, all .delay()/.apply_async() calls are routed through airlock.enqueue(). When no scope is active, calls emit a deprecation warning and pass through normally.</p> <p>With wrap_task_execution=True (default), task execution is also wrapped in an airlock scope. This means: - Tasks automatically get an airlock scope (like using AirlockTask) - Any .delay() calls within tasks are intercepted and buffered - On task success: buffered intents flush - On task exception: buffered intents are discarded</p> <p>This is a monkey-patch. Call it once at app startup, after Celery is configured but before tasks are invoked.</p> Usage <p>Parameters:</p> Name Type Description Default <code>app</code> <code>Celery | None</code> <p>Optional Celery app. Currently unused but reserved for future  per-app scoping.</p> <code>None</code> <code>wrap_task_execution</code> <code>bool</code> <p>If True (default), wrap Task.call in an airlock scope so tasks automatically buffer and flush effects.</p> <code>True</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called more than once.</p>"},{"location":"api/celery/#airlock.integrations.celery.install_global_intercept--celerypy-or-conftestpy","title":"celery.py or conftest.py","text":"<p>from airlock.integrations.celery import install_global_intercept</p> <p>app = Celery(...) install_global_intercept(app)</p>"},{"location":"api/celery/#airlock.integrations.celery.install_global_intercept--or-without-execution-wrapping-only-intercept-delay-calls","title":"Or without execution wrapping (only intercept .delay() calls):","text":"<p>install_global_intercept(app, wrap_task_execution=False)</p>"},{"location":"api/celery/#airlock.integrations.celery.uninstall_global_intercept","title":"uninstall_global_intercept","text":"<pre><code>uninstall_global_intercept() -&gt; None\n</code></pre> <p>Remove global interception. Mainly for testing.</p>"},{"location":"api/core/","title":"Core API","text":"<p>The main airlock module. Import with <code>import airlock</code>.</p>"},{"location":"api/core/#functions","title":"Functions","text":""},{"location":"api/core/#airlock.scope","title":"scope","text":"<pre><code>scope(policy: Policy | None = None, *, _cls: type[Scope] = Scope, **kwargs) -&gt; Iterator[Scope]\n</code></pre> <p>Context manager defining a lifecycle boundary for side effects.</p> <p>Parameters:</p> Name Type Description Default <code>policy</code> <code>Policy | None</code> <p>Policy controlling what intents are allowed. Defaults to AllowAll.</p> <code>None</code> <code>_cls</code> <code>type[Scope]</code> <p>Scope class to use. Subclass Scope and override should_flush() to customize flush/discard behavior.</p> <code>Scope</code> <code>**kwargs</code> <p>Additional arguments passed to Scope constructor (e.g., executor).</p> <code>{}</code> Common kwargs <p>executor: Callable that executes intents. Defaults to synchronous execution.     See airlock.integrations.executors for available executors.</p> Behavior <ul> <li>On normal exit: calls flush() if should_flush(None) returns True</li> <li>On exception: calls flush() if should_flush(error) returns True, else discard()</li> </ul> <p>The default Scope.should_flush() returns True on success, False on error. Subclass Scope to customize this behavior.</p> <p>Examples:</p>"},{"location":"api/core/#airlock.scope--use-celery-executor","title":"Use celery executor","text":"<p>from airlock.integrations.executors.celery import celery_executor with airlock.scope(executor=celery_executor):     airlock.enqueue(my_task, ...)</p>"},{"location":"api/core/#airlock.scope--use-django-q-executor","title":"Use django-q executor","text":"<p>from airlock.integrations.executors.django_q import django_q_executor with airlock.scope(executor=django_q_executor):     airlock.enqueue(my_task, ...)</p>"},{"location":"api/core/#airlock.enqueue","title":"enqueue","text":"<pre><code>enqueue(task: Callable, *args: Any, _origin: str | None = None, _dispatch_options: dict[str, Any] | None = None, **kwargs: Any) -&gt; None\n</code></pre> <p>Express intent to perform a side effect.</p> <p>This is the ONLY function domain code should call.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>Callable</code> <p>The callable to execute (Celery task, function, etc.)</p> required <code>*args</code> <code>Any</code> <p>Positional arguments for the task.</p> <code>()</code> <code>_origin</code> <code>str | None</code> <p>Optional origin metadata for debugging/observability. This is NOT auto-detected - it must be set explicitly if needed. Integrations (Django middleware, Celery task wrapper) may set this to provide context like request path, task name, or trace/span IDs. For structured observability, prefer OpenTelemetry span context.</p> <code>None</code> <code>_dispatch_options</code> <code>dict[str, Any] | None</code> <p>Optional dispatch options (countdown, queue, etc.) Passed through to the task queue backend (e.g., Celery's apply_async). Ignored for plain callables.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Keyword arguments for the task.</p> <code>{}</code> <p>Raises:</p> Type Description <code>PolicyEnqueueError</code> <p>If called from within a policy callback.</p> <code>NoScopeError</code> <p>If no scope is active.</p> <code>PolicyViolation</code> <p>If a policy explicitly rejects the intent via on_enqueue(). For example, AssertNoEffects policy raises PolicyViolation on any enqueue. When this happens, the intent is NOT added to the buffer.</p>"},{"location":"api/core/#airlock.policy","title":"policy","text":"<pre><code>policy(p: Policy) -&gt; Iterator[None]\n</code></pre> <p>Context manager for local policy contexts.</p> <p>Intents enqueued within this context capture the policy and apply it at flush time. This enables local control without nested buffers.</p> Example <p>with airlock.scope():     airlock.enqueue(task_a)  # will dispatch</p> <pre><code>with airlock.policy(DropAll()):\n    airlock.enqueue(task_b)  # will NOT dispatch\n\nairlock.enqueue(task_c)  # will dispatch\n</code></pre> <p>Unlike nested scopes, all intents go to the same buffer. The local policy is metadata that affects dispatch decisions at flush.</p> <p>NOTE: This does NOT create a new buffer or nested scope. All intents from within this context still go to the enclosing scope's buffer. The policy is captured on each intent at enqueue time and evaluated at flush. This is intentional - it preserves a single dispatch boundary while allowing fine-grained control over which intents survive.</p>"},{"location":"api/core/#airlock.get_current_scope","title":"get_current_scope","text":"<pre><code>get_current_scope() -&gt; Scope | None\n</code></pre> <p>Get the currently active airlock scope, if any.</p>"},{"location":"api/core/#classes","title":"Classes","text":""},{"location":"api/core/#airlock.Scope","title":"Scope","text":"<p>A lifecycle scope that buffers and controls side effect intents.</p> <p>Parameters:</p> Name Type Description Default <code>policy</code> <code>Policy</code> <p>Policy controlling what intents are allowed</p> required <code>executor</code> <code>Executor | None</code> <p>Callable that executes intents. Defaults to synchronous execution. See airlock.integrations.executors for available executors.</p> <code>None</code>"},{"location":"api/core/#airlock.Scope.intents","title":"intents  <code>property</code>","text":"<pre><code>intents: list[Intent]\n</code></pre> <p>Read-only access to buffered intents for inspection.</p>"},{"location":"api/core/#airlock.Scope.own_intents","title":"own_intents  <code>property</code>","text":"<pre><code>own_intents: list[Intent]\n</code></pre> <p>Intents enqueued directly in this scope (not captured from nested scopes).</p>"},{"location":"api/core/#airlock.Scope.captured_intents","title":"captured_intents  <code>property</code>","text":"<pre><code>captured_intents: list[Intent]\n</code></pre> <p>Intents captured from nested scopes.</p>"},{"location":"api/core/#airlock.Scope.is_flushed","title":"is_flushed  <code>property</code>","text":"<pre><code>is_flushed: bool\n</code></pre>"},{"location":"api/core/#airlock.Scope.is_discarded","title":"is_discarded  <code>property</code>","text":"<pre><code>is_discarded: bool\n</code></pre>"},{"location":"api/core/#airlock.Scope.is_active","title":"is_active  <code>property</code>","text":"<pre><code>is_active: bool\n</code></pre> <p>True if this scope is currently the active scope.</p>"},{"location":"api/core/#airlock.Scope.enter","title":"enter","text":"<pre><code>enter() -&gt; Scope\n</code></pre> <p>Activate this scope.</p> <p>Sets the context var so enqueue() routes intents to this scope. Must call exit() when done, before calling flush() or discard().</p> <p>Returns:</p> Type Description <code>Scope</code> <p>self (for chaining)</p> <p>Raises:</p> Type Description <code>ScopeStateError</code> <p>If this scope is already active.</p>"},{"location":"api/core/#airlock.Scope.exit","title":"exit","text":"<pre><code>exit() -&gt; None\n</code></pre> <p>Deactivate this scope.</p> <p>Resets the context var to the previous scope (or None). Must be called before flush() or discard().</p> <p>Raises:</p> Type Description <code>ScopeStateError</code> <p>If this scope is not active.</p>"},{"location":"api/core/#airlock.Scope.flush","title":"flush","text":"<pre><code>flush() -&gt; list[Intent]\n</code></pre> <p>Flush all buffered intents - apply policy and dispatch.</p> <p>Filters intents through policies (both local and scope-level), then dispatches them in FIFO order using the configured executor.</p> <p>Returns:</p> Type Description <code>list[Intent]</code> <p>List of intents that were dispatched (after policy filtering).</p> <p>Raises:</p> Type Description <code>ScopeStateError</code> <p>If scope is already flushed, discarded, or still active.</p> Note <p>The scope is marked as flushed even if an executor raises an exception. This prevents retry attempts, as the scope is in an inconsistent state (some intents may have been dispatched before the failure).</p>"},{"location":"api/core/#airlock.Scope.discard","title":"discard","text":"<pre><code>discard() -&gt; list[Intent]\n</code></pre> <p>Discard all buffered intents without dispatching.</p>"},{"location":"api/core/#airlock.Scope.should_flush","title":"should_flush","text":"<pre><code>should_flush(error: BaseException | None) -&gt; bool\n</code></pre> <p>Decide terminal action when context manager exits.</p> <p>Override this method in subclasses to customize flush/discard behavior.</p> <p>Parameters:</p> Name Type Description Default <code>error</code> <code>BaseException | None</code> <p>The exception that caused exit, or None for normal exit.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True to flush (dispatch intents), False to discard.</p> <p>Default behavior: flush on success, discard on error.</p>"},{"location":"api/core/#airlock.Scope.before_descendant_flushes","title":"before_descendant_flushes","text":"<pre><code>before_descendant_flushes(exiting_scope: Scope, intents: list[Intent]) -&gt; list[Intent]\n</code></pre> <p>Called when a nested scope exits and attempts to flush.</p> <p>This method is called during the parent chain walk, allowing each ancestor to decide which intents the exiting scope may flush vs which to capture.</p> <p>Parameters:</p> Name Type Description Default <code>exiting_scope</code> <code>Scope</code> <p>The nested scope that is exiting (may be deeply nested)</p> required <code>intents</code> <code>list[Intent]</code> <p>The list of intents the exiting scope wants to flush</p> required <p>Returns:</p> Name Type Description <code>list[Intent]</code> <p>The list of intents to allow through (the exiting scope will flush these).</p> <code>list[Intent]</code> <p>Any intents not in the returned list are captured into this scope's buffer.</p> <code>IMPORTANT</code> <code>list[Intent]</code> <p>Must return a list. Returning None or other types raises TypeError.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If return value is not a list.</p> <p>Default behavior: Capture all intents (return []). This is the controlled default - outer scopes have authority over nested scopes.</p> Override this method to allow nested scopes to flush independently <ul> <li>Return [] to capture all intents (default, controlled)</li> <li>Return intents to allow all (independent nested scopes)</li> <li>Return filtered list to selectively capture</li> </ul> Notes <ul> <li>Do not mutate the <code>intents</code> list. Return a new list or slice.</li> <li>Returning intents not in the input list has undefined behavior.</li> <li>In multi-level nesting, <code>exiting_scope</code> is always the innermost scope,   not necessarily the immediate child. Intermediate scopes haven't exited yet.</li> </ul> Example <p>class IndependentScope(Scope):     def before_descendant_flushes(self, exiting_scope, intents):         return intents  # Allow nested scopes to flush independently</p> <p>class SmartScope(Scope):     def before_descendant_flushes(self, exiting_scope, intents):         # Capture dangerous tasks, allow safe ones         return [i for i in intents if 'dangerous' not in i.name]</p>"},{"location":"api/core/#airlock.Intent","title":"Intent  <code>dataclass</code>","text":"<p>Represents the intent to perform a side effect.</p> <p>Stores the actual callable, not just a name. The name property derives a string for serialization/logging.</p> <p>Captures local policy context at enqueue time for introspection and deferred application at flush.</p>"},{"location":"api/core/#airlock.Intent.task","title":"task  <code>instance-attribute</code>","text":"<pre><code>task: Callable\n</code></pre>"},{"location":"api/core/#airlock.Intent.args","title":"args  <code>instance-attribute</code>","text":"<pre><code>args: tuple[Any, ...]\n</code></pre>"},{"location":"api/core/#airlock.Intent.kwargs","title":"kwargs  <code>instance-attribute</code>","text":"<pre><code>kwargs: dict[str, Any]\n</code></pre>"},{"location":"api/core/#airlock.Intent.origin","title":"origin  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>origin: str | None = None\n</code></pre>"},{"location":"api/core/#airlock.Intent.dispatch_options","title":"dispatch_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>dispatch_options: dict[str, Any] | None = None\n</code></pre>"},{"location":"api/core/#airlock.Intent.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>Derived name for serialization/logging.</p>"},{"location":"api/core/#airlock.Intent.local_policies","title":"local_policies  <code>property</code>","text":"<pre><code>local_policies: tuple[Policy, ...]\n</code></pre> <p>Local policies captured at enqueue time.</p>"},{"location":"api/core/#airlock.Intent.passes_local_policies","title":"passes_local_policies","text":"<pre><code>passes_local_policies() -&gt; bool\n</code></pre> <p>Check if this intent passes its captured local policies.</p> <p>Returns True if all local policies allow this intent.</p> This does NOT guarantee the intent will be dispatched. It does not consider: <ul> <li>scope-level policy (checked separately at flush)</li> <li>whether the scope flushes or discards</li> <li>dispatch execution success</li> </ul> <p>Use for inspection and audit, not execution prediction.</p>"},{"location":"api/core/#protocols","title":"Protocols","text":""},{"location":"api/core/#airlock.Policy","title":"Policy","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for side effect policies.</p> <p>Policies are per-intent boolean gates that decide which intents dispatch. This design enforces FIFO order by construction - policies can filter intents but cannot reorder them.</p> <p>Methods:</p> Name Description <code>on_enqueue</code> <p>Called when an intent is added to the buffer. Use for observation, logging, or raising PolicyViolation for hard blocks.</p> <code>allows</code> <p>Called at flush time for each intent. Return True to dispatch, False to silently drop.</p>"},{"location":"api/core/#airlock.Policy.on_enqueue","title":"on_enqueue","text":"<pre><code>on_enqueue(intent: Intent) -&gt; None\n</code></pre> <p>Called when an intent is added to the buffer. Observe or raise.</p>"},{"location":"api/core/#airlock.Policy.allows","title":"allows","text":"<pre><code>allows(intent: Intent) -&gt; bool\n</code></pre> <p>Called at flush time. Return True to dispatch, False to drop.</p>"},{"location":"api/core/#airlock.Executor","title":"Executor","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for intent executors.</p> <p>An executor is a callable that takes an Intent and executes it via some dispatch mechanism (synchronous, Celery, django-q, etc.).</p> <p>Built-in executors are available in airlock.integrations.executors: - sync_executor: Synchronous execution (default) - celery_executor: Dispatch via Celery .delay() / .apply_async() - django_q_executor: Dispatch via django-q's async_task() - django_tasks_executor: Dispatch via Django 6+'s built-in tasks framework - huey_executor: Dispatch via Huey's .schedule() - dramatiq_executor: Dispatch via Dramatiq's .send()</p> <p>Custom executors can be written by implementing this protocol.</p>"},{"location":"api/core/#airlock.Executor.__call__","title":"__call__","text":"<pre><code>__call__(intent: Intent) -&gt; None\n</code></pre> <p>Execute the given intent.</p>"},{"location":"api/core/#built-in-policies","title":"Built-in Policies","text":""},{"location":"api/core/#airlock.AllowAll","title":"AllowAll","text":"<p>Policy that allows all side effects.</p>"},{"location":"api/core/#airlock.DropAll","title":"DropAll","text":"<p>Policy that drops all side effects.</p>"},{"location":"api/core/#airlock.AssertNoEffects","title":"AssertNoEffects","text":"<p>Policy that raises if any side effect is attempted.</p>"},{"location":"api/core/#airlock.BlockTasks","title":"BlockTasks","text":"<p>Policy that blocks specific tasks by name.</p>"},{"location":"api/core/#airlock.LogOnFlush","title":"LogOnFlush","text":"<p>Policy that logs intents at flush time (allows all).</p>"},{"location":"api/core/#airlock.CompositePolicy","title":"CompositePolicy","text":"<p>Policy that combines multiple policies (all must allow).</p>"},{"location":"api/core/#exceptions","title":"Exceptions","text":""},{"location":"api/core/#airlock.AirlockError","title":"AirlockError","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for all airlock errors.</p>"},{"location":"api/core/#airlock.UsageError","title":"UsageError","text":"<p>               Bases: <code>AirlockError</code></p> <p>Raised when airlock is used incorrectly (API misuse).</p>"},{"location":"api/core/#airlock.NoScopeError","title":"NoScopeError","text":"<p>               Bases: <code>UsageError</code></p> <p>Raised when enqueue() is called with no active scope.</p> <p>This is intentional: airlock requires explicit lifecycle boundaries. Side effects should not escape silently. Every enqueue() must occur within a scope() that decides when (and whether) effects dispatch.</p> <p>If you're seeing this error, wrap your code in an airlock.scope():</p> <pre><code>with airlock.scope():\n    do_stuff()  # enqueue() calls are now valid\n</code></pre>"},{"location":"api/core/#airlock.PolicyEnqueueError","title":"PolicyEnqueueError","text":"<p>               Bases: <code>UsageError</code></p> <p>Raised when enqueue() is called from within a policy callback.</p>"},{"location":"api/core/#airlock.ScopeStateError","title":"ScopeStateError","text":"<p>               Bases: <code>AirlockError</code></p> <p>Raised when an operation is invalid for the scope's current lifecycle state.</p>"},{"location":"api/core/#airlock.PolicyViolation","title":"PolicyViolation","text":"<p>               Bases: <code>AirlockError</code></p> <p>Raised when a policy explicitly rejects an intent.</p>"},{"location":"api/django/","title":"Django Integration","text":"<p>Django-specific components for airlock.</p> <pre><code>from airlock.integrations.django import DjangoScope, AirlockMiddleware, airlock_command\n</code></pre>"},{"location":"api/django/#configuration","title":"Configuration","text":"<p>Configure via <code>settings.py</code>:</p> <pre><code>AIRLOCK = {\n    \"POLICY\": \"airlock.AllowAll\",  # Dotted path or callable\n    \"EXECUTOR\": \"airlock.integrations.executors.celery.celery_executor\",\n    \"SCOPE\": \"airlock.integrations.django.DjangoScope\",\n}\n</code></pre>"},{"location":"api/django/#classes","title":"Classes","text":""},{"location":"api/django/#airlock.integrations.django.DjangoScope","title":"DjangoScope","text":"<p>               Bases: <code>Scope</code></p> <p>A Django-specific scope that respects database transactions.</p> <p>Defers dispatch to transaction.on_commit() so side effects only fire after the transaction commits successfully. When called outside a transaction (autocommit mode), on_commit executes immediately.</p> <p>If no executor is provided, uses get_executor() to select one based on EXECUTOR setting.</p> <p>Subclass and override schedule_dispatch() to customize dispatch timing.</p>"},{"location":"api/django/#airlock.integrations.django.DjangoScope.schedule_dispatch","title":"schedule_dispatch","text":"<pre><code>schedule_dispatch(callback: Callable[[], None]) -&gt; None\n</code></pre> <p>Schedule the dispatch callback. Override to customize dispatch timing.</p> <p>By default, uses transaction.on_commit(robust=True). This defers dispatch until the transaction commits, or runs immediately if outside a transaction (autocommit mode).</p> <p>Override to change timing, robust behavior, or skip on_commit entirely.</p>"},{"location":"api/django/#airlock.integrations.django.AirlockMiddleware","title":"AirlockMiddleware","text":"<p>Django middleware that wraps each request in an airlock scope.</p> <p>By default: - 1xx/2xx/3xx responses: flush - 4xx/5xx responses or exceptions: discard</p> <p>Subclass and override should_flush() for custom behavior.</p>"},{"location":"api/django/#airlock.integrations.django.AirlockMiddleware.should_flush","title":"should_flush","text":"<pre><code>should_flush(request, response) -&gt; bool\n</code></pre> <p>Override to customize flush behavior.</p>"},{"location":"api/django/#functions","title":"Functions","text":""},{"location":"api/django/#airlock.integrations.django.airlock_command","title":"airlock_command","text":"<pre><code>airlock_command(func: Callable = None, *, dry_run_kwarg: str = 'dry_run') -&gt; Callable\n</code></pre> <p>Decorator for Django management commands.</p> <p>Wraps the handle() method in an airlock scope. If options[dry_run_kwarg] is True, uses DropAll policy.</p> <p>Dispatch is deferred to transaction.on_commit():     - With an active transaction: dispatch occurs after commit     - Without a transaction (most commands): dispatch occurs immediately</p> Usage <p>class Command(BaseCommand):     def add_arguments(self, parser):         parser.add_argument('--dry-run', action='store_true')</p> <pre><code>@airlock_command\ndef handle(self, *args, **options):\n    airlock.enqueue(some_task, ...)\n</code></pre>"},{"location":"api/django/#airlock.integrations.django.get_executor","title":"get_executor","text":"<pre><code>get_executor() -&gt; Executor\n</code></pre> <p>Get the appropriate executor based on EXECUTOR setting.</p> <p>EXECUTOR should be a dotted import path to an executor callable, or None for synchronous execution.</p> <p>Examples:</p> <p>AIRLOCK = {     'EXECUTOR': 'airlock.integrations.executors.django_q.django_q_executor', }</p>"},{"location":"api/django/#airlock.integrations.django.get_executor--or-use-a-custom-executor","title":"Or use a custom executor","text":"<p>AIRLOCK = {     'EXECUTOR': 'myapp.executors.custom_executor', }</p> <p>Returns:</p> Type Description <code>Executor</code> <p>Executor function based on EXECUTOR setting</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If the executor module/callable cannot be imported</p>"},{"location":"api/django/#airlock.integrations.django.get_policy","title":"get_policy","text":"<pre><code>get_policy()\n</code></pre> <p>Get the policy instance based on POLICY setting.</p>"},{"location":"api/django/#airlock.integrations.django.get_scope_class","title":"get_scope_class","text":"<pre><code>get_scope_class()\n</code></pre> <p>Get the scope class to use, based on SCOPE setting.</p>"},{"location":"api/executors/","title":"Executors","text":"<p>Executors control how intents are dispatched. Pass to <code>airlock.scope(executor=...)</code>.</p> <pre><code>from airlock.integrations.executors.sync import sync_executor\nfrom airlock.integrations.executors.celery import celery_executor\nfrom airlock.integrations.executors.django_q import django_q_executor\nfrom airlock.integrations.executors.django_tasks import django_tasks_executor\nfrom airlock.integrations.executors.huey import huey_executor\nfrom airlock.integrations.executors.dramatiq import dramatiq_executor\n</code></pre>"},{"location":"api/executors/#sync_executor","title":"sync_executor","text":""},{"location":"api/executors/#airlock.integrations.executors.sync.sync_executor","title":"sync_executor","text":"<pre><code>sync_executor(intent: Intent) -&gt; None\n</code></pre> <p>Execute intent synchronously by calling the task directly.</p> <p>This is the simplest executor - no queue, no threading, just immediate execution. Dispatch options are ignored.</p>"},{"location":"api/executors/#celery_executor","title":"celery_executor","text":""},{"location":"api/executors/#airlock.integrations.executors.celery.celery_executor","title":"celery_executor","text":"<pre><code>celery_executor(intent: Intent) -&gt; None\n</code></pre> <p>Execute intent via Celery task queue.</p> <p>Passes dispatch_options directly to apply_async() or ignores them for .delay(). Falls back to synchronous execution for plain callables.</p>"},{"location":"api/executors/#django_q_executor","title":"django_q_executor","text":""},{"location":"api/executors/#airlock.integrations.executors.django_q.django_q_executor","title":"django_q_executor","text":"<pre><code>django_q_executor(intent: Intent) -&gt; None\n</code></pre> <p>Execute intent via django-q's async_task().</p> <p>Passes dispatch_options directly to async_task() as keyword arguments.</p>"},{"location":"api/executors/#django_tasks_executor","title":"django_tasks_executor","text":""},{"location":"api/executors/#airlock.integrations.executors.django_tasks.django_tasks_executor","title":"django_tasks_executor","text":"<pre><code>django_tasks_executor(intent: Intent) -&gt; None\n</code></pre> <p>Execute intent via Django's built-in tasks framework.</p> <p>Passes dispatch_options to the task's .using() method for configuration of priority, run_after, queue_name, and backend options. Falls back to synchronous execution for plain callables.</p> Supported dispatch_options <ul> <li>priority: Integer between -100 and 100 (higher = higher priority)</li> <li>run_after: datetime for deferred execution</li> <li>queue_name: Specific queue for task execution</li> <li>backend: Backend name from TASKS configuration</li> </ul>"},{"location":"api/executors/#huey_executor","title":"huey_executor","text":""},{"location":"api/executors/#airlock.integrations.executors.huey.huey_executor","title":"huey_executor","text":"<pre><code>huey_executor(intent: Intent) -&gt; None\n</code></pre> <p>Execute intent via Huey task queue.</p> <p>Passes dispatch_options directly to schedule() as keyword arguments. Falls back to synchronous execution for plain callables.</p>"},{"location":"api/executors/#dramatiq_executor","title":"dramatiq_executor","text":""},{"location":"api/executors/#airlock.integrations.executors.dramatiq.dramatiq_executor","title":"dramatiq_executor","text":"<pre><code>dramatiq_executor(intent: Intent) -&gt; None\n</code></pre> <p>Execute intent via Dramatiq task queue.</p> <p>Passes dispatch_options directly to send_with_options() or ignores them for .send(). Falls back to synchronous execution for plain callables.</p>"},{"location":"api/executors/#writing-custom-executors","title":"Writing Custom Executors","text":"<p>An executor is simply a callable that accepts an <code>Intent</code>:</p> <pre><code>def my_executor(intent: Intent) -&gt; None:\n    \"\"\"Execute an intent.\"\"\"\n    intent.task(*intent.args, **intent.kwargs)\n</code></pre> <p>See Custom Executors for examples.</p>"},{"location":"celery/","title":"Celery Integration","text":"<p>Airlock integrates with Celery to buffer and control task dispatch.</p>"},{"location":"celery/#quickstart","title":"Quickstart","text":""},{"location":"celery/#install","title":"Install","text":"<pre><code>pip install airlock celery\n</code></pre>"},{"location":"celery/#wrap-task-execution","title":"Wrap Task Execution","text":"<p>Use <code>AirlockTask</code> as base class to auto-scope task execution:</p> <pre><code>from celery import Celery\nfrom airlock.integrations.celery import AirlockTask\nimport airlock\n\napp = Celery('myapp')\n\n@app.task(base=AirlockTask)\ndef process_order(order_id):\n    order = fetch_order(order_id)\n    order.status = \"processed\"\n    save_order(order)\n\n    # These are buffered within the task's scope\n    airlock.enqueue(send_email, order_id=order_id)\n    airlock.enqueue(update_analytics, order_id=order_id)\n    # Flushes when task completes successfully\n    # Discards if task raises exception\n</code></pre>"},{"location":"celery/#dispatch-via-celery","title":"Dispatch via Celery","text":"<p>Use <code>celery_executor</code> to dispatch intents through Celery:</p> <pre><code>from airlock.integrations.executors.celery import celery_executor\n\nwith airlock.scope(executor=celery_executor):\n    airlock.enqueue(send_email, user_id=123)\n    airlock.enqueue(process_data, item_id=456)\n# Dispatches via .delay()\n</code></pre>"},{"location":"celery/#combining-both","title":"Combining Both","text":"<p>Task execution scoping + Celery dispatch:</p> <pre><code>@app.task(base=AirlockTask)\ndef process_order(order_id):\n    # This task runs in a scope\n    order = fetch_order(order_id)\n    save_order(order)\n\n    # Dispatch follow-up task via Celery\n    airlock.enqueue(send_email, order_id=order_id)\n\n# Trigger it\nwith airlock.scope(executor=celery_executor):\n    airlock.enqueue(process_order, order_id=123)\n# process_order.delay(order_id=123) is called\n# When it runs, send_email is also queued via Celery\n</code></pre>"},{"location":"celery/#pass-celery-options","title":"Pass Celery Options","text":"<pre><code>airlock.enqueue(\n    send_email,\n    user_id=123,\n    _dispatch_options={\n        \"countdown\": 60,      # Delay 60 seconds\n        \"queue\": \"emails\",    # Use specific queue\n        \"priority\": 9,        # High priority\n    }\n)\n</code></pre>"},{"location":"celery/#with-django","title":"With Django","text":"<p>Combine Django middleware + Celery executor:</p> <pre><code># settings.py\nMIDDLEWARE = [\n    \"airlock.integrations.django.AirlockMiddleware\",\n]\n\nAIRLOCK = {\n    \"EXECUTOR\": \"airlock.integrations.executors.celery.celery_executor\",\n}\n</code></pre> <p>Now every request auto-scopes and dispatches via Celery:</p> <pre><code>import airlock\n\ndef checkout_view(request):\n    order = process_checkout(request)\n    airlock.enqueue(send_confirmation, order_id=order.id)\n    airlock.enqueue(notify_warehouse, order_id=order.id)\n    return HttpResponse(\"OK\")\n# Both tasks dispatch via Celery after transaction.on_commit()\n</code></pre>"},{"location":"celery/#next-steps","title":"Next Steps","text":"<ul> <li>Task Wrapper Deep Dive - Customizing <code>AirlockTask</code></li> <li>Migration Guide - Migrating from direct <code>.delay()</code> calls</li> </ul>"},{"location":"celery/migration/","title":"Migration Guide","text":"<p>How to migrate an existing codebase from direct Celery <code>.delay()</code> calls to airlock.</p>"},{"location":"celery/migration/#the-challenge","title":"The Challenge","text":"<p>You have code like this scattered everywhere:</p> <pre><code>class Order(models.Model):\n    def save(self, *args, **kwargs):\n        super().save(*args, **kwargs)\n        notify_warehouse.delay(self.id)\n        send_email.delay(self.id)\n\n# And in views\ndef process_order(request, order_id):\n    order.process()\n    analytics.delay(order.id)\n    return HttpResponse(\"OK\")\n</code></pre> <p>Changing every <code>.delay()</code> to <code>airlock.enqueue()</code> is tedious and error-prone.</p>"},{"location":"celery/migration/#decision-tree","title":"Decision Tree","text":"<pre><code>Do you have 100+ .delay() calls?\n+-- Yes -&gt; Start with blanket migration\n+-- No  -&gt; Use selective migration\n\nIs this a new feature/module?\n+-- Yes -&gt; Use greenfield (airlock.enqueue from start)\n+-- No  -&gt; Continue below\n\nCan you afford 1-2 weeks of migration work?\n+-- Yes -&gt; Selective migration (safest)\n+-- No  -&gt; Blanket migration (fastest)\n</code></pre>"},{"location":"celery/migration/#strategy-1-selective-migration-recommended","title":"Strategy 1: Selective Migration (Recommended)","text":"<p>Migrate tasks one at a time using <code>LegacyTaskShim</code>:</p> <pre><code>from airlock.integrations.celery import LegacyTaskShim\n\n# Apply to tasks you're migrating\n@app.task(base=LegacyTaskShim)\ndef notify_warehouse(order_id):\n    ...\n\n# Old code still works (inside scopes)\nwith airlock.scope():\n    notify_warehouse.delay(order_id)  # Routes through airlock, warns\n</code></pre> <p>Behavior: - Inside scope: routes through airlock, returns <code>None</code> - Outside scope: raises <code>NoScopeError</code> - Always emits <code>DeprecationWarning</code></p> <p>Migration path: 1. Add <code>LegacyTaskShim</code> to one task 2. Ensure all call sites have scopes 3. Replace <code>.delay()</code> with <code>airlock.enqueue()</code> at your leisure 4. Remove <code>LegacyTaskShim</code> when done</p>"},{"location":"celery/migration/#pros","title":"Pros","text":"<ul> <li>Safe - Explicit about what's migrated</li> <li>Controlled - Migrate critical paths first</li> <li>Clear - Easy to see migration progress</li> <li>Testable - Test each task individually</li> </ul>"},{"location":"celery/migration/#cons","title":"Cons","text":"<ul> <li>Slow - Must apply shim to each task</li> <li>Requires scopes - Raises <code>NoScopeError</code> outside scopes</li> <li>Incomplete coverage - Un-shimmed tasks still use old behavior</li> </ul>"},{"location":"celery/migration/#strategy-2-blanket-migration","title":"Strategy 2: Blanket Migration","text":"<p>Intercept ALL tasks globally:</p> <pre><code># celery.py\nfrom celery import Celery\nfrom airlock.integrations.celery import install_global_intercept\n\napp = Celery('myapp')\n\n# Patch all tasks at startup\ninstall_global_intercept(app)\n</code></pre> <p>Behavior: - Inside scope: routes through airlock, returns <code>None</code> - Outside scope: passes through to Celery, warns - Always emits <code>DeprecationWarning</code> - Wraps all task execution in scopes automatically</p> <p>Use for: - Large codebases with 100s of <code>.delay()</code> calls - Quick proof-of-concept - Gradual migration without breaking existing code</p> <p>Warning</p> <p>This is a migration tool, not steady-state architecture. It monkey-patches Celery globally. Plan to replace <code>.delay()</code> with <code>airlock.enqueue()</code> over time.</p>"},{"location":"celery/migration/#pros_1","title":"Pros","text":"<ul> <li>Fast - One line of code</li> <li>Complete - Covers all tasks immediately</li> <li>Graceful - Works outside scopes (warns, doesn't break)</li> <li>Auto-wraps execution - Tasks run in scopes automatically</li> </ul>"},{"location":"celery/migration/#cons_1","title":"Cons","text":"<ul> <li>Global side effects - Monkey-patches Celery</li> <li>Migration tool - Not intended for steady-state</li> <li>Less control - Everything migrated at once</li> <li>Returns None - <code>.delay()</code> returns <code>None</code> inside scopes</li> </ul>"},{"location":"celery/migration/#strategy-3-greenfield-new-code","title":"Strategy 3: Greenfield (New Code)","text":"<p>Just use <code>airlock.enqueue()</code> from the start:</p> <pre><code>import airlock\n\nclass Order(models.Model):\n    def save(self, *args, **kwargs):\n        super().save(*args, **kwargs)\n        airlock.enqueue(notify_warehouse, self.id)\n\n# In views (with Django middleware)\ndef process_order(request, order_id):\n    order.process()  # Effects auto-scoped by middleware\n    return HttpResponse(\"OK\")\n</code></pre> <p>No shims, no warnings, no migration needed.</p>"},{"location":"celery/migration/#comparison","title":"Comparison","text":"Approach Effort Risk Use When Selective Medium Low Methodical migration, want control Blanket Low Medium Large codebase, need quick win Greenfield Low None New project or isolated feature"},{"location":"celery/migration/#hybrid-approach","title":"Hybrid Approach","text":"<p>Use both strategies:</p> <pre><code># celery.py - Global intercept for most tasks\ninstall_global_intercept(app, wrap_task_execution=False)\n\n# Critical tasks - Explicit shimming for control\n@app.task(base=LegacyTaskShim)\ndef critical_payment_task(order_id):\n    ...\n</code></pre> <p>This gives: - Blanket coverage for routine tasks - Explicit control for critical tasks - Gradual migration path</p>"},{"location":"celery/migration/#common-patterns","title":"Common Patterns","text":""},{"location":"celery/migration/#pattern-1-start-blanket-finish-selective","title":"Pattern 1: Start Blanket, Finish Selective","text":"<pre><code># Week 1: Install blanket migration\ninstall_global_intercept(app)\n\n# Week 2-4: Add scopes to critical paths\nwith airlock.scope():\n    process_order()\n\n# Week 5+: Replace .delay() with airlock.enqueue()\n# Old: task.delay(arg)\n# New: airlock.enqueue(task, arg)\n\n# Eventually: Remove intercept when all replaced\n</code></pre>"},{"location":"celery/migration/#pattern-2-selective-for-new-blanket-for-old","title":"Pattern 2: Selective for New, Blanket for Old","text":"<pre><code># New feature: Use airlock.enqueue from start\ndef new_checkout_flow():\n    airlock.enqueue(new_task, ...)\n\n# Legacy code: Blanket intercept\ninstall_global_intercept(app)\n</code></pre>"},{"location":"celery/migration/#pattern-3-feature-flag-migration","title":"Pattern 3: Feature Flag Migration","text":"<pre><code># settings.py\nUSE_AIRLOCK = env.bool(\"USE_AIRLOCK\", default=False)\n\n# celery.py\nif settings.USE_AIRLOCK:\n    install_global_intercept(app)\n</code></pre> <p>Test in staging, roll out gradually.</p>"},{"location":"celery/migration/#common-issues","title":"Common Issues","text":""},{"location":"celery/migration/#issue-noscopeerror-with-legacytaskshim","title":"Issue: <code>NoScopeError</code> with <code>LegacyTaskShim</code>","text":"<pre><code>notify_warehouse.delay(123)  # NoScopeError!\n</code></pre> <p>Fix: <code>LegacyTaskShim</code> requires a scope. Add one:</p> <pre><code>with airlock.scope():\n    notify_warehouse.delay(123)  # Works\n</code></pre> <p>Or use <code>install_global_intercept()</code> instead (allows outside scopes).</p>"},{"location":"celery/migration/#issue-return-value-is-none","title":"Issue: Return value is <code>None</code>","text":"<pre><code>result = task.delay(123)\nresult.get()  # AttributeError: 'NoneType' has no attribute 'get'\n</code></pre> <p>Why: Inside scopes, <code>.delay()</code> returns <code>None</code> because dispatch is deferred.</p> <p>Fix: Stop relying on <code>AsyncResult</code>. Decouple intent from result tracking. If you need results, use a different pattern (callbacks, database polling, etc.).</p>"},{"location":"celery/migration/#issue-warnings-everywhere","title":"Issue: Warnings everywhere","text":"<pre><code>DeprecationWarning: task.delay() is deprecated, use airlock.enqueue()\n</code></pre> <p>Fix: This is intentional! Replace <code>.delay()</code> with <code>airlock.enqueue()</code>:</p> <pre><code># Old\ntask.delay(arg)\n\n# New\nairlock.enqueue(task, arg)\n</code></pre>"},{"location":"celery/migration/#issue-blanket-airlocktask-double-scopes","title":"Issue: Blanket + AirlockTask = Double Scopes","text":"<p>Don't use both:</p> <pre><code># Bad - creates nested scopes\ninstall_global_intercept(app)  # Wraps execution in scope\n\n@app.task(base=AirlockTask)  # Also wraps execution in scope\ndef my_task():\n    ...\n</code></pre> <p>Choose one: - Blanket intercept with <code>wrap_task_execution=True</code> (default) - OR explicit <code>AirlockTask</code> base class</p>"},{"location":"celery/migration/#recommendation","title":"Recommendation","text":"<p>For most teams: Start with blanket migration, gradually replace <code>.delay()</code> calls.</p> <p>For small teams/codebases: Use selective migration for explicit control.</p> <p>For new code: Skip migration entirely, use <code>airlock.enqueue()</code> from day 1.</p>"},{"location":"celery/task-wrapper/","title":"Task Wrapper (AirlockTask)","text":"<p>Deep dive on wrapping Celery tasks with automatic scoping.</p>"},{"location":"celery/task-wrapper/#what-it-does","title":"What It Does","text":"<p><code>AirlockTask</code> wraps task execution in a scope:</p> <pre><code># Without AirlockTask\ndef my_task():\n    do_work()\n    airlock.enqueue(followup)  # NoScopeError!\n\n# With AirlockTask\n@app.task(base=AirlockTask)\ndef my_task():\n    do_work()\n    airlock.enqueue(followup)  # Buffered\n    # Dispatches when task exits\n</code></pre>"},{"location":"celery/task-wrapper/#lifecycle","title":"Lifecycle","text":"<pre><code>Task starts\n    |\nScope created and activated\n    |\nTask body executes\n    |\nTask completes (success or error)\n    |\nScope exits\n    |\nShould flush? (default: flush on success, discard on error)\n    |\nEffects dispatch (if flushed)\n</code></pre>"},{"location":"celery/task-wrapper/#customizing-behavior","title":"Customizing Behavior","text":""},{"location":"celery/task-wrapper/#custom-policy","title":"Custom Policy","text":"<pre><code>class MyAirlockTask(AirlockTask):\n    def get_policy(self):\n        # Log all side effects\n        return airlock.LogOnFlush(logger)\n\n@app.task(base=MyAirlockTask)\ndef my_task():\n    ...\n</code></pre>"},{"location":"celery/task-wrapper/#custom-executor","title":"Custom Executor","text":"<pre><code>class MyAirlockTask(AirlockTask):\n    def get_executor(self):\n        # Use django-q for nested tasks\n        from airlock.integrations.executors.django_q import django_q_executor\n        return django_q_executor\n\n@app.task(base=MyAirlockTask)\ndef my_task():\n    airlock.enqueue(nested_task)  # Dispatches via django-q\n</code></pre>"},{"location":"celery/task-wrapper/#custom-flush-behavior","title":"Custom Flush Behavior","text":"<pre><code>class AlwaysFlushTask(AirlockTask):\n    def should_flush(self, error):\n        # Flush even on error (for error notification tasks)\n        return True\n\n@app.task(base=AlwaysFlushTask)\ndef send_error_alert():\n    airlock.enqueue(notify_oncall, severity=\"critical\")\n    raise Exception(\"Something broke\")\n    # Still dispatches notification despite exception\n</code></pre>"},{"location":"celery/task-wrapper/#task-chaining","title":"Task Chaining","text":"<p>Tasks can trigger other tasks:</p> <pre><code>@app.task(base=AirlockTask)\ndef step_1(data):\n    result = process(data)\n    airlock.enqueue(step_2, result)\n    return result\n\n@app.task(base=AirlockTask)\ndef step_2(data):\n    final = finalize(data)\n    airlock.enqueue(step_3, final)\n    return final\n\n@app.task(base=AirlockTask)\ndef step_3(data):\n    cleanup(data)\n</code></pre> <p>Each task has its own scope. Effects dispatch when each task completes.</p>"},{"location":"celery/task-wrapper/#retries","title":"Retries","text":"<p>Airlock respects Celery retries:</p> <pre><code>@app.task(base=AirlockTask, max_retries=3)\ndef flaky_task(order_id):\n    try:\n        risky_operation()\n        airlock.enqueue(success_notification)\n    except Exception as e:\n        # Scope discards (task failed)\n        raise self.retry(exc=e)\n</code></pre> <p>Behavior: - On retry: scope discards (error path) - On final success: scope flushes - On final failure: scope discards</p> <p>Effects only dispatch when task ultimately succeeds.</p>"},{"location":"celery/task-wrapper/#testing","title":"Testing","text":"<p>Test tasks without running broker:</p> <pre><code>def test_task_side_effects():\n    with airlock.scope(policy=airlock.AssertNoEffects()):\n        process_order(123)  # Raises if any side effects\n\ndef test_task_effects():\n    # Run task body directly (not via .delay())\n    with airlock.scope() as s:\n        process_order(123)\n\n    # Inspect buffered effects\n    assert len(s.intents) == 2\n    assert s.intents[0].task.__name__ == \"send_email\"\n</code></pre>"},{"location":"celery/task-wrapper/#airlocktask-vs-install_global_intercept","title":"AirlockTask vs install_global_intercept","text":"Feature AirlockTask install_global_intercept Explicit Opt-in per task All tasks affected Safe No monkey-patching Global side effects Migration Medium effort Quick but not steady-state Control Per-task customization Global behavior <p>Recommendation: Use <code>AirlockTask</code> for production. Use <code>install_global_intercept</code> for migration only.</p>"},{"location":"extending/custom-executors/","title":"Custom Executors","text":"<p>Write custom executors to dispatch intents however you want.</p>"},{"location":"extending/custom-executors/#the-executor-interface","title":"The Executor Interface","text":"<p>An executor is just a callable that accepts an <code>Intent</code>:</p> <pre><code>def my_executor(intent: Intent) -&gt; None:\n    \"\"\"Execute an intent.\"\"\"\n    intent.task(*intent.args, **intent.kwargs)\n</code></pre> <p>That's it! No inheritance, no protocol, just a function.</p>"},{"location":"extending/custom-executors/#example-thread-pool","title":"Example: Thread Pool","text":"<pre><code>from concurrent.futures import ThreadPoolExecutor\n\nexecutor_pool = ThreadPoolExecutor(max_workers=10)\n\ndef thread_executor(intent):\n    \"\"\"Execute in thread pool.\"\"\"\n    executor_pool.submit(intent.task, *intent.args, **intent.kwargs)\n\n# Usage\nwith airlock.scope(executor=thread_executor):\n    airlock.enqueue(cpu_bound_task, data)\n# Dispatches in background thread\n</code></pre>"},{"location":"extending/custom-executors/#example-process-pool","title":"Example: Process Pool","text":"<pre><code>from multiprocessing import Pool\n\nprocess_pool = Pool(processes=4)\n\ndef process_executor(intent):\n    \"\"\"Execute in process pool.\"\"\"\n    process_pool.apply_async(intent.task, intent.args, intent.kwargs)\n\nwith airlock.scope(executor=process_executor):\n    airlock.enqueue(heavy_computation, large_data)\n</code></pre>"},{"location":"extending/custom-executors/#example-aws-lambda","title":"Example: AWS Lambda","text":"<pre><code>import boto3\nimport json\n\nlambda_client = boto3.client('lambda')\n\ndef lambda_executor(intent):\n    \"\"\"Execute via AWS Lambda.\"\"\"\n    payload = {\n        \"function\": intent.name,\n        \"args\": intent.args,\n        \"kwargs\": intent.kwargs,\n    }\n\n    lambda_client.invoke(\n        FunctionName=intent.name,\n        InvocationType='Event',\n        Payload=json.dumps(payload)\n    )\n\nwith airlock.scope(executor=lambda_executor):\n    airlock.enqueue(remote_task, data=payload)\n</code></pre>"},{"location":"extending/custom-executors/#example-http-api","title":"Example: HTTP API","text":"<pre><code>import requests\n\ndef api_executor(intent):\n    \"\"\"Execute via HTTP webhook.\"\"\"\n    endpoint = intent.dispatch_options.get(\"endpoint\", \"/default\")\n\n    requests.post(\n        f\"https://api.example.com{endpoint}\",\n        json={\n            \"task\": intent.name,\n            \"args\": intent.args,\n            \"kwargs\": intent.kwargs,\n        }\n    )\n\nwith airlock.scope(executor=api_executor):\n    airlock.enqueue(\n        remote_task,\n        data,\n        _dispatch_options={\"endpoint\": \"/tasks/heavy\"}\n    )\n</code></pre>"},{"location":"extending/custom-executors/#example-dry-run-logger","title":"Example: Dry-Run Logger","text":"<pre><code>def logging_executor(intent):\n    \"\"\"Log instead of executing (dry-run).\"\"\"\n    logger.info(\n        f\"Would execute: {intent.name}({intent.args}, {intent.kwargs})\"\n    )\n\nwith airlock.scope(executor=logging_executor):\n    airlock.enqueue(dangerous_task)  # Just logs, doesn't execute\n</code></pre>"},{"location":"extending/custom-executors/#example-conditional-executor","title":"Example: Conditional Executor","text":"<p>Route to different backends based on intent:</p> <pre><code>from airlock.integrations.executors.celery import celery_executor\nfrom airlock.integrations.executors.sync import sync_executor\n\ndef smart_executor(intent):\n    \"\"\"Route heavy tasks to Celery, light tasks run sync.\"\"\"\n    if intent.dispatch_options.get(\"heavy\"):\n        celery_executor(intent)\n    else:\n        sync_executor(intent)\n\nwith airlock.scope(executor=smart_executor):\n    airlock.enqueue(light_task)  # Runs sync\n    airlock.enqueue(heavy_task, _dispatch_options={\"heavy\": True})  # Via Celery\n</code></pre>"},{"location":"extending/custom-executors/#using-dispatch-options","title":"Using Dispatch Options","text":"<p>Executors can read <code>intent.dispatch_options</code>:</p> <pre><code>def priority_executor(intent):\n    \"\"\"Execute high-priority tasks immediately, queue low-priority.\"\"\"\n    priority = intent.dispatch_options.get(\"priority\", 5)\n\n    if priority &gt;= 8:\n        # High priority: execute immediately\n        intent.task(*intent.args, **intent.kwargs)\n    else:\n        # Low priority: queue for later\n        celery_executor(intent)\n\n# Usage\nairlock.enqueue(\n    urgent_task,\n    _dispatch_options={\"priority\": 10}\n)  # Runs immediately\n\nairlock.enqueue(\n    batch_task,\n    _dispatch_options={\"priority\": 3}\n)  # Queued\n</code></pre>"},{"location":"extending/custom-executors/#error-handling","title":"Error Handling","text":"<p>Executor exceptions abort flush:</p> <pre><code>def careful_executor(intent):\n    try:\n        intent.task(*intent.args, **intent.kwargs)\n    except Exception as e:\n        # Log but don't crash flush\n        logger.error(f\"Failed to execute {intent.name}: {e}\")\n        # Re-raise to abort flush (or don't to continue)\n        raise\n</code></pre> <p>By default, exceptions propagate and abort flush. This is fail-fast behavior.</p>"},{"location":"extending/custom-executors/#composing-executors","title":"Composing Executors","text":"<p>Wrap executors for additional behavior:</p> <pre><code>def with_retry(executor, retries=3):\n    \"\"\"Wrap executor with retry logic.\"\"\"\n    def retrying_executor(intent):\n        for attempt in range(retries):\n            try:\n                executor(intent)\n                return\n            except Exception as e:\n                if attempt == retries - 1:\n                    raise\n                logger.warning(f\"Retry {attempt + 1}/{retries} for {intent.name}\")\n    return retrying_executor\n\n# Usage\nexecutor = with_retry(celery_executor, retries=3)\n\nwith airlock.scope(executor=executor):\n    airlock.enqueue(flaky_task)\n</code></pre>"},{"location":"extending/custom-executors/#testing-custom-executors","title":"Testing Custom Executors","text":"<pre><code>def test_thread_executor():\n    executed = []\n\n    def track_executor(intent):\n        executed.append(intent.name)\n\n    with airlock.scope(executor=track_executor):\n        airlock.enqueue(task_a)\n        airlock.enqueue(task_b)\n\n    assert len(executed) == 2\n    assert executed == [\"task_a\", \"task_b\"]\n</code></pre>"},{"location":"extending/custom-executors/#built-in-executors","title":"Built-in Executors","text":"<p>Airlock provides executors for common backends:</p> <pre><code>from airlock.integrations.executors.sync import sync_executor\nfrom airlock.integrations.executors.celery import celery_executor\nfrom airlock.integrations.executors.django_q import django_q_executor\nfrom airlock.integrations.executors.huey import huey_executor\nfrom airlock.integrations.executors.dramatiq import dramatiq_executor\n</code></pre> <p>See Dispatch Guide for details.</p>"},{"location":"extending/custom-executors/#common-patterns","title":"Common Patterns","text":""},{"location":"extending/custom-executors/#pattern-1-fallback-executor","title":"Pattern 1: Fallback Executor","text":"<pre><code>def fallback_executor(intent):\n    \"\"\"Try Celery, fall back to sync if unavailable.\"\"\"\n    try:\n        celery_executor(intent)\n    except Exception:\n        logger.warning(f\"Celery unavailable, running {intent.name} sync\")\n        sync_executor(intent)\n</code></pre>"},{"location":"extending/custom-executors/#pattern-2-batching-executor","title":"Pattern 2: Batching Executor","text":"<pre><code>class BatchingExecutor:\n    def __init__(self, batch_size=10):\n        self.batch_size = batch_size\n        self.batch = []\n\n    def __call__(self, intent):\n        self.batch.append(intent)\n        if len(self.batch) &gt;= self.batch_size:\n            self.flush_batch()\n\n    def flush_batch(self):\n        # Execute batch\n        for intent in self.batch:\n            intent.task(*intent.args, **intent.kwargs)\n        self.batch.clear()\n\nexecutor = BatchingExecutor(batch_size=100)\n</code></pre>"},{"location":"extending/custom-executors/#pattern-3-rate-limited-executor","title":"Pattern 3: Rate-Limited Executor","text":"<pre><code>import time\n\nclass RateLimitedExecutor:\n    def __init__(self, max_per_second=10):\n        self.interval = 1.0 / max_per_second\n        self.last_execute = 0\n\n    def __call__(self, intent):\n        now = time.time()\n        elapsed = now - self.last_execute\n        if elapsed &lt; self.interval:\n            time.sleep(self.interval - elapsed)\n\n        intent.task(*intent.args, **intent.kwargs)\n        self.last_execute = time.time()\n</code></pre>"},{"location":"extending/custom-policies/","title":"Custom Policies","text":"<p>Write your own policies to implement custom filtering, validation, and observation logic.</p>"},{"location":"extending/custom-policies/#the-policy-protocol","title":"The Policy Protocol","text":"<pre><code>class Policy:\n    def on_enqueue(self, intent: Intent) -&gt; None:\n        \"\"\"\n        Called when intent is added to buffer.\n        Observe or raise. Return value ignored.\n        \"\"\"\n        pass\n\n    def allows(self, intent: Intent) -&gt; bool:\n        \"\"\"\n        Called at flush time.\n        Return True to dispatch, False to drop.\n        \"\"\"\n        return True\n</code></pre>"},{"location":"extending/custom-policies/#example-rate-limiting","title":"Example: Rate Limiting","text":"<pre><code>class RateLimitPolicy:\n    def __init__(self, max_per_flush: int):\n        self.max = max_per_flush\n        self._count = 0\n\n    def on_enqueue(self, intent):\n        pass  # Could warn if close to limit\n\n    def allows(self, intent):\n        if self._count &gt;= self.max:\n            return False\n        self._count += 1\n        return True\n\n# Usage\nwith airlock.scope(policy=RateLimitPolicy(max_per_flush=10)):\n    for i in range(100):\n        airlock.enqueue(task, i)\n# Only first 10 dispatch\n</code></pre>"},{"location":"extending/custom-policies/#example-priority-filtering","title":"Example: Priority Filtering","text":"<pre><code>class PriorityPolicy:\n    def __init__(self, min_priority: int):\n        self.min_priority = min_priority\n\n    def on_enqueue(self, intent):\n        pass\n\n    def allows(self, intent):\n        priority = intent.dispatch_options.get(\"priority\", 0)\n        return priority &gt;= self.min_priority\n\n# Usage\nwith airlock.scope(policy=PriorityPolicy(min_priority=5)):\n    airlock.enqueue(low_task, _dispatch_options={\"priority\": 1})   # Dropped\n    airlock.enqueue(high_task, _dispatch_options={\"priority\": 10}) # Dispatches\n</code></pre>"},{"location":"extending/custom-policies/#example-metrics-collection","title":"Example: Metrics Collection","text":"<pre><code>from datadog import statsd\n\nclass MetricsPolicy:\n    def on_enqueue(self, intent):\n        statsd.increment(f\"airlock.enqueued.{intent.name}\")\n\n    def allows(self, intent):\n        statsd.increment(f\"airlock.dispatched.{intent.name}\")\n        return True\n\n# All intents tracked in Datadog\n</code></pre>"},{"location":"extending/custom-policies/#example-audit-logging","title":"Example: Audit Logging","text":"<pre><code>import json\nfrom datetime import datetime\n\nclass AuditPolicy:\n    def __init__(self, audit_file):\n        self.audit_file = audit_file\n\n    def on_enqueue(self, intent):\n        entry = {\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"action\": \"enqueued\",\n            \"task\": intent.name,\n            \"args\": intent.args,\n            \"kwargs\": intent.kwargs,\n        }\n        with open(self.audit_file, \"a\") as f:\n            f.write(json.dumps(entry) + \"\\n\")\n\n    def allows(self, intent):\n        # Log again at dispatch\n        entry = {\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"action\": \"dispatched\",\n            \"task\": intent.name,\n        }\n        with open(self.audit_file, \"a\") as f:\n            f.write(json.dumps(entry) + \"\\n\")\n        return True\n</code></pre>"},{"location":"extending/custom-policies/#example-sampling","title":"Example: Sampling","text":"<pre><code>import random\n\nclass SamplingPolicy:\n    def __init__(self, sample_rate: float):\n        self.sample_rate = sample_rate\n\n    def on_enqueue(self, intent):\n        pass\n\n    def allows(self, intent):\n        return random.random() &lt; self.sample_rate\n\n# Only dispatch 10% of effects\nwith airlock.scope(policy=SamplingPolicy(0.1)):\n    for i in range(1000):\n        airlock.enqueue(analytics_task, i)\n# ~100 dispatch\n</code></pre>"},{"location":"extending/custom-policies/#example-circuit-breaker","title":"Example: Circuit Breaker","text":"<pre><code>class CircuitBreakerPolicy:\n    def __init__(self, error_threshold: int = 5):\n        self.error_threshold = error_threshold\n        self.error_count = 0\n        self.is_open = False\n\n    def on_enqueue(self, intent):\n        if self.is_open:\n            raise PolicyViolation(\"Circuit breaker is OPEN - too many errors\")\n\n    def allows(self, intent):\n        return not self.is_open\n\n    def record_error(self):\n        self.error_count += 1\n        if self.error_count &gt;= self.error_threshold:\n            self.is_open = True\n\n    def reset(self):\n        self.error_count = 0\n        self.is_open = False\n</code></pre>"},{"location":"extending/custom-policies/#when-to-raise-vs-return-false","title":"When to Raise vs Return False","text":"<p>Raise in <code>on_enqueue()</code> for fail-fast feedback:</p> <pre><code>def on_enqueue(self, intent):\n    if \"dangerous\" in intent.name:\n        raise PolicyViolation(f\"Dangerous task blocked: {intent.name}\")\n</code></pre> <p>Stack trace points to the <code>enqueue()</code> call site. Good for catching bugs.</p> <p>Return False in <code>allows()</code> for silent filtering:</p> <pre><code>def allows(self, intent):\n    if \"dangerous\" in intent.name:\n        return False  # Silently drop\n    return True\n</code></pre> <p>No error, no trace. Good for production filtering.</p>"},{"location":"extending/custom-policies/#stateful-policies","title":"Stateful Policies","text":"<p>Policies can maintain state:</p> <pre><code>class CountingPolicy:\n    def __init__(self):\n        self.enqueued = 0\n        self.dispatched = 0\n\n    def on_enqueue(self, intent):\n        self.enqueued += 1\n\n    def allows(self, intent):\n        self.dispatched += 1\n        return True\n\nwith airlock.scope(policy=CountingPolicy()) as s:\n    for i in range(10):\n        airlock.enqueue(task, i)\n\nprint(f\"Enqueued: {s._policy.enqueued}\")    # 10\nprint(f\"Dispatched: {s._policy.dispatched}\")  # 10\n</code></pre>"},{"location":"extending/custom-policies/#combining-policies","title":"Combining Policies","text":"<p>Use <code>CompositePolicy</code>:</p> <pre><code>policy = airlock.CompositePolicy(\n    RateLimitPolicy(max_per_flush=100),\n    MetricsPolicy(),\n    AuditPolicy(\"audit.log\"),\n)\n</code></pre> <p>Each policy's <code>allows()</code> is called. If any returns <code>False</code>, the intent is dropped.</p>"},{"location":"extending/custom-policies/#testing-custom-policies","title":"Testing Custom Policies","text":"<pre><code>def test_priority_policy():\n    policy = PriorityPolicy(min_priority=5)\n\n    low_intent = Intent(task=my_task, args=(), kwargs={}, dispatch_options={\"priority\": 1})\n    high_intent = Intent(task=my_task, args=(), kwargs={}, dispatch_options={\"priority\": 10})\n\n    assert policy.allows(low_intent) is False\n    assert policy.allows(high_intent) is True\n</code></pre>"},{"location":"extending/custom-policies/#common-patterns","title":"Common Patterns","text":""},{"location":"extending/custom-policies/#pattern-1-environment-based-behavior","title":"Pattern 1: Environment-Based Behavior","text":"<pre><code>class EnvPolicy:\n    def allows(self, intent):\n        if settings.ENV == \"development\":\n            return False  # Drop all in dev\n        if settings.ENV == \"staging\" and \"customer\" in intent.name:\n            return False  # Drop customer notifications in staging\n        return True\n</code></pre>"},{"location":"extending/custom-policies/#pattern-2-feature-flag-integration","title":"Pattern 2: Feature Flag Integration","text":"<pre><code>class FeatureFlagPolicy:\n    def allows(self, intent):\n        feature = intent.dispatch_options.get(\"feature\")\n        if feature and not feature_flags.is_enabled(feature):\n            return False\n        return True\n\n# Usage\nairlock.enqueue(\n    new_feature_task,\n    _dispatch_options={\"feature\": \"new_checkout\"}\n)\n</code></pre>"},{"location":"extending/custom-policies/#pattern-3-conditional-logging","title":"Pattern 3: Conditional Logging","text":"<pre><code>class VerbosePolicy:\n    def __init__(self, verbose: bool = False):\n        self.verbose = verbose\n\n    def on_enqueue(self, intent):\n        if self.verbose:\n            logger.debug(f\"Enqueued: {intent.name}\")\n\n    def allows(self, intent):\n        if self.verbose:\n            logger.debug(f\"Dispatching: {intent.name}\")\n        return True\n</code></pre>"},{"location":"extending/custom-policies/#important-constraints","title":"Important Constraints","text":""},{"location":"extending/custom-policies/#cannot-call-enqueue-from-policy","title":"Cannot Call enqueue() from Policy","text":"<pre><code>class BadPolicy:\n    def on_enqueue(self, intent):\n        airlock.enqueue(log_task)  # Raises PolicyEnqueueError!\n</code></pre> <p>This prevents infinite loops. If you need to trigger side effects from a policy, use a custom scope instead.</p>"},{"location":"extending/custom-policies/#cannot-reorder-intents","title":"Cannot Reorder Intents","text":"<p>Policies are per-intent boolean gates. They can't reorder:</p> <pre><code># \u274c Can't do this\ndef allows(self, intent):\n    if intent.priority == \"high\":\n        move_to_front(intent)  # Not possible\n    return True\n</code></pre> <p>For reordering, override <code>Scope._dispatch_all()</code>.</p>"},{"location":"extending/custom-scopes/","title":"Custom Scopes","text":"<p>Subclass <code>Scope</code> to customize lifecycle behavior: when to flush, how to dispatch, nested scope handling.</p>"},{"location":"extending/custom-scopes/#extension-points","title":"Extension Points","text":"Method Purpose Default <code>should_flush(error)</code> Decide whether to flush or discard Flush on success, discard on error <code>before_descendant_flushes(scope, intents)</code> Control nested scope capture Capture all <code>_dispatch_all(intents)</code> Customize dispatch mechanism Iterate and execute"},{"location":"extending/custom-scopes/#example-always-flush-even-on-error","title":"Example: Always Flush (Even on Error)","text":"<pre><code>class AlwaysFlushScope(Scope):\n    \"\"\"Flush even on error - for error notification patterns.\"\"\"\n\n    def should_flush(self, error: BaseException | None) -&gt; bool:\n        return True  # Always flush\n\n# Usage\nwith airlock.scope(_cls=AlwaysFlushScope):\n    airlock.enqueue(send_alert, severity=\"info\")\n    raise Exception(\"Something broke\")\n    # send_alert still dispatches despite exception\n</code></pre>"},{"location":"extending/custom-scopes/#example-conditional-flush","title":"Example: Conditional Flush","text":"<pre><code>class ConditionalScope(Scope):\n    \"\"\"Only flush if there are high-priority intents.\"\"\"\n\n    def should_flush(self, error: BaseException | None) -&gt; bool:\n        if error:\n            return False\n\n        # Only flush if at least one high-priority intent\n        return any(\n            i.dispatch_options and i.dispatch_options.get(\"priority\") == \"high\"\n            for i in self.intents\n        )\n\nwith airlock.scope(_cls=ConditionalScope):\n    airlock.enqueue(low_task, _dispatch_options={\"priority\": \"low\"})\n    airlock.enqueue(high_task, _dispatch_options={\"priority\": \"high\"})\n# Flushes because high_task is present\n</code></pre>"},{"location":"extending/custom-scopes/#example-deferred-dispatch-django-on_commit","title":"Example: Deferred Dispatch (Django on_commit)","text":"<pre><code>from django.db import transaction\n\nclass DjangoScope(Scope):\n    \"\"\"Defer dispatch until transaction commits.\"\"\"\n\n    def _dispatch_all(self, intents: list[Intent]) -&gt; None:\n        def do_dispatch():\n            # Execute dispatch after commit\n            for intent in intents:\n                _execute(intent)\n\n        transaction.on_commit(do_dispatch)\n\n# Usage\nwith transaction.atomic():\n    with airlock.scope(_cls=DjangoScope):\n        order.save()\n        airlock.enqueue(send_email, order.id)\n    # Email buffered, not dispatched yet\n# Email dispatches here (after commit)\n</code></pre>"},{"location":"extending/custom-scopes/#example-persistent-buffer-outbox-pattern","title":"Example: Persistent Buffer (Outbox Pattern)","text":"<pre><code>class OutboxScope(Scope):\n    \"\"\"Persist intents to database for durable buffering.\"\"\"\n\n    def _add(self, intent):\n        super()._add(intent)  # Add to in-memory buffer\n\n        # Also persist to database\n        TaskOutbox.objects.create(\n            task_name=intent.name,\n            args=intent.args,\n            kwargs=intent.kwargs,\n            status='pending'\n        )\n\n    def _dispatch_all(self, intents):\n        # Mark as ready instead of executing\n        # Separate worker will dispatch later\n        TaskOutbox.objects.filter(\n            task_name__in=[i.name for i in intents],\n            status='pending'\n        ).update(status='ready')\n\n# Intents survive process crashes\n</code></pre>"},{"location":"extending/custom-scopes/#example-independent-nested-scopes","title":"Example: Independent Nested Scopes","text":"<pre><code>class IndependentScope(Scope):\n    \"\"\"Allow nested scopes to flush independently.\"\"\"\n\n    def before_descendant_flushes(self, exiting_scope, intents):\n        return intents  # Allow all through (don't capture)\n\nwith IndependentScope():\n    with airlock.scope():\n        airlock.enqueue(task)\n    # task dispatches here (not captured)\n</code></pre>"},{"location":"extending/custom-scopes/#example-selective-capture","title":"Example: Selective Capture","text":"<pre><code>class SafetyScope(Scope):\n    \"\"\"Capture dangerous tasks, allow safe tasks through.\"\"\"\n\n    def before_descendant_flushes(self, exiting_scope, intents):\n        # Allow safe tasks through\n        safe = [i for i in intents if not i.dispatch_options.get(\"dangerous\")]\n        return safe\n\nwith SafetyScope():\n    with airlock.scope():\n        airlock.enqueue(safe_task)\n        airlock.enqueue(dangerous_task, _dispatch_options={\"dangerous\": True})\n    # safe_task executes here\n\n# dangerous_task executes here (was captured)\n</code></pre>"},{"location":"extending/custom-scopes/#example-batching-scope","title":"Example: Batching Scope","text":"<pre><code>class EmailBatchScope(Scope):\n    \"\"\"Batch emails, allow other intents through.\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.email_batch = []\n\n    def before_descendant_flushes(self, exiting_scope, intents):\n        # Separate emails from others\n        emails = [i for i in intents if 'email' in i.name]\n        others = [i for i in intents if 'email' not in i.name]\n\n        # Batch emails for later\n        self.email_batch.extend(emails)\n\n        # Allow others through now\n        return others\n\nwith EmailBatchScope() as scope:\n    process_bulk_operations()  # Nested code enqueues emails\n    # Non-email effects dispatched\n\n# Send batched emails\nsend_batch_emails(scope.email_batch)\n</code></pre>"},{"location":"extending/custom-scopes/#available-state-in-subclasses","title":"Available State in Subclasses","text":"Property Type Description <code>self.intents</code> <code>list[Intent]</code> All buffered intents (own + captured) <code>self.own_intents</code> <code>list[Intent]</code> Intents from this scope <code>self.captured_intents</code> <code>list[Intent]</code> Intents from nested scopes <code>self._policy</code> <code>Policy</code> Scope's policy <code>self.is_flushed</code> <code>bool</code> True after flush() called <code>self.is_discarded</code> <code>bool</code> True after discard() called"},{"location":"extending/custom-scopes/#lifecycle-phases","title":"Lifecycle Phases","text":"<p>Understanding the lifecycle helps with customization:</p> <pre><code>1. __init__()         - Scope created\n2. enter()            - Scope activated (context var set)\n3. [intents buffered] - Code executes, enqueue() calls buffered\n4. exit()             - Scope deactivated (context var reset)\n5. should_flush()     - Decide terminal action\n6. flush()            - Apply policy, call _dispatch_all()\n7. _dispatch_all()    - Execute intents\n</code></pre>"},{"location":"extending/custom-scopes/#common-mistakes","title":"Common Mistakes","text":""},{"location":"extending/custom-scopes/#dont-override-flush","title":"\u274c Don't Override flush()","text":"<pre><code># \u274c Bad - breaks internal state management\nclass BadScope(Scope):\n    def flush(self):\n        # Custom logic\n        ...\n</code></pre> <p>Instead: Override <code>should_flush()</code> or <code>_dispatch_all()</code>.</p>"},{"location":"extending/custom-scopes/#dont-forget-to-call-super","title":"\u274c Don't Forget to Call super()","text":"<pre><code># \u274c Bad - breaks buffer management\nclass BadScope(Scope):\n    def _add(self, intent):\n        my_custom_buffer.append(intent)  # Forgot super()!\n</code></pre> <p>Fix:</p> <pre><code>class GoodScope(Scope):\n    def _add(self, intent):\n        super()._add(intent)  # Add to internal buffer\n        my_custom_buffer.append(intent)  # Plus custom logic\n</code></pre>"},{"location":"extending/custom-scopes/#dont-mutate-intents-list","title":"\u274c Don't Mutate Intents List","text":"<pre><code># \u274c Bad - mutates caller's list\ndef before_descendant_flushes(self, exiting_scope, intents):\n    intents.append(new_intent)  # Mutates original!\n    return intents\n</code></pre> <p>Fix:</p> <pre><code>def before_descendant_flushes(self, exiting_scope, intents):\n    return intents + [new_intent]  # Return new list\n</code></pre>"},{"location":"extending/custom-scopes/#testing-custom-scopes","title":"Testing Custom Scopes","text":"<pre><code>def test_always_flush_scope():\n    with airlock.scope(_cls=AlwaysFlushScope) as s:\n        airlock.enqueue(task)\n        raise Exception()\n\n    # Verify it flushed despite exception\n    assert s.is_flushed\n    assert not s.is_discarded\n</code></pre>"},{"location":"quickstart/django/","title":"Django integration","text":"<p>Airlock provides a Django middleware that automatically creates a scopes for your view code.  Out of the box, Airlock is compatible with many popular task frameworks including Celery,  django-q, Dramatiq, huey, and Django Tasks.</p>"},{"location":"quickstart/django/#how-it-works","title":"How it works","text":"<p>The middleware automatically wraps each request in a scope with the following behaviors:</p> <ul> <li>All side effects enqueued during a request remain buffered until the end of the request.</li> <li>When the Response reaches airlock's middleware:</li> <li>If the response is an error (4xx/5xx or unhandled exception) side effects are discarded.</li> <li>If the response is successful (1xx/2xx/3xx) side effects are dispatched.<ul> <li>If you're in a database transaction, side effects will be deferred to <code>transaction.on_commit()</code> automatically.</li> </ul> </li> </ul> <p>These default behaviors are configurable.</p>"},{"location":"quickstart/django/#installation-setup","title":"Installation &amp; setup","text":"<pre><code>pip install airlock\n</code></pre> <p>In <code>settings.py</code>, add middleware and configure your task framework:</p> <pre><code>MIDDLEWARE = [\n    # ... other middleware ...\n    \"airlock.integrations.django.AirlockMiddleware\",\n]\n\nAIRLOCK = {\n    \"EXECUTOR\": \"airlock.integrations.executors.celery.celery_executor\",\n}\n</code></pre>"},{"location":"quickstart/django/#basic-usage","title":"Basic usage","text":"<p>Anywhere in your models/views/services/etc, pass your task functions to <code>airlock.enqueue()</code>:</p> <pre><code>## models.py\nimport airlock\nimport .tasks\n\nclass Order(models.Model):\n    def process(self):\n        self.status = \"processed\"\n        self.save()\n        airlock.enqueue(tasks.send_confirmation_email, order_id=self.id)\n        airlock.enqueue(tasks.notify_warehouse, order_id=self.id)\n\n## views.py\ndef checkout(request):\n    order = Order.objects.get(id=request.POST['order_id'])\n    order.process()\n    return HttpResponse(\"OK\")\n# All side effects dispatch here after response + transaction commit\n</code></pre>"},{"location":"quickstart/django/#configuration","title":"Configuration","text":"<p>With zero configuration, all tasks execute synchronously as plain callables at dispatch time, hooked in to <code>transaction.on_commit(robust=True)</code> against the default database.</p> <pre><code># settings.py\nAIRLOCK = {\n    # Just call functions synchronously at dispatch time\n    \"EXECUTOR\": \"airlock.integrations.executors.sync.sync_executor\",\n    # Other built in options:\n    # \"EXECUTOR\": \"airlock.integrations.executors.celery.celery_executor\",\n    # \"EXECUTOR\": \"airlock.integrations.executors.django_q.django_q_executor\",\n    # \"EXECUTOR\": \"airlock.integrations.executors.huey.huey_executor\",\n    # \"EXECUTOR\": \"airlock.integrations.executors.dramatiq.dramatiq_executor\",\n    # \"EXECUTOR\": \"airlock.integrations.executors.django_tasks.django_tasks_executor\",\n\n    \"POLICY\": \"airlock.AllowAll\",\n}\n</code></pre>"},{"location":"quickstart/django/#overriding-4xx5xx-behavior","title":"Overriding 4xx/5xx behavior","text":"<p>By default airlock's Django middleware discards side effects  on 4xx/5xx responses and on exceptions. To customize this behavior, subclass <code>AirlockMiddleware</code> and override <code>should_flush</code>:</p> <pre><code>## middleware.py\nfrom airlock.integrations.django import AirlockMiddleware\nclass UnconditionallyDispatchingAirlockMiddleware(AirlockMiddleware):\n    def should_flush(self, request, response):\n        return True\n\n## settings.py\nMIDDLEWARE = [\n    # ...\n    \"my_app.middleware.UnconditionallyDispatchingAirlockMiddleware\",\n    # ...\n]\n</code></pre>"},{"location":"quickstart/django/#middleware-placement","title":"Middleware placement","text":"<p>Any placement works for most projects. Django's request handler converts uncaught exceptions to 4xx/5xx responses, so <code>AirlockMiddleware</code> typically sees the correct status code and discards appropriately.</p> <p>Placement matters if you have custom middleware with <code>process_exception()</code> that catches view exceptions and returns 2xx or 3xx responses. In that case, place <code>AirlockMiddleware</code> higher (earlier) in the list than such middleware, so it sees the exception via its own <code>process_exception</code> before another middleware converts it to a misleading success response.</p> <p>If you care about dispatching conditional on exceptions from middleware themselves (not just views), place <code>AirlockMiddleware</code> above those middleware. Similarly, if you use <code>ATOMIC_REQUESTS=False</code> and maintain your own control over transaction boundaries across middleware layers, you may need to be more opinionated about ordering.</p>"},{"location":"quickstart/django/#airlock-in-management-commands","title":"Airlock in management commands","text":"<p>Wrap commands with <code>@airlock_command</code> for automatic scoping:</p> <ul> <li>All side effects enqueued during a command remain buffered until the end of the command.</li> <li>When the command finishes:</li> <li>If there was an unhandled exception, side effects are discarded.</li> <li>If the command is successful, side effects are dispatched.</li> <li>If your command supports a <code>--dry-run</code> flag, airlock will discard side effects when your command executes in dry-run mode.</li> </ul> <pre><code>from django.core.management.base import BaseCommand\nfrom airlock.integrations.django import airlock_command\n\nclass Command(BaseCommand):\n    def add_arguments(self, parser):\n        parser.add_argument('--dry-run', action='store_true')\n\n    @airlock_command\n    def handle(self, *args, **options):\n        # If --dry-run, all side effects will drop automatically\n        # Otherwise, all side effects will dispatch at the end of the script\n        for order in Order.objects.filter(status='pending'):\n            order.process()\n</code></pre>"},{"location":"quickstart/django/#manual-scoping","title":"Manual scoping","text":"<p>You can always maintain explicit control too with the context manager API.  Use <code>DjangoScope</code> to pick up settings and transaction-aware dispatch timing:</p> <pre><code>from airlock.integrations.django import DjangoScope\n\n# In a script, task, etc:\ndef background_job():\n    with airlock.scope(_cls=DjangoScope):\n        do_stuff()\n    # Effects dispatch after transaction commit\n\n# Or in a view with finer-grained control:\ndef checkout(request):\n    order = Order.objects.get(id=request.POST['order_id'])\n    with airlock.scope(_cls=DjangoScope):\n        order.process()\n    with airlock.scope(_cls=DjangoScope):\n        ping_analytics(request.user)\n    return HttpResponse(\"OK\")\n</code></pre> <p>This pattern can also be combined with middleware-based implicit scopes. You'll want to read more about how nested scopes work in that case!</p>"},{"location":"understanding/alternatives/","title":"Alternatives","text":""},{"location":"understanding/alternatives/#transactionon_commit","title":"<code>transaction.on_commit()</code>","text":"<p>In many Django projects, the typical pattern evolution is to start with immediately-escaping tasks:</p> <pre><code>class Order:\n    def process(self):\n        self.status = \"processed\"\n        self.save()\n        notify_warehouse.delay(self.id)\n        send_confirmation_email(self.id)\n</code></pre> <p>And then migrate to a transaction boundary:</p> <pre><code>class Order:\n    def process(self):\n        self.status = \"processed\"\n        self.save()\n        transaction.on_commit(lambda: notify_warehouse.delay(self.id))\n        transaction.on_commit(lambda: send_confirmation_email(self.id))\n</code></pre> <p>This solves one problem: don't fire if the transaction rolls back, and don't fire until database state has settled. But it doesn't solve the rest:</p> <ul> <li>Only works inside a transaction. If you call <code>on_commit()</code> while there isn't an open transaction, the callback will be executed immediately. So the temporal sequence of your code changes silently based on both global configuration (<code>ATOMIC_REQUESTS</code>) and any given call stack (<code>with transaction.atomic()</code>) -- yikes!</li> <li>No opt-out. Migrations, fixtures, tests still trigger.</li> <li>No introspection. Can't ask \"what's about to fire?\"</li> <li>No policy control. Can't suppress specific tasks or block regions.</li> <li>What about sequential transactions? What about savepoints (nested transactions)? Hard to reason about! (Your side effects will run after each outermost transaction commits, in the order they were registered within that transaction's scope.)</li> </ul> <p>Airlock gives you <code>on_commit</code> behavior (via <code>DjangoScope</code>) plus policies, introspection, and a single dispatch boundary.</p>"},{"location":"understanding/alternatives/#django-signals","title":"Django signals","text":"<p>Signals move where the side effect lives, not whether or when it fires. This is a powerful tool for code organization, but it doesn't address the core problems.</p>"},{"location":"understanding/alternatives/#celery-chordschains","title":"Celery chords/chains","text":"<p>If your tasks trigger other tasks, consider whether the workflow should be defined upfront instead. <code>chain(task_a.s(), task_b.s())</code> makes the cascade explicit with no hidden enqueues.</p> <p>Airlock helps when that's not practical: triggers deep in the call stack that can't be extracted trivially; tasks that conditionally trigger others; or when you legitimately want to keep your side effect intents DRY across all callers.</p>"},{"location":"understanding/alternatives/#when-you-dont-need-this","title":"When you don't need this","text":"<p>You might not need airlock if:</p> <ul> <li>Views are the only place you enqueue. All <code>.delay()</code> calls are in views, never in models or reusable services.</li> <li>Tasks don't chain internally. No task triggers another task within its code.</li> <li>You use <code>ATOMIC_REQUESTS</code>. Transaction boundaries are already request-scoped, so <code>on_commit</code> behaves predictably.</li> <li>You always remember to hook into <code>transaction.on_commit</code>. All your view code reliably runs <code>transaction.on_commit(functools.partial(task.delay, ...))</code> so side effects never escape out of an incomplete or rolled-back transaction.</li> <li>You're happy with these constraints. You accept that domain intent (\"notify warehouse when order ships\") lives in views, not models.</li> </ul> <p>In this scenario, the view plus the database transaction is your boundary.</p> <p>That's a valid architecture. (I prefer it actually!) Airlock is for when you want to express intent closer to the domain -- in <code>save()</code>, in signals, in service methods -- without losing control over escape.</p>"},{"location":"understanding/core-model/","title":"Core Model: The 3 Concerns","text":"<p>Airlock separates three orthogonal concerns that can be mixed and customized.</p> Concern Controlled By Question WHEN Scope When do effects escape? WHAT Policy Which effects execute? HOW Executor How do they run?"},{"location":"understanding/core-model/#concern-1-when-scope","title":"Concern 1: WHEN (Scope)","text":"<p>Scopes control timing and lifecycle.</p> <pre><code># Basic scope: flush on success, discard on error\nwith airlock.scope():\n    do_stuff()\n    # Effects buffered...\n# Effects execute here (on normal exit)\n</code></pre> <pre><code># Transaction-aware scope: wait for commit\nfrom airlock.integrations.django import DjangoScope\n\nwith transaction.atomic():\n    with airlock.scope(_cls=DjangoScope):\n        order.save()\n        airlock.enqueue(send_email, order.id)\n    # Effects still buffered...\n# Effects execute here (after commit)\n</code></pre>"},{"location":"understanding/core-model/#scope-decides","title":"Scope decides:","text":"<ul> <li>When to flush (end of block, after commit, custom)</li> <li>Whether to flush (success vs error)</li> <li>How to store buffer (memory, database, etc.)</li> </ul> <p>Default: flush on normal exit, discard on exception.</p>"},{"location":"understanding/core-model/#concern-2-what-policy","title":"Concern 2: WHAT (Policy)","text":"<p>Policies filter and observe intents.</p> <pre><code># Drop all effects (dry-run)\nwith airlock.scope(policy=airlock.DropAll()):\n    process_orders()  # Effects buffered but never dispatched\n\n# Assert no effects (testing)\nwith airlock.scope(policy=airlock.AssertNoEffects()):\n    pure_function()  # Raises if any enqueue() called\n\n# Block specific tasks\nwith airlock.scope(policy=airlock.BlockTasks({\"send_email\"})):\n    process_order()  # Emails dropped, other tasks execute\n\n# Log everything\nwith airlock.scope(policy=airlock.LogOnFlush(logger)):\n    do_stuff()  # All dispatches logged\n</code></pre>"},{"location":"understanding/core-model/#policy-decides","title":"Policy decides:","text":"<ul> <li>Which intents are allowed (filter)</li> <li>What to observe (logging, metrics)</li> <li>When to fail fast (assertions)</li> </ul> <p>Default: allow everything.</p>"},{"location":"understanding/core-model/#concern-3-how-executor","title":"Concern 3: HOW (Executor)","text":"<p>Executors control dispatch mechanism.</p> <pre><code># Sync execution (default)\nwith airlock.scope():\n    airlock.enqueue(my_function, arg=123)\n# Executes: my_function(arg=123)\n\n# Celery\nfrom airlock.integrations.executors.celery import celery_executor\n\nwith airlock.scope(executor=celery_executor):\n    airlock.enqueue(celery_task, arg=123)\n# Executes: celery_task.delay(arg=123)\n\n# django-q\nfrom airlock.integrations.executors.django_q import django_q_executor\n\nwith airlock.scope(executor=django_q_executor):\n    airlock.enqueue(any_function, arg=123)\n# Executes: async_task(any_function, arg=123)\n</code></pre>"},{"location":"understanding/core-model/#executor-decides","title":"Executor decides:","text":"<ul> <li>How to run the task (sync, queue, thread pool...)</li> <li>What protocol to use (Celery, django-q, Huey, custom)</li> </ul> <p>Default: synchronous execution.</p>"},{"location":"understanding/core-model/#mixing-concerns","title":"Mixing Concerns","text":"<p>The power is in composition:</p> <pre><code># Transaction-aware + Celery + logging\nfrom airlock.integrations.django import DjangoScope\nfrom airlock.integrations.executors.celery import celery_executor\n\nwith airlock.scope(\n    _cls=DjangoScope,           # WHEN: after transaction.on_commit()\n    executor=celery_executor,   # HOW: via Celery\n    policy=LogOnFlush(logger)   # WHAT: log everything\n):\n    order.save()\n    airlock.enqueue(send_email, order.id)\n# Waits for commit, dispatches via Celery, logs\n</code></pre> <pre><code># Test scope + sync executor + assertion\nwith airlock.scope(\n    _cls=Scope,                      # WHEN: immediate (no transaction)\n    executor=sync_executor,          # HOW: synchronous\n    policy=AssertNoEffects()         # WHAT: fail if anything enqueued\n):\n    test_calculation()\n</code></pre> <pre><code># Migration scope + drop all + immediate\nwith airlock.scope(\n    _cls=Scope,                      # WHEN: immediate\n    executor=sync_executor,          # HOW: doesn't matter (nothing runs)\n    policy=DropAll()                 # WHAT: suppress everything\n):\n    backfill_data()\n</code></pre>"},{"location":"understanding/design-invariants/","title":"Design Invariants","text":"<p>These are the core guarantees that airlock enforces by design.</p>"},{"location":"understanding/design-invariants/#1-policies-cannot-enqueue","title":"1. Policies cannot enqueue","text":"<p>Calling <code>enqueue()</code> from within a policy raises <code>PolicyEnqueueError</code>.</p> <p>Policies observe and filter \u2014 they don't produce new side effects. This keeps the system predictable: the set of intents comes from your domain code, not from policy logic.</p>"},{"location":"understanding/design-invariants/#2-buffered-effects-escape-only-at-flush","title":"2. Buffered effects escape only at flush","text":"<p>Effects enqueued via <code>airlock.enqueue()</code> are held in the buffer until the scope flushes. There's no way for them to escape early \u2014 no \"force dispatch\" API, no automatic leaking.</p> <p>This is the control airlock provides: you express intent anywhere in your code, but the scope boundary decides when (and whether) those effects actually run.</p>"},{"location":"understanding/design-invariants/#3-no-scope-error","title":"3. No scope = error","text":"<p>Calling <code>enqueue()</code> outside a scope raises <code>NoScopeError</code>.</p> <p>This is intentional. Airlock requires explicit lifecycle boundaries \u2014 side effects should not escape silently. If you want auto-dispatch without a scope, just call <code>.delay()</code> directly. The strictness is a feature, not a limitation.</p>"},{"location":"understanding/nesting/","title":"Nesting","text":"<p>With airlock you can nest scopes or policies arbitrarily.</p>"},{"location":"understanding/nesting/#nested-policies","title":"Nested Policies","text":"<p>Use <code>with airlock.policy()</code> to layer additional policies anywhere in your codebase, all in the same scope's buffer:</p> <pre><code>with airlock.scope():\n    airlock.enqueue(task_a)  \n\n    with airlock.policy(airlock.DropAll()):\n        airlock.enqueue(task_b)  \n\n    airlock.enqueue(task_c) \n# `task_a` executes, `task_b` is dropped, `task_c` executes\n</code></pre>"},{"location":"understanding/nesting/#nested-scopes","title":"Nested Scopes","text":"<p>Your <code>with airlock.scope()</code> contexts can also be nested. Nested scopes don't flush independently by default. They're captured by their parent instead.</p> <pre><code>with airlock.scope() as outer:\n    airlock.enqueue(task_a)\n\n    with airlock.scope() as inner:\n        airlock.enqueue(task_b)\n    # Inner scope exits, but task_b is CAPTURED by outer\n\n# `task_a` and `task_b` both execute here\n</code></pre> <p>This logic applies recursively; the outermost <code>airlock.scope</code> has ultimate authority:</p> <pre><code>def code_with_side_effects(a):\n    with airlock.scope():\n        airlock.enqueue(task_c)\n        return a * 2\n\nwith airlock.scope() as outer:\n    airlock.enqueue(task_a)\n\n    with airlock.scope() as inner:\n        airlock.enqueue(task_b)\n        code_with_side_effects(5)\n\n# `task_a`, `task_b`, and `task_c` all execute here\n</code></pre>"},{"location":"understanding/nesting/#wait-what-why-not-local-control","title":"Wait, what? Why not local control?","text":"<p>If nested scopes were to flush by default, we would have an inverse flywheel -- the more library code adopts airlock, the less control you have. Airlock scopes defined deep in call stacks would recreate the same \"side effects might get released anywhere\" problem that airlock tries to solve.</p> <p>With \"outermost scope controls\", multi-step operations stay well defined even when callees use scopes, without callers needing to know:</p> <pre><code>def checkout_cart(cart_id):\n    with airlock.scope():\n        validate_inventory(cart_id)     # May use scopes internally\n        charge_payment(cart_id)         # May use scopes internally\n        send_confirmation(cart_id)      # May use scopes internally\n    # All effects dispatch only if we reach the end successfully\n</code></pre>"},{"location":"understanding/nesting/#provenance-tracking","title":"Provenance Tracking","text":"<p>After capturing a nested scope's intents, a parent scope can distinguish its own intents from captured ones:</p> <pre><code>with airlock.scope() as outer:\n    airlock.enqueue(task_a)  \n\n    with airlock.scope() as inner:\n        airlock.enqueue(task_b) \n\n    print(f\"Own: {len(outer.own_intents)}\")          # 1\n    print(f\"Captured: {len(outer.captured_intents)}\")  # 1\n    print(f\"Total: {len(outer.intents)}\")            # 2\n</code></pre> <p>This enables: - Auditing where intents came from - Different handling for own vs captured - Debugging nested behavior</p>"},{"location":"understanding/nesting/#the-before_descendant_flushes-hook","title":"The <code>before_descendant_flushes</code> Hook","text":"<p>If you want to change this behavior, create your own scope class to define what happens when nested scopes exit.</p> <pre><code>class Scope:\n    def before_descendant_flushes(\n        self,\n        exiting_scope: Scope,\n        intents: list[Intent]\n    ) -&gt; list[Intent]:\n        \"\"\"\n        Called when nested scope exits.\n\n        Return intents to allow through.\n        Anything not returned is captured.\n\n        Default: return [] (capture all)\n        \"\"\"\n        return []\n</code></pre>"},{"location":"understanding/nesting/#use-cases","title":"Use Cases","text":"<p>Selective capture:</p> <pre><code>class SafetyScope(Scope):\n    \"\"\"Capture dangerous tasks, allow others through.\"\"\"\n\n    def before_descendant_flushes(self, exiting_scope, intents):\n        safe = [i for i in intents if not i.dispatch_options.get(\"dangerous\")]\n        return safe\n\nwith SafetyScope():\n    with airlock.scope():\n        airlock.enqueue(safe_task)              # Allowed through\n        airlock.enqueue(\n            dangerous_task,\n            _dispatch_options={\"dangerous\": True}\n        )                                        # Captured\n    # safe_task executed \u2713\n\n# dangerous_task executes here \u2713\n</code></pre> <p>Batching:</p> <pre><code>class EmailBatchScope(Scope):\n    \"\"\"Batch emails, allow others through.\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.email_batch = []\n\n    def before_descendant_flushes(self, exiting_scope, intents):\n        emails = [i for i in intents if 'email' in i.name]\n        others = [i for i in intents if 'email' not in i.name]\n\n        self.email_batch.extend(emails)  # Capture for batching\n        return others                     # Others execute now\n\nwith EmailBatchScope() as batch:\n    with airlock.scope():\n        airlock.enqueue(send_email, to=\"user1@example.com\")\n        airlock.enqueue(log_event, event=\"email_queued\")\n    # log_event executes \u2713, email captured\n\n# Send batch\nsend_batch_emails(batch.email_batch)\n</code></pre> <p>Independent scopes (opt-out of capture):</p> <pre><code>class IndependentScope(Scope):\n    \"\"\"Allow nested scopes to flush independently.\"\"\"\n\n    def before_descendant_flushes(self, exiting_scope, intents):\n        return intents  # Allow all through\n\nwith IndependentScope():\n    with airlock.scope():\n        airlock.enqueue(task)\n    # task dispatches here (not captured) \u2713\n</code></pre>"},{"location":"understanding/nesting/#policy-vs-capture","title":"Policy vs Capture","text":"<p>Policy controls WHAT executes (filtering):</p> <pre><code>with airlock.scope(policy=BlockTasks({\"send_email\"})):\n    airlock.enqueue(send_email)  # Blocked - never executes\n    airlock.enqueue(log_event)   # Allowed - executes\n</code></pre> <p>Capture controls WHEN executes (timing):</p> <pre><code>with airlock.scope() as outer:\n    with airlock.scope():\n        airlock.enqueue(send_email)  # Captured - executes later\n        airlock.enqueue(log_event)   # Captured - executes later\n# Both execute here (deferred, not blocked)\n</code></pre> <p>Key difference: - Policy: intent filtered out (never executes) - Capture: intent deferred (executes later at outer scope)</p>"},{"location":"understanding/nesting/#extension-points-summary","title":"Extension Points Summary","text":"<p>Control different aspects of composition:</p> Extension Point Controls Default Policy What intents are allowed <code>AllowAll()</code> <code>should_flush()</code> Whether scope flushes/discards Flush on success <code>before_descendant_flushes()</code> When nested intents execute Capture all Executor How intents execute Sync <p>These are independent and compose freely.</p>"},{"location":"understanding/nesting/#mental-model","title":"Mental Model","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Outer Scope                         \u2502\n\u2502                                     \u2502\n\u2502  Own intent: task_a                 \u2502\n\u2502                                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Inner Scope                   \u2502 \u2502\n\u2502  \u2502                               \u2502 \u2502\n\u2502  \u2502  Own intent: task_b           \u2502 \u2502\n\u2502  \u2502                               \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502         \u2502                           \u2502\n\u2502         \u2502 before_descendant_flushes()\u2502\n\u2502         \u25bc                           \u2502\n\u2502  Captured intent: task_b            \u2502\n\u2502                                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u2502 flush()\n         \u25bc\n   [task_a, task_b] dispatch together\n</code></pre>"},{"location":"understanding/nesting/#common-patterns","title":"Common Patterns","text":""},{"location":"understanding/nesting/#pattern-1-transaction-boundary","title":"Pattern 1: Transaction Boundary","text":"<pre><code>class TransactionScope(DjangoScope):\n    def before_descendant_flushes(self, exiting_scope, intents):\n        return []  # Capture all\n\nwith transaction.atomic():\n    with airlock.scope(_cls=TransactionScope):\n        complex_operation()  # May have nested scopes\n    # Nothing dispatches yet\n# All dispatches after commit \u2713\n</code></pre>"},{"location":"understanding/nesting/#pattern-2-conditional-batching","title":"Pattern 2: Conditional Batching","text":"<pre><code>class ConditionalBatchScope(Scope):\n    def before_descendant_flushes(self, exiting_scope, intents):\n        # Batch high-volume tasks, allow low-volume through\n        high_volume = [i for i in intents if i.dispatch_options.get(\"batch\")]\n        return [i for i in intents if i not in high_volume]\n\nwith ConditionalBatchScope():\n    bulk_operation()\n    # Low-volume dispatches immediately, high-volume batched\n</code></pre>"},{"location":"understanding/nesting/#pattern-3-ordering-control","title":"Pattern 3: Ordering Control","text":"<pre><code>class DBBeforeCacheScope(Scope):\n    \"\"\"DB writes now, cache updates later.\"\"\"\n\n    def before_descendant_flushes(self, exiting_scope, intents):\n        db_writes = [i for i in intents if 'db' in i.name]\n        return db_writes  # Allow DB writes through now\n\nwith DBBeforeCacheScope():\n    with airlock.scope():\n        airlock.enqueue(update_cache)\n        airlock.enqueue(db_write)\n    # db_write executes \u2713, update_cache captured\n# update_cache executes here (after DB commit) \u2713\n</code></pre>"},{"location":"understanding/the-problem/","title":"The Problem","text":""},{"location":"understanding/the-problem/#why-does-airlock-exist-what-problem-does-it-solve","title":"Why does airlock exist? What problem does it solve?","text":"<p>Putting side effects deep in the call stack is common but dangerous:</p> <pre><code>class Order:\n    def process(self):\n        self.status = \"processed\"\n        notify_warehouse(self.id)\n        send_confirmation_email(self.id)\n</code></pre> <p>It's also tempting to centralize \"conditional side effect dispatch\" in a deep method. Also dangerous!</p> <pre><code>class Order:\n    def update_status(self, status):\n        notify_warehouse(self.id)\n        if status == \"paid\":\n            send_confirmation_email(self.id)\n        elif status == \"shipped\":\n            update_tracking_system(self.id)\n            send_update_email(self.id)\n</code></pre> <p>But why are they dangerous?</p> <ul> <li>You can't opt out. Every scripted creation, fixture load, and migration that calls the method fires the tasks.</li> <li>It's invisible at the call site. <code>order.mark_as_paid()</code> looks innocent. You have to know to trace its call stack for side effects.</li> <li>Testing is miserable. Mock at the task level (fragile), run a real broker (slow), or <code>CELERY_ALWAYS_EAGER=True</code> (hides async bugs).</li> <li>Bulk operations explode. A loop calling <code>save()</code> on 10,000 orders enqueues 10,000 tasks.</li> <li>Re-entrancy bites. <code>User.save()</code> calls <code>enrich_from_api.delay(user.id)</code>. That task fetches data, sets <code>user.age</code> and <code>user.income</code>, then calls <code>user.save()</code>... which enqueues <code>enrich_from_api</code> again. Now you're adding flags like <code>_skip_enrich=True</code> and threading them through everywhere. (Or you're diffing against <code>Model.objects.get(pk=self.pk)</code> in every <code>save()</code> and using <code>save(changed_fields=[])</code> as a task dispatcher. Now you have three problems.)</li> </ul> <p>The problem isn't where the intent is expressed. It's that the effects are silent, and escape immediately.</p>"},{"location":"understanding/the-problem/#stuff-it-all-in-an-airlock","title":"Stuff it all in an airlock","text":"<p>With airlock, you express an intent to perform a side effect, but the side effects don't escape until someone lets them out:</p> <pre><code>import airlock\n\nclass Order:\n    def process(self):\n        self.status = \"processed\"\n        airlock.enqueue(notify_warehouse, self.id)          # Buffered for later\n        airlock.enqueue(send_confirmation_email, self.id)   # Buffered for later\n</code></pre> <p>Now these methods are a legitimate and safe place to express domain intent:</p> <ul> <li>Colocation. The model knows when it needs side effects. You may want that knowledge to belong here.</li> <li>DRY. Every code path that saves an Order expresses the side effects. You can't forget.</li> <li>Control. The scope decides what escapes, not the call site.</li> <li>Visibility. You can inspect the buffer before it flushes... run a model method and compare before-and-after... great for tests!</li> <li>Control again. Define your own nested scopes for surgically stacked policies, or even define multiple execution boundaries.</li> </ul> <p>Side effects can be defined close to the source, and still escape in one place.</p>"},{"location":"understanding/the-problem/#what-this-unlocks","title":"What this unlocks","text":"<p>Without airlock, \"enqueue all side effects at the edge\" is an important constraint for maintaining predictable timing, auditability, and control. Side effects deep in the call stack are dangerous, so you're forced to pull them out.</p> <p>With airlock, both patterns are safe:</p> <ul> <li>Edge-only: All enqueues in views/handlers. Explicit, visible at the boundary.</li> <li>Colocated: Enqueues near domain logic (<code>save()</code>, signals, service methods). DRY, encapsulated.</li> </ul> <p>Choose based on your preferences, not out of necessity.</p>"},{"location":"understanding/the-problem/#do-i-really-need-this","title":"Do I really need this...?","text":"<ul> <li>See Alternatives</li> </ul>"}]}